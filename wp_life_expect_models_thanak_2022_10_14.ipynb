{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "316a0779",
   "metadata": {},
   "source": [
    "# Wikipedia Notable Life Expectancies\n",
    "# [Notebook  13: Models](https://github.com/teresahanak/wikipedia-life-expectancy/blob/main/wp_life_expect_models_thanak_2022_10_14.ipynb)\n",
    "### Context\n",
    "\n",
    "The\n",
    "### Objective\n",
    "\n",
    "The\n",
    "### Data Dictionary\n",
    "- Feature: Description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99245d51",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "453bba83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1;\n",
       "                var nbb_unformatted_code = \"# To structure code automatically\\n%load_ext nb_black\\n\\n# To import/export sqlite databases\\n# import sqlite3 as sql\\n\\n# To save/open python objects in pickle file\\nimport pickle\\n\\n# To help with reading, cleaning, and manipulating data\\nimport pandas as pd\\nimport numpy as np\\n\\n# To help with data visualization\\nimport matplotlib.pyplot as plt\\nimport seaborn as sns\\n\\n# To be used for missing value imputation\\nfrom sklearn.impute import SimpleImputer\\n\\n# To help with model building\\nfrom sklearn.tree import DecisionTreeRegressor\\nfrom sklearn.linear_model import LinearRegression\\n\\nfrom sklearn.ensemble import (\\n    AdaBoostRegressor,\\n    GradientBoostingRegressor,\\n    RandomForestRegressor,\\n    BaggingRegressor,\\n)\\nfrom xgboost import XGBRegressor\\n\\n# To randomly split data, for cross validation, and to check model performance\\nfrom sklearn import metrics\\nfrom sklearn.model_selection import train_test_split, KFold, cross_val_score\\nfrom sklearn.metrics import (\\n    mean_absolute_error,\\n    mean_squared_error,\\n    r2_score,\\n    mean_absolute_percentage_error,\\n)\\n\\n# To be used for data scaling and one hot encoding\\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder\\n\\n# To be used for tuning the model\\nfrom sklearn.model_selection import GridSearchCV, RandomizedSearchCV\\n\\n# To be used for hyperparameter tuning searches\\nfrom scipy.stats import loguniform\\nfrom scipy.stats import uniform\\nfrom scipy.stats import expon\\n\\n# To be used for creating pipelines and personalizing them\\nfrom sklearn.pipeline import Pipeline\\nfrom sklearn.compose import ColumnTransformer\\n\\n# To define maximum number of columns to be displayed in a dataframe\\npd.set_option(\\\"display.max_columns\\\", None)\\n# To define the maximum number of rows to be displayed in a dataframe\\npd.set_option(\\\"display.max_rows\\\", 211)\\n\\n# To set some dataframe visualization attributes\\npd.set_option(\\\"max_colwidth\\\", 150)\\n\\n# To supress scientific notations for a dataframe\\n# pd.set_option(\\\"display.float_format\\\", lambda x: \\\"%.3f\\\" % x)\\n\\n# To supress warnings\\n# import warnings\\n\\n# warnings.filterwarnings(\\\"ignore\\\")\\n\\n# To set some plot visualization attributes\\nsns.set_theme()\\nsns.set(font_scale=1.4)\\nsns.set_palette(\\n    (\\n        \\\"midnightblue\\\",\\n        \\\"goldenrod\\\",\\n        \\\"maroon\\\",\\n        \\\"darkolivegreen\\\",\\n        \\\"cadetblue\\\",\\n        \\\"tab:purple\\\",\\n        \\\"yellowgreen\\\",\\n    )\\n)\\n# plt.rc(\\\"font\\\", size=12)\\n# plt.rc(\\\"axes\\\", titlesize=15)\\n# plt.rc(\\\"axes\\\", labelsize=14)\\n# plt.rc(\\\"xtick\\\", labelsize=13)\\n# plt.rc(\\\"ytick\\\", labelsize=13)\\n# plt.rc(\\\"legend\\\", fontsize=13)\\n# plt.rc(\\\"legend\\\", fontsize=14)\\n# plt.rc(\\\"figure\\\", titlesize=16)\\n\\n# To play auditory cue when cell has executed, has warning, or has error and set chime theme\\nimport chime\\n\\nchime.theme(\\\"zelda\\\")\";\n",
       "                var nbb_formatted_code = \"# To structure code automatically\\n%load_ext nb_black\\n\\n# To import/export sqlite databases\\n# import sqlite3 as sql\\n\\n# To save/open python objects in pickle file\\nimport pickle\\n\\n# To help with reading, cleaning, and manipulating data\\nimport pandas as pd\\nimport numpy as np\\n\\n# To help with data visualization\\nimport matplotlib.pyplot as plt\\nimport seaborn as sns\\n\\n# To be used for missing value imputation\\nfrom sklearn.impute import SimpleImputer\\n\\n# To help with model building\\nfrom sklearn.tree import DecisionTreeRegressor\\nfrom sklearn.linear_model import LinearRegression\\n\\nfrom sklearn.ensemble import (\\n    AdaBoostRegressor,\\n    GradientBoostingRegressor,\\n    RandomForestRegressor,\\n    BaggingRegressor,\\n)\\nfrom xgboost import XGBRegressor\\n\\n# To randomly split data, for cross validation, and to check model performance\\nfrom sklearn import metrics\\nfrom sklearn.model_selection import train_test_split, KFold, cross_val_score\\nfrom sklearn.metrics import (\\n    mean_absolute_error,\\n    mean_squared_error,\\n    r2_score,\\n    mean_absolute_percentage_error,\\n)\\n\\n# To be used for data scaling and one hot encoding\\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder\\n\\n# To be used for tuning the model\\nfrom sklearn.model_selection import GridSearchCV, RandomizedSearchCV\\n\\n# To be used for hyperparameter tuning searches\\nfrom scipy.stats import loguniform\\nfrom scipy.stats import uniform\\nfrom scipy.stats import expon\\n\\n# To be used for creating pipelines and personalizing them\\nfrom sklearn.pipeline import Pipeline\\nfrom sklearn.compose import ColumnTransformer\\n\\n# To define maximum number of columns to be displayed in a dataframe\\npd.set_option(\\\"display.max_columns\\\", None)\\n# To define the maximum number of rows to be displayed in a dataframe\\npd.set_option(\\\"display.max_rows\\\", 211)\\n\\n# To set some dataframe visualization attributes\\npd.set_option(\\\"max_colwidth\\\", 150)\\n\\n# To supress scientific notations for a dataframe\\n# pd.set_option(\\\"display.float_format\\\", lambda x: \\\"%.3f\\\" % x)\\n\\n# To supress warnings\\n# import warnings\\n\\n# warnings.filterwarnings(\\\"ignore\\\")\\n\\n# To set some plot visualization attributes\\nsns.set_theme()\\nsns.set(font_scale=1.4)\\nsns.set_palette(\\n    (\\n        \\\"midnightblue\\\",\\n        \\\"goldenrod\\\",\\n        \\\"maroon\\\",\\n        \\\"darkolivegreen\\\",\\n        \\\"cadetblue\\\",\\n        \\\"tab:purple\\\",\\n        \\\"yellowgreen\\\",\\n    )\\n)\\n# plt.rc(\\\"font\\\", size=12)\\n# plt.rc(\\\"axes\\\", titlesize=15)\\n# plt.rc(\\\"axes\\\", labelsize=14)\\n# plt.rc(\\\"xtick\\\", labelsize=13)\\n# plt.rc(\\\"ytick\\\", labelsize=13)\\n# plt.rc(\\\"legend\\\", fontsize=13)\\n# plt.rc(\\\"legend\\\", fontsize=14)\\n# plt.rc(\\\"figure\\\", titlesize=16)\\n\\n# To play auditory cue when cell has executed, has warning, or has error and set chime theme\\nimport chime\\n\\nchime.theme(\\\"zelda\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# To structure code automatically\n",
    "%load_ext nb_black\n",
    "\n",
    "# To import/export sqlite databases\n",
    "# import sqlite3 as sql\n",
    "\n",
    "# To save/open python objects in pickle file\n",
    "import pickle\n",
    "\n",
    "# To help with reading, cleaning, and manipulating data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# To help with data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# To be used for missing value imputation\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# To help with model building\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from sklearn.ensemble import (\n",
    "    AdaBoostRegressor,\n",
    "    GradientBoostingRegressor,\n",
    "    RandomForestRegressor,\n",
    "    BaggingRegressor,\n",
    ")\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# To randomly split data, for cross validation, and to check model performance\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.metrics import (\n",
    "    mean_absolute_error,\n",
    "    mean_squared_error,\n",
    "    r2_score,\n",
    "    mean_absolute_percentage_error,\n",
    ")\n",
    "\n",
    "# To be used for data scaling and one hot encoding\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder\n",
    "\n",
    "# To be used for tuning the model\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "# To be used for hyperparameter tuning searches\n",
    "from scipy.stats import loguniform\n",
    "from scipy.stats import uniform\n",
    "from scipy.stats import expon\n",
    "\n",
    "# To be used for creating pipelines and personalizing them\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# To define maximum number of columns to be displayed in a dataframe\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "# To define the maximum number of rows to be displayed in a dataframe\n",
    "pd.set_option(\"display.max_rows\", 211)\n",
    "\n",
    "# To set some dataframe visualization attributes\n",
    "pd.set_option(\"max_colwidth\", 150)\n",
    "\n",
    "# To supress scientific notations for a dataframe\n",
    "# pd.set_option(\"display.float_format\", lambda x: \"%.3f\" % x)\n",
    "\n",
    "# To supress warnings\n",
    "# import warnings\n",
    "\n",
    "# warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# To set some plot visualization attributes\n",
    "sns.set_theme()\n",
    "sns.set(font_scale=1.4)\n",
    "sns.set_palette(\n",
    "    (\n",
    "        \"midnightblue\",\n",
    "        \"goldenrod\",\n",
    "        \"maroon\",\n",
    "        \"darkolivegreen\",\n",
    "        \"cadetblue\",\n",
    "        \"tab:purple\",\n",
    "        \"yellowgreen\",\n",
    "    )\n",
    ")\n",
    "# plt.rc(\"font\", size=12)\n",
    "# plt.rc(\"axes\", titlesize=15)\n",
    "# plt.rc(\"axes\", labelsize=14)\n",
    "# plt.rc(\"xtick\", labelsize=13)\n",
    "# plt.rc(\"ytick\", labelsize=13)\n",
    "# plt.rc(\"legend\", fontsize=13)\n",
    "# plt.rc(\"legend\", fontsize=14)\n",
    "# plt.rc(\"figure\", titlesize=16)\n",
    "\n",
    "# To play auditory cue when cell has executed, has warning, or has error and set chime theme\n",
    "import chime\n",
    "\n",
    "chime.theme(\"zelda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc818a82",
   "metadata": {},
   "source": [
    "## Data Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed005f6",
   "metadata": {},
   "source": [
    "### [Reading](https://github.com/teresahanak/wikipedia-life-expectancy/blob/main/wp_life_expect_train_preproc.csv), Sampling, and Checking Data Shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ca58a95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 77624 rows and 20 columns.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_references</th>\n",
       "      <th>age</th>\n",
       "      <th>sciences</th>\n",
       "      <th>social</th>\n",
       "      <th>spiritual</th>\n",
       "      <th>academia_humanities</th>\n",
       "      <th>business_farming</th>\n",
       "      <th>arts</th>\n",
       "      <th>sports</th>\n",
       "      <th>law_enf_military_operator</th>\n",
       "      <th>politics_govt_law</th>\n",
       "      <th>crime</th>\n",
       "      <th>num_categories</th>\n",
       "      <th>age_sqrd</th>\n",
       "      <th>recip_num_references</th>\n",
       "      <th>years</th>\n",
       "      <th>years_sqrd</th>\n",
       "      <th>region</th>\n",
       "      <th>prior_region</th>\n",
       "      <th>known_for</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>73.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5329.0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>8</td>\n",
       "      <td>64</td>\n",
       "      <td>Europe</td>\n",
       "      <td>No Prior Region</td>\n",
       "      <td>spiritual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>90.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>8100.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>13</td>\n",
       "      <td>169</td>\n",
       "      <td>North America</td>\n",
       "      <td>No Prior Region</td>\n",
       "      <td>two</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_references   age  sciences  social  spiritual  academia_humanities  \\\n",
       "0               4  73.0         0       0          1                    0   \n",
       "1               3  90.0         1       0          0                    1   \n",
       "\n",
       "   business_farming  arts  sports  law_enf_military_operator  \\\n",
       "0                 0     0       0                          0   \n",
       "1                 0     0       0                          0   \n",
       "\n",
       "   politics_govt_law  crime  num_categories  age_sqrd  recip_num_references  \\\n",
       "0                  0      0               1    5329.0              0.250000   \n",
       "1                  0      0               2    8100.0              0.333333   \n",
       "\n",
       "   years  years_sqrd         region     prior_region  known_for  \n",
       "0      8          64         Europe  No Prior Region  spiritual  \n",
       "1     13         169  North America  No Prior Region        two  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2;\n",
       "                var nbb_unformatted_code = \"# Reading the dataset\\ndata = pd.read_csv(\\\"wp_life_expect_train_preproc.csv\\\")\\n\\n# Making a working copy\\ndf = data.copy()\\n\\n# Checking the shape\\nprint(f\\\"There are {df.shape[0]} rows and {df.shape[1]} columns.\\\")\\n\\n# Checking first 2 rows of the data\\ndf.head(2)\";\n",
       "                var nbb_formatted_code = \"# Reading the dataset\\ndata = pd.read_csv(\\\"wp_life_expect_train_preproc.csv\\\")\\n\\n# Making a working copy\\ndf = data.copy()\\n\\n# Checking the shape\\nprint(f\\\"There are {df.shape[0]} rows and {df.shape[1]} columns.\\\")\\n\\n# Checking first 2 rows of the data\\ndf.head(2)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Reading the dataset\n",
    "data = pd.read_csv(\"wp_life_expect_train_preproc.csv\")\n",
    "\n",
    "# Making a working copy\n",
    "df = data.copy()\n",
    "\n",
    "# Checking the shape\n",
    "print(f\"There are {df.shape[0]} rows and {df.shape[1]} columns.\")\n",
    "\n",
    "# Checking first 2 rows of the data\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6cca416f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_references</th>\n",
       "      <th>age</th>\n",
       "      <th>sciences</th>\n",
       "      <th>social</th>\n",
       "      <th>spiritual</th>\n",
       "      <th>academia_humanities</th>\n",
       "      <th>business_farming</th>\n",
       "      <th>arts</th>\n",
       "      <th>sports</th>\n",
       "      <th>law_enf_military_operator</th>\n",
       "      <th>politics_govt_law</th>\n",
       "      <th>crime</th>\n",
       "      <th>num_categories</th>\n",
       "      <th>age_sqrd</th>\n",
       "      <th>recip_num_references</th>\n",
       "      <th>years</th>\n",
       "      <th>years_sqrd</th>\n",
       "      <th>region</th>\n",
       "      <th>prior_region</th>\n",
       "      <th>known_for</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>77622</th>\n",
       "      <td>7</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5476.0</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>North America</td>\n",
       "      <td>No Prior Region</td>\n",
       "      <td>arts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77623</th>\n",
       "      <td>5</td>\n",
       "      <td>92.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8464.0</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>8</td>\n",
       "      <td>64</td>\n",
       "      <td>Europe</td>\n",
       "      <td>No Prior Region</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       num_references   age  sciences  social  spiritual  academia_humanities  \\\n",
       "77622               7  74.0         0       0          0                    0   \n",
       "77623               5  92.0         0       0          0                    0   \n",
       "\n",
       "       business_farming  arts  sports  law_enf_military_operator  \\\n",
       "77622                 0     1       0                          0   \n",
       "77623                 0     0       1                          0   \n",
       "\n",
       "       politics_govt_law  crime  num_categories  age_sqrd  \\\n",
       "77622                  0      0               1    5476.0   \n",
       "77623                  0      0               1    8464.0   \n",
       "\n",
       "       recip_num_references  years  years_sqrd         region  \\\n",
       "77622              0.142857      0           0  North America   \n",
       "77623              0.200000      8          64         Europe   \n",
       "\n",
       "          prior_region known_for  \n",
       "77622  No Prior Region      arts  \n",
       "77623  No Prior Region    sports  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 3;\n",
       "                var nbb_unformatted_code = \"# Checking last 2 rows of the data\\ndf.tail(2)\";\n",
       "                var nbb_formatted_code = \"# Checking last 2 rows of the data\\ndf.tail(2)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Checking last 2 rows of the data\n",
    "df.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de6e8ee5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_references</th>\n",
       "      <th>age</th>\n",
       "      <th>sciences</th>\n",
       "      <th>social</th>\n",
       "      <th>spiritual</th>\n",
       "      <th>academia_humanities</th>\n",
       "      <th>business_farming</th>\n",
       "      <th>arts</th>\n",
       "      <th>sports</th>\n",
       "      <th>law_enf_military_operator</th>\n",
       "      <th>politics_govt_law</th>\n",
       "      <th>crime</th>\n",
       "      <th>num_categories</th>\n",
       "      <th>age_sqrd</th>\n",
       "      <th>recip_num_references</th>\n",
       "      <th>years</th>\n",
       "      <th>years_sqrd</th>\n",
       "      <th>region</th>\n",
       "      <th>prior_region</th>\n",
       "      <th>known_for</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>77572</th>\n",
       "      <td>4</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>13</td>\n",
       "      <td>169</td>\n",
       "      <td>Oceania</td>\n",
       "      <td>No Prior Region</td>\n",
       "      <td>arts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2586</th>\n",
       "      <td>3</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5625.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>15</td>\n",
       "      <td>225</td>\n",
       "      <td>North America</td>\n",
       "      <td>Africa</td>\n",
       "      <td>arts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17106</th>\n",
       "      <td>18</td>\n",
       "      <td>73.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5329.0</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>Europe</td>\n",
       "      <td>No Prior Region</td>\n",
       "      <td>law_enf_military_operator</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50426</th>\n",
       "      <td>4</td>\n",
       "      <td>79.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6241.0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>27</td>\n",
       "      <td>729</td>\n",
       "      <td>Europe</td>\n",
       "      <td>No Prior Region</td>\n",
       "      <td>politics_govt_law</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69097</th>\n",
       "      <td>3</td>\n",
       "      <td>93.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8649.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>21</td>\n",
       "      <td>441</td>\n",
       "      <td>North America</td>\n",
       "      <td>No Prior Region</td>\n",
       "      <td>arts</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       num_references   age  sciences  social  spiritual  academia_humanities  \\\n",
       "77572               4  50.0         0       0          0                    0   \n",
       "2586                3  75.0         0       0          0                    0   \n",
       "17106              18  73.0         0       0          0                    0   \n",
       "50426               4  79.0         0       0          0                    0   \n",
       "69097               3  93.0         0       0          0                    0   \n",
       "\n",
       "       business_farming  arts  sports  law_enf_military_operator  \\\n",
       "77572                 0     1       0                          0   \n",
       "2586                  0     1       0                          0   \n",
       "17106                 0     0       0                          1   \n",
       "50426                 0     0       0                          0   \n",
       "69097                 0     1       0                          0   \n",
       "\n",
       "       politics_govt_law  crime  num_categories  age_sqrd  \\\n",
       "77572                  0      0               1    2500.0   \n",
       "2586                   0      0               1    5625.0   \n",
       "17106                  0      0               1    5329.0   \n",
       "50426                  1      0               1    6241.0   \n",
       "69097                  0      0               1    8649.0   \n",
       "\n",
       "       recip_num_references  years  years_sqrd         region  \\\n",
       "77572              0.250000     13         169        Oceania   \n",
       "2586               0.333333     15         225  North America   \n",
       "17106              0.055556      3           9         Europe   \n",
       "50426              0.250000     27         729         Europe   \n",
       "69097              0.333333     21         441  North America   \n",
       "\n",
       "          prior_region                  known_for  \n",
       "77572  No Prior Region                       arts  \n",
       "2586            Africa                       arts  \n",
       "17106  No Prior Region  law_enf_military_operator  \n",
       "50426  No Prior Region          politics_govt_law  \n",
       "69097  No Prior Region                       arts  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 4;\n",
       "                var nbb_unformatted_code = \"# Checking a sample of the data\\ndf.sample(5)\";\n",
       "                var nbb_formatted_code = \"# Checking a sample of the data\\ndf.sample(5)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Checking a sample of the data\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d5f29da",
   "metadata": {},
   "source": [
    "### Checking Data Types and Null Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf505f87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 77624 entries, 0 to 77623\n",
      "Data columns (total 20 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   num_references             77624 non-null  int64  \n",
      " 1   age                        77624 non-null  float64\n",
      " 2   sciences                   77624 non-null  int64  \n",
      " 3   social                     77624 non-null  int64  \n",
      " 4   spiritual                  77624 non-null  int64  \n",
      " 5   academia_humanities        77624 non-null  int64  \n",
      " 6   business_farming           77624 non-null  int64  \n",
      " 7   arts                       77624 non-null  int64  \n",
      " 8   sports                     77624 non-null  int64  \n",
      " 9   law_enf_military_operator  77624 non-null  int64  \n",
      " 10  politics_govt_law          77624 non-null  int64  \n",
      " 11  crime                      77624 non-null  int64  \n",
      " 12  num_categories             77624 non-null  int64  \n",
      " 13  age_sqrd                   77624 non-null  float64\n",
      " 14  recip_num_references       77624 non-null  float64\n",
      " 15  years                      77624 non-null  int64  \n",
      " 16  years_sqrd                 77624 non-null  int64  \n",
      " 17  region                     77624 non-null  object \n",
      " 18  prior_region               77624 non-null  object \n",
      " 19  known_for                  77624 non-null  object \n",
      "dtypes: float64(3), int64(14), object(3)\n",
      "memory usage: 11.8+ MB\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 5;\n",
       "                var nbb_unformatted_code = \"# Checking data types and null values\\ndf.info()\";\n",
       "                var nbb_formatted_code = \"# Checking data types and null values\\ndf.info()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Checking data types and null values\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c459d7f8",
   "metadata": {},
   "source": [
    "#### Observations:\n",
    "- With our dataset loaded, we are ready for modeling.\n",
    "- We have three variables that need typcasting from object to category, then one hot encoding just prior to modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bdf2565",
   "metadata": {},
   "source": [
    "#### Typecasting `region`, `prior_region`, and `known_for` as Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2aef3f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 77624 entries, 0 to 77623\n",
      "Data columns (total 20 columns):\n",
      " #   Column                     Non-Null Count  Dtype   \n",
      "---  ------                     --------------  -----   \n",
      " 0   num_references             77624 non-null  int64   \n",
      " 1   age                        77624 non-null  float64 \n",
      " 2   sciences                   77624 non-null  int64   \n",
      " 3   social                     77624 non-null  int64   \n",
      " 4   spiritual                  77624 non-null  int64   \n",
      " 5   academia_humanities        77624 non-null  int64   \n",
      " 6   business_farming           77624 non-null  int64   \n",
      " 7   arts                       77624 non-null  int64   \n",
      " 8   sports                     77624 non-null  int64   \n",
      " 9   law_enf_military_operator  77624 non-null  int64   \n",
      " 10  politics_govt_law          77624 non-null  int64   \n",
      " 11  crime                      77624 non-null  int64   \n",
      " 12  num_categories             77624 non-null  int64   \n",
      " 13  age_sqrd                   77624 non-null  float64 \n",
      " 14  recip_num_references       77624 non-null  float64 \n",
      " 15  years                      77624 non-null  int64   \n",
      " 16  years_sqrd                 77624 non-null  int64   \n",
      " 17  region                     77624 non-null  category\n",
      " 18  prior_region               77624 non-null  category\n",
      " 19  known_for                  77624 non-null  category\n",
      "dtypes: category(3), float64(3), int64(14)\n",
      "memory usage: 10.3 MB\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 6;\n",
       "                var nbb_unformatted_code = \"# Typcasting prior_region and region as categorical\\ndf[[\\\"prior_region\\\", \\\"region\\\", \\\"known_for\\\"]] = df[\\n    [\\\"prior_region\\\", \\\"region\\\", \\\"known_for\\\"]\\n].astype(\\\"category\\\")\\n\\n# Re-check info\\ndf.info()\";\n",
       "                var nbb_formatted_code = \"# Typcasting prior_region and region as categorical\\ndf[[\\\"prior_region\\\", \\\"region\\\", \\\"known_for\\\"]] = df[\\n    [\\\"prior_region\\\", \\\"region\\\", \\\"known_for\\\"]\\n].astype(\\\"category\\\")\\n\\n# Re-check info\\ndf.info()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Typcasting prior_region and region as categorical\n",
    "df[[\"prior_region\", \"region\", \"known_for\"]] = df[\n",
    "    [\"prior_region\", \"region\", \"known_for\"]\n",
    "].astype(\"category\")\n",
    "\n",
    "# Re-check info\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1eafaa",
   "metadata": {},
   "source": [
    "## Data Preparation for Modeling\n",
    "In contrast to building the [linear regression model](https://github.com/teresahanak/wikipedia-life-expectancy/blob/main/wp_life_expect_olsmodel_thanak_2022_10_9.ipynb), we will be tuning these models.  So, we will split the train set into train and validation sets and utilize the `test` set only to check out-of-sample performance of the champion model.  We will load and treat the test set at that point."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef2eaa0",
   "metadata": {},
   "source": [
    "### Defining Independent and Dependent Variables for Train and Validation Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "71fbe26e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 54336 rows and 34 columns in the train set.\n",
      "\n",
      "There are 23288 rows and 34 columns in the validation set.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_references</th>\n",
       "      <th>years</th>\n",
       "      <th>region_Asia</th>\n",
       "      <th>region_Central Asia</th>\n",
       "      <th>region_Europe</th>\n",
       "      <th>region_Mid-Cent America/Caribbean</th>\n",
       "      <th>region_Middle East</th>\n",
       "      <th>region_North America</th>\n",
       "      <th>region_Oceania</th>\n",
       "      <th>region_Russian Federation</th>\n",
       "      <th>region_South America</th>\n",
       "      <th>region_South East Asia</th>\n",
       "      <th>prior_region_Asia</th>\n",
       "      <th>prior_region_Central Asia</th>\n",
       "      <th>prior_region_Europe</th>\n",
       "      <th>prior_region_Mid-Cent America/Caribbean</th>\n",
       "      <th>prior_region_Middle East</th>\n",
       "      <th>prior_region_No Prior Region</th>\n",
       "      <th>prior_region_North America</th>\n",
       "      <th>prior_region_Oceania</th>\n",
       "      <th>prior_region_Russian Federation</th>\n",
       "      <th>prior_region_South America</th>\n",
       "      <th>prior_region_South East Asia</th>\n",
       "      <th>known_for_arts</th>\n",
       "      <th>known_for_business_farming</th>\n",
       "      <th>known_for_crime</th>\n",
       "      <th>known_for_law_enf_military_operator</th>\n",
       "      <th>known_for_politics_govt_law</th>\n",
       "      <th>known_for_sciences</th>\n",
       "      <th>known_for_social</th>\n",
       "      <th>known_for_spiritual</th>\n",
       "      <th>known_for_sports</th>\n",
       "      <th>known_for_three_to_five</th>\n",
       "      <th>known_for_two</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7948</th>\n",
       "      <td>38.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      num_references  years  region_Asia  region_Central Asia  region_Europe  \\\n",
       "7948            38.0   25.0          0.0                  0.0            1.0   \n",
       "\n",
       "      region_Mid-Cent America/Caribbean  region_Middle East  \\\n",
       "7948                                0.0                 0.0   \n",
       "\n",
       "      region_North America  region_Oceania  region_Russian Federation  \\\n",
       "7948                   0.0             0.0                        0.0   \n",
       "\n",
       "      region_South America  region_South East Asia  prior_region_Asia  \\\n",
       "7948                   0.0                     0.0                0.0   \n",
       "\n",
       "      prior_region_Central Asia  prior_region_Europe  \\\n",
       "7948                        0.0                  0.0   \n",
       "\n",
       "      prior_region_Mid-Cent America/Caribbean  prior_region_Middle East  \\\n",
       "7948                                      0.0                       0.0   \n",
       "\n",
       "      prior_region_No Prior Region  prior_region_North America  \\\n",
       "7948                           1.0                         0.0   \n",
       "\n",
       "      prior_region_Oceania  prior_region_Russian Federation  \\\n",
       "7948                   0.0                              0.0   \n",
       "\n",
       "      prior_region_South America  prior_region_South East Asia  \\\n",
       "7948                         0.0                           0.0   \n",
       "\n",
       "      known_for_arts  known_for_business_farming  known_for_crime  \\\n",
       "7948             0.0                         0.0              0.0   \n",
       "\n",
       "      known_for_law_enf_military_operator  known_for_politics_govt_law  \\\n",
       "7948                                  0.0                          0.0   \n",
       "\n",
       "      known_for_sciences  known_for_social  known_for_spiritual  \\\n",
       "7948                 0.0               0.0                  0.0   \n",
       "\n",
       "      known_for_sports  known_for_three_to_five  known_for_two  \n",
       "7948               1.0                      0.0            0.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 7;\n",
       "                var nbb_unformatted_code = \"# Creating list of predictor columns\\npredictor_cols = [\\n    \\\"num_references\\\",\\n    \\\"years\\\",\\n    \\\"region\\\",\\n    \\\"prior_region\\\",\\n    \\\"known_for\\\",\\n]\\n\\n# Defining target column\\ntarget = \\\"age\\\"\\n\\n# Defining independent and dependent variables\\nX = df[predictor_cols]\\ny = df[target]\\n\\n# One hot encoding of categorical predictors and typecasting all predictors as float\\nX = pd.get_dummies(X, drop_first=True).astype(\\\"float64\\\")\\n\\n# Splitting into 70:30 train and validation sets\\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=42)\\n\\n# Checking shape of train and validation sets\\nprint(\\n    f\\\"There are {X_train.shape[0]} rows and {X_train.shape[1]} columns in the train set.\\\\n\\\"\\n)\\nprint(\\n    f\\\"There are {X_val.shape[0]} rows and {X_val.shape[1]} columns in the validation set.\\\\n\\\"\\n)\\n\\n# Checking a sample\\nX_train.sample()\";\n",
       "                var nbb_formatted_code = \"# Creating list of predictor columns\\npredictor_cols = [\\n    \\\"num_references\\\",\\n    \\\"years\\\",\\n    \\\"region\\\",\\n    \\\"prior_region\\\",\\n    \\\"known_for\\\",\\n]\\n\\n# Defining target column\\ntarget = \\\"age\\\"\\n\\n# Defining independent and dependent variables\\nX = df[predictor_cols]\\ny = df[target]\\n\\n# One hot encoding of categorical predictors and typecasting all predictors as float\\nX = pd.get_dummies(X, drop_first=True).astype(\\\"float64\\\")\\n\\n# Splitting into 70:30 train and validation sets\\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=42)\\n\\n# Checking shape of train and validation sets\\nprint(\\n    f\\\"There are {X_train.shape[0]} rows and {X_train.shape[1]} columns in the train set.\\\\n\\\"\\n)\\nprint(\\n    f\\\"There are {X_val.shape[0]} rows and {X_val.shape[1]} columns in the validation set.\\\\n\\\"\\n)\\n\\n# Checking a sample\\nX_train.sample()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Creating list of predictor columns\n",
    "predictor_cols = [\n",
    "    \"num_references\",\n",
    "    \"years\",\n",
    "    \"region\",\n",
    "    \"prior_region\",\n",
    "    \"known_for\",\n",
    "]\n",
    "\n",
    "# Defining target column\n",
    "target = \"age\"\n",
    "\n",
    "# Defining independent and dependent variables\n",
    "X = df[predictor_cols]\n",
    "y = df[target]\n",
    "\n",
    "# One hot encoding of categorical predictors and typecasting all predictors as float\n",
    "X = pd.get_dummies(X, drop_first=True).astype(\"float64\")\n",
    "\n",
    "# Splitting into 70:30 train and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Checking shape of train and validation sets\n",
    "print(\n",
    "    f\"There are {X_train.shape[0]} rows and {X_train.shape[1]} columns in the train set.\\n\"\n",
    ")\n",
    "print(\n",
    "    f\"There are {X_val.shape[0]} rows and {X_val.shape[1]} columns in the validation set.\\n\"\n",
    ")\n",
    "\n",
    "# Checking a sample\n",
    "X_train.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318bcc3d",
   "metadata": {},
   "source": [
    "## Model Building\n",
    "#### Model Evaluation Criterion\n",
    "The predictions made by the regressors will have the following performance metrics:\n",
    "- RMSE\n",
    "- MAE\n",
    "- R$^2$\n",
    "- Ajusted R$^2$\n",
    "- MAPE\n",
    "\n",
    "#### Which Metric to Optimize?\n",
    "- For hyperparameter tuning, we will optimize R$^2$, which is the proportion of variation in the target that is explained by the predictors.  \n",
    "\n",
    "- To select the champion model, will compare Adjusted R$^2$.  It is the metric that represents the amount of variation in the target that is explained by the predictors, with a penalty for more predictors.  The number of included predictors may vary between algorithms, especially as we are building including examples of decion tree regressors.  R$^2$ will improve with the addition of predictors, even if they contribute very little to the model, whereas, the penalty in Adjusted R$^2$ offsets such an increase."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bdb1386",
   "metadata": {},
   "source": [
    "#### Functions for Checking and Tuning Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e40e3f27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 8;\n",
       "                var nbb_unformatted_code = \"# Function to compute adjusted R-squared\\ndef adj_r2_score(predictors, targets, predictions):\\n    r2 = r2_score(targets, predictions)\\n    n = predictors.shape[0]\\n    k = predictors.shape[1]\\n    return 1 - ((1 - r2) * (n - 1) / (n - k - 1))\\n\\n\\n# Function to compute MAPE\\ndef mape_score(targets, predictions):\\n    return np.mean(np.abs((targets - predictions) / targets)) * 100\\n\\n\\n# Function to compute and display different metrics to check performance of a regression model\\ndef model_performance_regression(model, predictors, target):\\n    \\\"\\\"\\\"\\n    Function to compute and return a dataframe of different metrics to check\\n    regression model performance\\n    \\n    model: regressor\\n    predictors: independent variables\\n    target: dependent variable\\n    \\\"\\\"\\\"\\n    # Predictions\\n    pred = model.predict(predictors)\\n\\n    r2 = r2_score(target, pred)  # To compute R-squared\\n    adjr2 = adj_r2_score(predictors, target, pred)  # To compute adjusted R-squared\\n    rmse = np.sqrt(mean_squared_error(target, pred))  # To compute RMSE\\n    mae = mean_absolute_error(target, pred)  # To compute MAE\\n    mape = mape_score(target, pred)  # To compute MAPE\\n\\n    # Creating a dataframe of metrics\\n    df_perf = pd.DataFrame(\\n        {\\n            \\\"RMSE\\\": rmse,\\n            \\\"MAE\\\": mae,\\n            \\\"R-squared\\\": r2,\\n            \\\"Adj. R-squared\\\": adjr2,\\n            \\\"MAPE\\\": mape,\\n        },\\n        index=[0],\\n    )\\n\\n    return df_perf\";\n",
       "                var nbb_formatted_code = \"# Function to compute adjusted R-squared\\ndef adj_r2_score(predictors, targets, predictions):\\n    r2 = r2_score(targets, predictions)\\n    n = predictors.shape[0]\\n    k = predictors.shape[1]\\n    return 1 - ((1 - r2) * (n - 1) / (n - k - 1))\\n\\n\\n# Function to compute MAPE\\ndef mape_score(targets, predictions):\\n    return np.mean(np.abs((targets - predictions) / targets)) * 100\\n\\n\\n# Function to compute and display different metrics to check performance of a regression model\\ndef model_performance_regression(model, predictors, target):\\n    \\\"\\\"\\\"\\n    Function to compute and return a dataframe of different metrics to check\\n    regression model performance\\n    \\n    model: regressor\\n    predictors: independent variables\\n    target: dependent variable\\n    \\\"\\\"\\\"\\n    # Predictions\\n    pred = model.predict(predictors)\\n\\n    r2 = r2_score(target, pred)  # To compute R-squared\\n    adjr2 = adj_r2_score(predictors, target, pred)  # To compute adjusted R-squared\\n    rmse = np.sqrt(mean_squared_error(target, pred))  # To compute RMSE\\n    mae = mean_absolute_error(target, pred)  # To compute MAE\\n    mape = mape_score(target, pred)  # To compute MAPE\\n\\n    # Creating a dataframe of metrics\\n    df_perf = pd.DataFrame(\\n        {\\n            \\\"RMSE\\\": rmse,\\n            \\\"MAE\\\": mae,\\n            \\\"R-squared\\\": r2,\\n            \\\"Adj. R-squared\\\": adjr2,\\n            \\\"MAPE\\\": mape,\\n        },\\n        index=[0],\\n    )\\n\\n    return df_perf\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Function to compute adjusted R-squared\n",
    "def adj_r2_score(predictors, targets, predictions):\n",
    "    r2 = r2_score(targets, predictions)\n",
    "    n = predictors.shape[0]\n",
    "    k = predictors.shape[1]\n",
    "    return 1 - ((1 - r2) * (n - 1) / (n - k - 1))\n",
    "\n",
    "\n",
    "# Function to compute MAPE\n",
    "def mape_score(targets, predictions):\n",
    "    return np.mean(np.abs((targets - predictions) / targets)) * 100\n",
    "\n",
    "\n",
    "# Function to compute and display different metrics to check performance of a regression model\n",
    "def model_performance_regression(model, predictors, target):\n",
    "    \"\"\"\n",
    "    Function to compute and return a dataframe of different metrics to check\n",
    "    regression model performance\n",
    "    \n",
    "    model: regressor\n",
    "    predictors: independent variables\n",
    "    target: dependent variable\n",
    "    \"\"\"\n",
    "    # Predictions\n",
    "    pred = model.predict(predictors)\n",
    "\n",
    "    r2 = r2_score(target, pred)  # To compute R-squared\n",
    "    adjr2 = adj_r2_score(predictors, target, pred)  # To compute adjusted R-squared\n",
    "    rmse = np.sqrt(mean_squared_error(target, pred))  # To compute RMSE\n",
    "    mae = mean_absolute_error(target, pred)  # To compute MAE\n",
    "    mape = mape_score(target, pred)  # To compute MAPE\n",
    "\n",
    "    # Creating a dataframe of metrics\n",
    "    df_perf = pd.DataFrame(\n",
    "        {\n",
    "            \"RMSE\": rmse,\n",
    "            \"MAE\": mae,\n",
    "            \"R-squared\": r2,\n",
    "            \"Adj. R-squared\": adjr2,\n",
    "            \"MAPE\": mape,\n",
    "        },\n",
    "        index=[0],\n",
    "    )\n",
    "\n",
    "    return df_perf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc98943",
   "metadata": {},
   "source": [
    "#### Defining Scorer for Cross-validation and Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea396d00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 9;\n",
       "                var nbb_unformatted_code = \"# Type of scoring used to compare parameter combinations--maximizing Adj R-squared\\nscorer = \\\"r2\\\"\";\n",
       "                var nbb_formatted_code = \"# Type of scoring used to compare parameter combinations--maximizing Adj R-squared\\nscorer = \\\"r2\\\"\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Type of scoring used to compare parameter combinations--maximizing Adj R-squared\n",
    "scorer = \"r2\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef465812",
   "metadata": {},
   "source": [
    "### Building the Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "294e79f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cross-Validation:\n",
      "\n",
      "Dtree: -0.3729288388785845\n",
      "Random Forest: -0.06498999161620542\n",
      "Bagging Dtree: -0.09780574269930184\n",
      "GBM: 0.10092407348408765\n",
      "AdaBoost Dtree: -0.041942386214516916\n",
      "XGB_gbtree: 0.08816799208071073\n",
      "XGB_gblinear: 0.08269567222231555\n",
      "\n",
      "Validation Performance:\n",
      "\n",
      "Dtree: -0.3725798827812159\n",
      "Random Forest: -0.06593088660036917\n",
      "Bagging Dtree: -0.09925861808350978\n",
      "GBM: 0.10355465508610728\n",
      "AdaBoost Dtree: -0.05608653156428711\n",
      "XGB_gbtree: 0.09146574210948322\n",
      "XGB_gblinear: 0.08675545468855927\n",
      "CPU times: total: 3min 9s\n",
      "Wall time: 1min 5s\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 10;\n",
       "                var nbb_unformatted_code = \"%%time\\n\\n# Creating list to store the models\\nmodels = []\\n\\n# Appending models to the list\\nmodels.append(('Dtree', DecisionTreeRegressor(random_state=42)))\\n\\nmodels.append(('Random Forest', RandomForestRegressor(random_state=42)))\\n\\nmodels.append(('Bagging Dtree', BaggingRegressor(random_state=42)))\\n\\nmodels.append(('GBM', GradientBoostingRegressor(random_state=42)))\\n\\nmodels.append(('AdaBoost Dtree', AdaBoostRegressor(random_state=42)))\\n\\nmodels.append(('XGB_gbtree', XGBRegressor(random_state=42)))\\n\\nmodels.append(('XGB_gblinear', XGBRegressor(random_state=42, booster='gblinear')))\\n\\n# Create empty list to store all model's names and CV scores\\nnames = []\\nresults = []\\n\\n# Loop through all models to get the mean cross validated score\\nprint(\\\"\\\\n\\\" \\\"Cross-Validation:\\\" \\\"\\\\n\\\")\\n\\nfor name, model in models:\\n    cv_result = cross_val_score(\\n        estimator=model, X=X_train, y=y_train, scoring=scorer, cv=5\\n    )\\n    results.append(cv_result)\\n    names.append(name)\\n    print(f\\\"{name}: {cv_result.mean()}\\\")\\n    \\nprint(\\\"\\\\n\\\" \\\"Validation Performance:\\\" \\\"\\\\n\\\")\\n\\nfor name, model in models:\\n    model.fit(X_train, y_train)\\n    scores = r2_score(y_val, model.predict(X_val))\\n    print(\\\"{}: {}\\\".format(name, scores))\";\n",
       "                var nbb_formatted_code = \"%%time\\n\\n# Creating list to store the models\\nmodels = []\\n\\n# Appending models to the list\\nmodels.append(('Dtree', DecisionTreeRegressor(random_state=42)))\\n\\nmodels.append(('Random Forest', RandomForestRegressor(random_state=42)))\\n\\nmodels.append(('Bagging Dtree', BaggingRegressor(random_state=42)))\\n\\nmodels.append(('GBM', GradientBoostingRegressor(random_state=42)))\\n\\nmodels.append(('AdaBoost Dtree', AdaBoostRegressor(random_state=42)))\\n\\nmodels.append(('XGB_gbtree', XGBRegressor(random_state=42)))\\n\\nmodels.append(('XGB_gblinear', XGBRegressor(random_state=42, booster='gblinear')))\\n\\n# Create empty list to store all model's names and CV scores\\nnames = []\\nresults = []\\n\\n# Loop through all models to get the mean cross validated score\\nprint(\\\"\\\\n\\\" \\\"Cross-Validation:\\\" \\\"\\\\n\\\")\\n\\nfor name, model in models:\\n    cv_result = cross_val_score(\\n        estimator=model, X=X_train, y=y_train, scoring=scorer, cv=5\\n    )\\n    results.append(cv_result)\\n    names.append(name)\\n    print(f\\\"{name}: {cv_result.mean()}\\\")\\n    \\nprint(\\\"\\\\n\\\" \\\"Validation Performance:\\\" \\\"\\\\n\\\")\\n\\nfor name, model in models:\\n    model.fit(X_train, y_train)\\n    scores = r2_score(y_val, model.predict(X_val))\\n    print(\\\"{}: {}\\\".format(name, scores))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Creating list to store the models\n",
    "models = []\n",
    "\n",
    "# Appending models to the list\n",
    "models.append(('Dtree', DecisionTreeRegressor(random_state=42)))\n",
    "\n",
    "models.append(('Random Forest', RandomForestRegressor(random_state=42)))\n",
    "\n",
    "models.append(('Bagging Dtree', BaggingRegressor(random_state=42)))\n",
    "\n",
    "models.append(('GBM', GradientBoostingRegressor(random_state=42)))\n",
    "\n",
    "models.append(('AdaBoost Dtree', AdaBoostRegressor(random_state=42)))\n",
    "\n",
    "models.append(('XGB_gbtree', XGBRegressor(random_state=42)))\n",
    "\n",
    "models.append(('XGB_gblinear', XGBRegressor(random_state=42, booster='gblinear')))\n",
    "\n",
    "# Create empty list to store all model's names and CV scores\n",
    "names = []\n",
    "results = []\n",
    "\n",
    "# Loop through all models to get the mean cross validated score\n",
    "print(\"\\n\" \"Cross-Validation:\" \"\\n\")\n",
    "\n",
    "for name, model in models:\n",
    "    cv_result = cross_val_score(\n",
    "        estimator=model, X=X_train, y=y_train, scoring=scorer, cv=5\n",
    "    )\n",
    "    results.append(cv_result)\n",
    "    names.append(name)\n",
    "    print(f\"{name}: {cv_result.mean()}\")\n",
    "    \n",
    "print(\"\\n\" \"Validation Performance:\" \"\\n\")\n",
    "\n",
    "for name, model in models:\n",
    "    model.fit(X_train, y_train)\n",
    "    scores = r2_score(y_val, model.predict(X_val))\n",
    "    print(\"{}: {}\".format(name, scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2f009f68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x504 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 11;\n",
       "                var nbb_unformatted_code = \"# Plotting boxplots for CV scores of all models defined above\\nfig = plt.figure(figsize=(20, 7))\\n\\nfig.suptitle(\\\"Algorithm Comparison for Cross-validation R-squared Score\\\")\\nax = fig.add_subplot(111)\\n\\nplt.boxplot(results)\\nax.set_xticklabels(names)\\nplt.xticks(rotation=30)\\n\\nplt.show()\";\n",
       "                var nbb_formatted_code = \"# Plotting boxplots for CV scores of all models defined above\\nfig = plt.figure(figsize=(20, 7))\\n\\nfig.suptitle(\\\"Algorithm Comparison for Cross-validation R-squared Score\\\")\\nax = fig.add_subplot(111)\\n\\nplt.boxplot(results)\\nax.set_xticklabels(names)\\nplt.xticks(rotation=30)\\n\\nplt.show()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting boxplots for CV scores of all models defined above\n",
    "fig = plt.figure(figsize=(20, 7))\n",
    "\n",
    "fig.suptitle(\"Algorithm Comparison for Cross-validation R-squared Score\")\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "plt.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "plt.xticks(rotation=30)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31587e35",
   "metadata": {},
   "source": [
    "#### Observations:\n",
    "- We have negative R$^2$ values for four of the models.  This means they are performing worse than a model that merely equates the predicted values to the constant mean value of the target.\n",
    "- The remaining three models, *GBM*, *XGB_gbtree*, and *XGB_gblinear* are giving generalized performances on train and validation sets, with similar, albeit very low, R$^2$ scores as [*olsmodel3*](https://github.com/teresahanak/wikipedia-life-expectancy/blob/main/wp_life_expect_olsmodel_thanak_2022_10_9.ipynb) (0.087).  Before hyperparameter tuning, *GBM* is outperforming the other models, including *olsmodel3*, with both train and validation R$^2$ scores of ~0.10.\n",
    "- We will perform hyperparameter tuning on the top 3 models.  Purely as an exercise we will also keep *Random Forest* in the mix."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70e8a88",
   "metadata": {},
   "source": [
    "#### Collecting Models with Best Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d7591d99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 12;\n",
       "                var nbb_unformatted_code = \"# List of top models so far\\ntop_models = [models[1]] + [models[3]] + models[-2:]\";\n",
       "                var nbb_formatted_code = \"# List of top models so far\\ntop_models = [models[1]] + [models[3]] + models[-2:]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# List of top models so far\n",
    "top_models = [models[1]] + [models[3]] + models[-2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93e521f",
   "metadata": {},
   "source": [
    "#### Creating Dataframes to Compare Training and Validation Performance of Best Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4d39e401",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 13;\n",
       "                var nbb_unformatted_code = \"# Creating empty dictionary to hold the models\\nmodels_to_tune = {}\\n\\n# For loop to add models to dictionary\\nfor model in top_models:\\n    key = model[0]\\n    value = model[1]\\n    models_to_tune[key] = value\\n\\n# Initializing dataframes to compare performance of all models\\nmodels_train_comp_df = pd.DataFrame()\\nmodels_val_comp_df = pd.DataFrame()\\n\\n# For loop to add performance results of each top model\\nfor name, model in models_to_tune.items():\\n    models_train_comp_df[name] = model_performance_regression(model, X_train, y_train).T\\n    models_val_comp_df[name] = model_performance_regression(model, X_val, y_val).T\";\n",
       "                var nbb_formatted_code = \"# Creating empty dictionary to hold the models\\nmodels_to_tune = {}\\n\\n# For loop to add models to dictionary\\nfor model in top_models:\\n    key = model[0]\\n    value = model[1]\\n    models_to_tune[key] = value\\n\\n# Initializing dataframes to compare performance of all models\\nmodels_train_comp_df = pd.DataFrame()\\nmodels_val_comp_df = pd.DataFrame()\\n\\n# For loop to add performance results of each top model\\nfor name, model in models_to_tune.items():\\n    models_train_comp_df[name] = model_performance_regression(model, X_train, y_train).T\\n    models_val_comp_df[name] = model_performance_regression(model, X_val, y_val).T\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Creating empty dictionary to hold the models\n",
    "models_to_tune = {}\n",
    "\n",
    "# For loop to add models to dictionary\n",
    "for model in top_models:\n",
    "    key = model[0]\n",
    "    value = model[1]\n",
    "    models_to_tune[key] = value\n",
    "\n",
    "# Initializing dataframes to compare performance of all models\n",
    "models_train_comp_df = pd.DataFrame()\n",
    "models_val_comp_df = pd.DataFrame()\n",
    "\n",
    "# For loop to add performance results of each top model\n",
    "for name, model in models_to_tune.items():\n",
    "    models_train_comp_df[name] = model_performance_regression(model, X_train, y_train).T\n",
    "    models_val_comp_df[name] = model_performance_regression(model, X_val, y_val).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b06410",
   "metadata": {},
   "source": [
    "#### Comparing Top Models Before Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d7bcfe83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Performance:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>GBM</th>\n",
       "      <th>XGB_gbtree</th>\n",
       "      <th>XGB_gblinear</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>11.686697</td>\n",
       "      <td>14.971421</td>\n",
       "      <td>14.237993</td>\n",
       "      <td>15.177929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>8.736482</td>\n",
       "      <td>11.627512</td>\n",
       "      <td>11.034927</td>\n",
       "      <td>11.790258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-squared</th>\n",
       "      <td>0.456950</td>\n",
       "      <td>0.108786</td>\n",
       "      <td>0.193965</td>\n",
       "      <td>0.084030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Adj. R-squared</th>\n",
       "      <td>0.456610</td>\n",
       "      <td>0.108228</td>\n",
       "      <td>0.193461</td>\n",
       "      <td>0.083457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAPE</th>\n",
       "      <td>13.944396</td>\n",
       "      <td>19.221156</td>\n",
       "      <td>18.032207</td>\n",
       "      <td>19.427922</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Random Forest        GBM  XGB_gbtree  XGB_gblinear\n",
       "RMSE                11.686697  14.971421   14.237993     15.177929\n",
       "MAE                  8.736482  11.627512   11.034927     11.790258\n",
       "R-squared            0.456950   0.108786    0.193965      0.084030\n",
       "Adj. R-squared       0.456610   0.108228    0.193461      0.083457\n",
       "MAPE                13.944396  19.221156   18.032207     19.427922"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 14;\n",
       "                var nbb_unformatted_code = \"# Comparing train performance\\nprint(f\\\"Training Performance:\\\")\\nmodels_train_comp_df\";\n",
       "                var nbb_formatted_code = \"# Comparing train performance\\nprint(f\\\"Training Performance:\\\")\\nmodels_train_comp_df\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Comparing train performance\n",
    "print(f\"Training Performance:\")\n",
    "models_train_comp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a67f0163",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Performance:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>GBM</th>\n",
       "      <th>XGB_gbtree</th>\n",
       "      <th>XGB_gblinear</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>16.271584</td>\n",
       "      <td>14.922006</td>\n",
       "      <td>15.022284</td>\n",
       "      <td>15.061175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>12.558769</td>\n",
       "      <td>11.580272</td>\n",
       "      <td>11.632590</td>\n",
       "      <td>11.702807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-squared</th>\n",
       "      <td>-0.065931</td>\n",
       "      <td>0.103555</td>\n",
       "      <td>0.091466</td>\n",
       "      <td>0.086755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Adj. R-squared</th>\n",
       "      <td>-0.067489</td>\n",
       "      <td>0.102244</td>\n",
       "      <td>0.090137</td>\n",
       "      <td>0.085420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAPE</th>\n",
       "      <td>20.193462</td>\n",
       "      <td>19.051063</td>\n",
       "      <td>19.008358</td>\n",
       "      <td>19.184454</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Random Forest        GBM  XGB_gbtree  XGB_gblinear\n",
       "RMSE                16.271584  14.922006   15.022284     15.061175\n",
       "MAE                 12.558769  11.580272   11.632590     11.702807\n",
       "R-squared           -0.065931   0.103555    0.091466      0.086755\n",
       "Adj. R-squared      -0.067489   0.102244    0.090137      0.085420\n",
       "MAPE                20.193462  19.051063   19.008358     19.184454"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 15;\n",
       "                var nbb_unformatted_code = \"# Comparing validation performance\\nprint(f\\\"Validation Performance:\\\")\\nmodels_val_comp_df\";\n",
       "                var nbb_formatted_code = \"# Comparing validation performance\\nprint(f\\\"Validation Performance:\\\")\\nmodels_val_comp_df\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Comparing validation performance\n",
    "print(f\"Validation Performance:\")\n",
    "models_val_comp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec420b4",
   "metadata": {},
   "source": [
    "#### Observations:\n",
    "- Here, we compare the performance on the whole train set to the validation set.\n",
    "- Only *GBM* and *XGB_gblinear* are giving generalized performances on the two sets.\n",
    "- These two are performing on par or slightly better than [*olsmodel3*](https://github.com/teresahanak/wikipedia-life-expectancy/blob/main/wp_life_expect_olsmodel_thanak_2022_10_9.ipynb), our linear regression model, for all metrics.\n",
    "- We will see if hyperparameter tuning improves their performance, again keeping *Random Forest* and *XGB_gbtree* in the mix for demonstration and comparison."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25b1cfa",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea25fe9",
   "metadata": {},
   "source": [
    "### *Random Forest Tuned*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6e1581b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(random_state=42)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 16;\n",
       "                var nbb_unformatted_code = \"# Confirming the model\\nmodels_to_tune[\\\"Random Forest\\\"]\";\n",
       "                var nbb_formatted_code = \"# Confirming the model\\nmodels_to_tune[\\\"Random Forest\\\"]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Confirming the model\n",
    "models_to_tune[\"Random Forest\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "98b005d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Teres\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "5 fits failed out of a total of 50.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Teres\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Teres\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 450, in fit\n",
      "    trees = Parallel(\n",
      "  File \"C:\\Users\\Teres\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Teres\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Teres\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Teres\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Teres\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Teres\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Teres\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Teres\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 216, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\Teres\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 185, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Teres\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1315, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\Teres\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 241, in fit\n",
      "    if not 0.0 < self.min_samples_leaf <= 0.5:\n",
      "TypeError: '<' not supported between instances of 'float' and 'NoneType'\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\Teres\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.09803003 0.09738486 0.0968302  0.09849117 0.0438569  0.09959073\n",
      " 0.09967033 0.09943607        nan 0.08892088]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters are {'criterion': 'squared_error', 'max_depth': None, 'max_features': 'sqrt', 'max_samples': 0.3909124836035503, 'min_samples_leaf': 4, 'n_estimators': 260} with CV score=0.09967033141183923:\n",
      "CPU times: total: 3.14 s\n",
      "Wall time: 57.4 s\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 17;\n",
       "                var nbb_unformatted_code = \"%%time\\n\\n# Defining model\\nModel = RandomForestRegressor(random_state=42)\\n\\n# Parameter grid to pass in RandomizedSearchCV\\nparam_grid = { \\n    \\\"n_estimators\\\": np.arange(100, 500), \\n    \\\"min_samples_leaf\\\": [None] + np.arange(1, 10).tolist(),\\n    \\\"max_features\\\": ['sqrt'], \\n    \\\"max_samples\\\": uniform(loc=0.3, scale=0.5),\\n    'criterion': ['squared_error'],\\n    \\\"max_depth\\\": [None]\\n}\\n\\n# Calling RandomizedSearchCV\\nrandomized_cv = RandomizedSearchCV(\\n    estimator=Model,\\n    param_distributions=param_grid,\\n    n_iter=10,\\n    n_jobs=-1,\\n    scoring=scorer,\\n    cv=5,\\n    random_state=42,\\n)\\n\\n# Fitting parameters in RandomizedSearchCV\\nrandomized_cv.fit(X_train, y_train)\\n\\nprint(\\n    \\\"Best parameters are {} with CV score={}:\\\".format(\\n        randomized_cv.best_params_, randomized_cv.best_score_\\n    )\\n)\\n\\n# Chime notification when cell successfully executes\\nchime.success()\";\n",
       "                var nbb_formatted_code = \"%%time\\n\\n# Defining model\\nModel = RandomForestRegressor(random_state=42)\\n\\n# Parameter grid to pass in RandomizedSearchCV\\nparam_grid = { \\n    \\\"n_estimators\\\": np.arange(100, 500), \\n    \\\"min_samples_leaf\\\": [None] + np.arange(1, 10).tolist(),\\n    \\\"max_features\\\": ['sqrt'], \\n    \\\"max_samples\\\": uniform(loc=0.3, scale=0.5),\\n    'criterion': ['squared_error'],\\n    \\\"max_depth\\\": [None]\\n}\\n\\n# Calling RandomizedSearchCV\\nrandomized_cv = RandomizedSearchCV(\\n    estimator=Model,\\n    param_distributions=param_grid,\\n    n_iter=10,\\n    n_jobs=-1,\\n    scoring=scorer,\\n    cv=5,\\n    random_state=42,\\n)\\n\\n# Fitting parameters in RandomizedSearchCV\\nrandomized_cv.fit(X_train, y_train)\\n\\nprint(\\n    \\\"Best parameters are {} with CV score={}:\\\".format(\\n        randomized_cv.best_params_, randomized_cv.best_score_\\n    )\\n)\\n\\n# Chime notification when cell successfully executes\\nchime.success()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Defining model\n",
    "Model = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Parameter grid to pass in RandomizedSearchCV\n",
    "param_grid = { \n",
    "    \"n_estimators\": np.arange(100, 500), \n",
    "    \"min_samples_leaf\": [None] + np.arange(1, 10).tolist(),\n",
    "    \"max_features\": ['sqrt'], \n",
    "    \"max_samples\": uniform(loc=0.3, scale=0.5),\n",
    "    'criterion': ['squared_error'],\n",
    "    \"max_depth\": [None]\n",
    "}\n",
    "\n",
    "# Calling RandomizedSearchCV\n",
    "randomized_cv = RandomizedSearchCV(\n",
    "    estimator=Model,\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=10,\n",
    "    n_jobs=-1,\n",
    "    scoring=scorer,\n",
    "    cv=5,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "# Fitting parameters in RandomizedSearchCV\n",
    "randomized_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\n",
    "    \"Best parameters are {} with CV score={}:\".format(\n",
    "        randomized_cv.best_params_, randomized_cv.best_score_\n",
    "    )\n",
    ")\n",
    "\n",
    "# Chime notification when cell successfully executes\n",
    "chime.success()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "70b8ba4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(max_features='sqrt', max_samples=0.3909124836035503,\n",
       "                      min_samples_leaf=4, n_estimators=260)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 18;\n",
       "                var nbb_unformatted_code = \"# Building model with best parameters\\nRandom_Forest_tuned = RandomForestRegressor(\\n    criterion=\\\"squared_error\\\",\\n    max_depth=None,\\n    max_features=\\\"sqrt\\\",\\n    max_samples=0.3909124836035503,\\n    min_samples_leaf=4,\\n    n_estimators=260,\\n)\\n\\n# Fit the model on training data\\nRandom_Forest_tuned.fit(X_train, y_train)\";\n",
       "                var nbb_formatted_code = \"# Building model with best parameters\\nRandom_Forest_tuned = RandomForestRegressor(\\n    criterion=\\\"squared_error\\\",\\n    max_depth=None,\\n    max_features=\\\"sqrt\\\",\\n    max_samples=0.3909124836035503,\\n    min_samples_leaf=4,\\n    n_estimators=260,\\n)\\n\\n# Fit the model on training data\\nRandom_Forest_tuned.fit(X_train, y_train)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Building model with best parameters\n",
    "Random_Forest_tuned = RandomForestRegressor(\n",
    "    criterion=\"squared_error\",\n",
    "    max_depth=None,\n",
    "    max_features=\"sqrt\",\n",
    "    max_samples=0.3909124836035503,\n",
    "    min_samples_leaf=4,\n",
    "    n_estimators=260,\n",
    ")\n",
    "\n",
    "# Fit the model on training data\n",
    "Random_Forest_tuned.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4b02b1d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training performance:\n",
      "         RMSE        MAE  R-squared  Adj. R-squared       MAPE\n",
      "0  14.578171  11.324773   0.154989         0.15446  18.732126\n",
      "\n",
      "Validation performance:\n",
      "         RMSE       MAE  R-squared  Adj. R-squared       MAPE\n",
      "0  14.952656  11.60246   0.099868        0.098552  19.097816\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 19;\n",
       "                var nbb_unformatted_code = \"# Calculating different metrics\\nRandom_Forest_tuned_train_perf = model_performance_regression(\\n    Random_Forest_tuned, X_train, y_train\\n)\\nprint(\\\"Training performance:\\\\n\\\", Random_Forest_tuned_train_perf)\\nRandom_Forest_tuned_val_perf = model_performance_regression(\\n    Random_Forest_tuned, X_val, y_val\\n)\\nprint(\\\"\\\\nValidation performance:\\\\n\\\", Random_Forest_tuned_val_perf)\\n\\n# Adding model to model comparison dataframes\\nmodels_train_comp_df[\\\"Random Forest Tuned\\\"] = Random_Forest_tuned_train_perf.T\\nmodels_val_comp_df[\\\"Random Forest Tuned\\\"] = Random_Forest_tuned_val_perf.T\";\n",
       "                var nbb_formatted_code = \"# Calculating different metrics\\nRandom_Forest_tuned_train_perf = model_performance_regression(\\n    Random_Forest_tuned, X_train, y_train\\n)\\nprint(\\\"Training performance:\\\\n\\\", Random_Forest_tuned_train_perf)\\nRandom_Forest_tuned_val_perf = model_performance_regression(\\n    Random_Forest_tuned, X_val, y_val\\n)\\nprint(\\\"\\\\nValidation performance:\\\\n\\\", Random_Forest_tuned_val_perf)\\n\\n# Adding model to model comparison dataframes\\nmodels_train_comp_df[\\\"Random Forest Tuned\\\"] = Random_Forest_tuned_train_perf.T\\nmodels_val_comp_df[\\\"Random Forest Tuned\\\"] = Random_Forest_tuned_val_perf.T\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculating different metrics\n",
    "Random_Forest_tuned_train_perf = model_performance_regression(\n",
    "    Random_Forest_tuned, X_train, y_train\n",
    ")\n",
    "print(\"Training performance:\\n\", Random_Forest_tuned_train_perf)\n",
    "Random_Forest_tuned_val_perf = model_performance_regression(\n",
    "    Random_Forest_tuned, X_val, y_val\n",
    ")\n",
    "print(\"\\nValidation performance:\\n\", Random_Forest_tuned_val_perf)\n",
    "\n",
    "# Adding model to model comparison dataframes\n",
    "models_train_comp_df[\"Random Forest Tuned\"] = Random_Forest_tuned_train_perf.T\n",
    "models_val_comp_df[\"Random Forest Tuned\"] = Random_Forest_tuned_val_perf.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b37c92f",
   "metadata": {},
   "source": [
    "#### Observations:\n",
    "- Hyperparameter tuning improved performance for *Random Forest*.\n",
    "- The algorithm is still overfitting the train set, compared to the validation set.\n",
    "- Note that we had a 10% fit fail during cross-validation (\"UserWarning: One or more of the test scores are non-finite..\") indicating cross-validation had some folds for which hyperparameter combinations led to Nan values.  We are going to allow it here, and go with the results of the successful iterations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208028f9",
   "metadata": {},
   "source": [
    "### *GBM Tuned*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "59c48bf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(random_state=42)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 20;\n",
       "                var nbb_unformatted_code = \"# Confirming the model\\nmodels_to_tune[\\\"GBM\\\"]\";\n",
       "                var nbb_formatted_code = \"# Confirming the model\\nmodels_to_tune[\\\"GBM\\\"]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Confirming the model\n",
    "models_to_tune[\"GBM\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "47553f87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters are {'learning_rate': 0.08171272700715591, 'max_features': 0.6630456668613307, 'n_estimators': 368, 'subsample': 0.7847684335570795} with CV score=0.1063224214498147:\n",
      "CPU times: total: 12.8 s\n",
      "Wall time: 6min 31s\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 21;\n",
       "                var nbb_unformatted_code = \"%%time\\n\\n# Defining model\\nModel = GradientBoostingRegressor(random_state=42)\\n\\n# Parameter grid to pass in RandomizedSearchCV\\nparam_grid = {\\n    \\\"n_estimators\\\": np.arange(100, 500),\\n    \\\"learning_rate\\\": loguniform(0.001, 1),\\n    \\\"subsample\\\": uniform(loc=0.3, scale=0.5),\\n    \\\"max_features\\\": uniform(loc=0.3, scale=0.5),\\n}\\n\\n# Calling RandomizedSearchCV\\nrandomized_cv = RandomizedSearchCV(\\n    estimator=Model,\\n    param_distributions=param_grid,\\n    n_iter=100,\\n    n_jobs=-1,\\n    scoring=scorer,\\n    cv=5,\\n    random_state=42,\\n)\\n\\n# Fitting parameters in RandomizedSearchCV\\nrandomized_cv.fit(X_train, y_train)\\n\\nprint(\\n    \\\"Best parameters are {} with CV score={}:\\\".format(\\n        randomized_cv.best_params_, randomized_cv.best_score_\\n    )\\n)\\n\\n# Chime notification when cell successfully executes\\nchime.success()\";\n",
       "                var nbb_formatted_code = \"%%time\\n\\n# Defining model\\nModel = GradientBoostingRegressor(random_state=42)\\n\\n# Parameter grid to pass in RandomizedSearchCV\\nparam_grid = {\\n    \\\"n_estimators\\\": np.arange(100, 500),\\n    \\\"learning_rate\\\": loguniform(0.001, 1),\\n    \\\"subsample\\\": uniform(loc=0.3, scale=0.5),\\n    \\\"max_features\\\": uniform(loc=0.3, scale=0.5),\\n}\\n\\n# Calling RandomizedSearchCV\\nrandomized_cv = RandomizedSearchCV(\\n    estimator=Model,\\n    param_distributions=param_grid,\\n    n_iter=100,\\n    n_jobs=-1,\\n    scoring=scorer,\\n    cv=5,\\n    random_state=42,\\n)\\n\\n# Fitting parameters in RandomizedSearchCV\\nrandomized_cv.fit(X_train, y_train)\\n\\nprint(\\n    \\\"Best parameters are {} with CV score={}:\\\".format(\\n        randomized_cv.best_params_, randomized_cv.best_score_\\n    )\\n)\\n\\n# Chime notification when cell successfully executes\\nchime.success()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Defining model\n",
    "Model = GradientBoostingRegressor(random_state=42)\n",
    "\n",
    "# Parameter grid to pass in RandomizedSearchCV\n",
    "param_grid = {\n",
    "    \"n_estimators\": np.arange(100, 500),\n",
    "    \"learning_rate\": loguniform(0.001, 1),\n",
    "    \"subsample\": uniform(loc=0.3, scale=0.5),\n",
    "    \"max_features\": uniform(loc=0.3, scale=0.5),\n",
    "}\n",
    "\n",
    "# Calling RandomizedSearchCV\n",
    "randomized_cv = RandomizedSearchCV(\n",
    "    estimator=Model,\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=100,\n",
    "    n_jobs=-1,\n",
    "    scoring=scorer,\n",
    "    cv=5,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "# Fitting parameters in RandomizedSearchCV\n",
    "randomized_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\n",
    "    \"Best parameters are {} with CV score={}:\".format(\n",
    "        randomized_cv.best_params_, randomized_cv.best_score_\n",
    "    )\n",
    ")\n",
    "\n",
    "# Chime notification when cell successfully executes\n",
    "chime.success()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6916dcf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(learning_rate=0.08171272700715591,\n",
       "                          max_features=0.6630456668613307, n_estimators=368,\n",
       "                          random_state=42, subsample=0.7847684335570795)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 22;\n",
       "                var nbb_unformatted_code = \"# Building model with best parameters\\nGBM_tuned = GradientBoostingRegressor(\\n    random_state=42,\\n    learning_rate=0.08171272700715591,\\n    max_features=0.6630456668613307,\\n    n_estimators=368,\\n    subsample=0.7847684335570795,\\n)\\n\\n# Fit the model on training data\\nGBM_tuned.fit(X_train, y_train)\";\n",
       "                var nbb_formatted_code = \"# Building model with best parameters\\nGBM_tuned = GradientBoostingRegressor(\\n    random_state=42,\\n    learning_rate=0.08171272700715591,\\n    max_features=0.6630456668613307,\\n    n_estimators=368,\\n    subsample=0.7847684335570795,\\n)\\n\\n# Fit the model on training data\\nGBM_tuned.fit(X_train, y_train)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Building model with best parameters\n",
    "GBM_tuned = GradientBoostingRegressor(\n",
    "    random_state=42,\n",
    "    learning_rate=0.08171272700715591,\n",
    "    max_features=0.6630456668613307,\n",
    "    n_estimators=368,\n",
    "    subsample=0.7847684335570795,\n",
    ")\n",
    "\n",
    "# Fit the model on training data\n",
    "GBM_tuned.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d47c87fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training performance:\n",
      "         RMSE        MAE  R-squared  Adj. R-squared       MAPE\n",
      "0  14.835035  11.521845   0.124949        0.124401  18.989296\n",
      "\n",
      "Validation performance:\n",
      "         RMSE        MAE  R-squared  Adj. R-squared       MAPE\n",
      "0  14.877704  11.542386    0.10887        0.107567  18.937928\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 23;\n",
       "                var nbb_unformatted_code = \"# Calculating different metrics\\nGBM_tuned_train_perf = model_performance_regression(GBM_tuned, X_train, y_train)\\nprint(\\\"Training performance:\\\\n\\\", GBM_tuned_train_perf)\\nGBM_tuned_val_perf = model_performance_regression(GBM_tuned, X_val, y_val)\\nprint(\\\"\\\\nValidation performance:\\\\n\\\", GBM_tuned_val_perf)\\n\\n# Adding model to model comparison dataframes\\nmodels_train_comp_df[\\\"GBM Tuned\\\"] = GBM_tuned_train_perf.T\\nmodels_val_comp_df[\\\"GBM Tuned\\\"] = GBM_tuned_val_perf.T\";\n",
       "                var nbb_formatted_code = \"# Calculating different metrics\\nGBM_tuned_train_perf = model_performance_regression(GBM_tuned, X_train, y_train)\\nprint(\\\"Training performance:\\\\n\\\", GBM_tuned_train_perf)\\nGBM_tuned_val_perf = model_performance_regression(GBM_tuned, X_val, y_val)\\nprint(\\\"\\\\nValidation performance:\\\\n\\\", GBM_tuned_val_perf)\\n\\n# Adding model to model comparison dataframes\\nmodels_train_comp_df[\\\"GBM Tuned\\\"] = GBM_tuned_train_perf.T\\nmodels_val_comp_df[\\\"GBM Tuned\\\"] = GBM_tuned_val_perf.T\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculating different metrics\n",
    "GBM_tuned_train_perf = model_performance_regression(GBM_tuned, X_train, y_train)\n",
    "print(\"Training performance:\\n\", GBM_tuned_train_perf)\n",
    "GBM_tuned_val_perf = model_performance_regression(GBM_tuned, X_val, y_val)\n",
    "print(\"\\nValidation performance:\\n\", GBM_tuned_val_perf)\n",
    "\n",
    "# Adding model to model comparison dataframes\n",
    "models_train_comp_df[\"GBM Tuned\"] = GBM_tuned_train_perf.T\n",
    "models_val_comp_df[\"GBM Tuned\"] = GBM_tuned_val_perf.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e76f44e0",
   "metadata": {},
   "source": [
    "#### Observations:\n",
    "- The performance for *GBM* is improved with hyperparameter tuning.  \n",
    "- There is a slight increase in overfitting, but the validation metrics are better."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d345d350",
   "metadata": {},
   "source": [
    "### *XGB_gbtree Tuned*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8a847975",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', callbacks=None,\n",
       "             colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "             early_stopping_rounds=None, enable_categorical=False,\n",
       "             eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n",
       "             importance_type=None, interaction_constraints='',\n",
       "             learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n",
       "             max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,\n",
       "             missing=nan, monotone_constraints='()', n_estimators=100, n_jobs=0,\n",
       "             num_parallel_tree=1, predictor='auto', random_state=42,\n",
       "             reg_alpha=0, reg_lambda=1, ...)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 24;\n",
       "                var nbb_unformatted_code = \"# Confirming the model\\nmodels_to_tune[\\\"XGB_gbtree\\\"]\";\n",
       "                var nbb_formatted_code = \"# Confirming the model\\nmodels_to_tune[\\\"XGB_gbtree\\\"]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Confirming the model\n",
    "models_to_tune[\"XGB_gbtree\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "06dbfd3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters are {'colsample_bytree': 0.42649508399462055, 'gamma': 1.188792356281234, 'learning_rate': 0.12263036412693079, 'max_depth': 3, 'n_estimators': 404, 'subsample': 0.7391497377969234} with CV score=0.10679644601394585:\n",
      "CPU times: total: 1min 9s\n",
      "Wall time: 20min 49s\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 25;\n",
       "                var nbb_unformatted_code = \"%%time\\n\\n# Defining model\\nModel = XGBRegressor(random_state=42, booster='gbtree')\\n\\n# Parameter grid to pass in RandomizedSearchCV\\nparam_grid={\\n    'n_estimators': np.arange(100, 500),\\n    \\\"learning_rate\\\": uniform(0.1, 0.3), # aka eta\\n    'gamma': expon(), # aka min_split_loss\\n    'subsample': uniform(loc=0.6, scale=0.2), # proportion of train set to randomly sample prior to growing trees\\n    'max_depth': np.arange(3, 8).tolist(),\\n    'colsample_bytree': uniform(loc=0.3, scale=0.5)\\n}\\n\\n# Calling RandomizedSearchCV\\nrandomized_cv = RandomizedSearchCV(\\n    estimator=Model,\\n    param_distributions=param_grid,\\n    n_iter=100,\\n    n_jobs=-1,\\n    scoring=scorer,\\n    cv=5,\\n    random_state=42,\\n)\\n\\n# Fitting parameters in RandomizedSearchCV\\nrandomized_cv.fit(X_train, y_train)\\n\\nprint(\\n    \\\"Best parameters are {} with CV score={}:\\\".format(\\n        randomized_cv.best_params_, randomized_cv.best_score_\\n    )\\n)\\n\\n# Chime notification when cell successfully executes\\nchime.success()\";\n",
       "                var nbb_formatted_code = \"%%time\\n\\n# Defining model\\nModel = XGBRegressor(random_state=42, booster='gbtree')\\n\\n# Parameter grid to pass in RandomizedSearchCV\\nparam_grid={\\n    'n_estimators': np.arange(100, 500),\\n    \\\"learning_rate\\\": uniform(0.1, 0.3), # aka eta\\n    'gamma': expon(), # aka min_split_loss\\n    'subsample': uniform(loc=0.6, scale=0.2), # proportion of train set to randomly sample prior to growing trees\\n    'max_depth': np.arange(3, 8).tolist(),\\n    'colsample_bytree': uniform(loc=0.3, scale=0.5)\\n}\\n\\n# Calling RandomizedSearchCV\\nrandomized_cv = RandomizedSearchCV(\\n    estimator=Model,\\n    param_distributions=param_grid,\\n    n_iter=100,\\n    n_jobs=-1,\\n    scoring=scorer,\\n    cv=5,\\n    random_state=42,\\n)\\n\\n# Fitting parameters in RandomizedSearchCV\\nrandomized_cv.fit(X_train, y_train)\\n\\nprint(\\n    \\\"Best parameters are {} with CV score={}:\\\".format(\\n        randomized_cv.best_params_, randomized_cv.best_score_\\n    )\\n)\\n\\n# Chime notification when cell successfully executes\\nchime.success()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Defining model\n",
    "Model = XGBRegressor(random_state=42, booster='gbtree')\n",
    "\n",
    "# Parameter grid to pass in RandomizedSearchCV\n",
    "param_grid={\n",
    "    'n_estimators': np.arange(100, 500),\n",
    "    \"learning_rate\": uniform(0.1, 0.3), # aka eta\n",
    "    'gamma': expon(), # aka min_split_loss\n",
    "    'subsample': uniform(loc=0.6, scale=0.2), # proportion of train set to randomly sample prior to growing trees\n",
    "    'max_depth': np.arange(3, 8).tolist(),\n",
    "    'colsample_bytree': uniform(loc=0.3, scale=0.5)\n",
    "}\n",
    "\n",
    "# Calling RandomizedSearchCV\n",
    "randomized_cv = RandomizedSearchCV(\n",
    "    estimator=Model,\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=100,\n",
    "    n_jobs=-1,\n",
    "    scoring=scorer,\n",
    "    cv=5,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "# Fitting parameters in RandomizedSearchCV\n",
    "randomized_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\n",
    "    \"Best parameters are {} with CV score={}:\".format(\n",
    "        randomized_cv.best_params_, randomized_cv.best_score_\n",
    "    )\n",
    ")\n",
    "\n",
    "# Chime notification when cell successfully executes\n",
    "chime.success()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9472522b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', callbacks=None,\n",
       "             colsample_bylevel=1, colsample_bynode=1,\n",
       "             colsample_bytree=0.42649508399462055, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None,\n",
       "             gamma=1.188792356281234, gpu_id=-1, grow_policy='depthwise',\n",
       "             importance_type=None, interaction_constraints='',\n",
       "             learning_rate=0.12263036412693079, max_bin=256,\n",
       "             max_cat_to_onehot=4, max_delta_step=0, max_depth=3, max_leaves=0,\n",
       "             min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "             n_estimators=404, n_jobs=0, num_parallel_tree=1, predictor='auto',\n",
       "             random_state=42, reg_alpha=0, reg_lambda=1, ...)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 26;\n",
       "                var nbb_unformatted_code = \"# Building model with best parameters\\nXGB_gbtree_tuned = XGBRegressor(\\n    booster=\\\"gbtree\\\",\\n    random_state=42,\\n    colsample_bytree=0.42649508399462055,\\n    gamma=1.188792356281234,\\n    learning_rate=0.12263036412693079,\\n    max_depth=3,\\n    n_estimators=404,\\n    subsample=0.7391497377969234,\\n)\\n\\n# Fit the model on training data\\nXGB_gbtree_tuned.fit(X_train, y_train)\";\n",
       "                var nbb_formatted_code = \"# Building model with best parameters\\nXGB_gbtree_tuned = XGBRegressor(\\n    booster=\\\"gbtree\\\",\\n    random_state=42,\\n    colsample_bytree=0.42649508399462055,\\n    gamma=1.188792356281234,\\n    learning_rate=0.12263036412693079,\\n    max_depth=3,\\n    n_estimators=404,\\n    subsample=0.7391497377969234,\\n)\\n\\n# Fit the model on training data\\nXGB_gbtree_tuned.fit(X_train, y_train)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Building model with best parameters\n",
    "XGB_gbtree_tuned = XGBRegressor(\n",
    "    booster=\"gbtree\",\n",
    "    random_state=42,\n",
    "    colsample_bytree=0.42649508399462055,\n",
    "    gamma=1.188792356281234,\n",
    "    learning_rate=0.12263036412693079,\n",
    "    max_depth=3,\n",
    "    n_estimators=404,\n",
    "    subsample=0.7391497377969234,\n",
    ")\n",
    "\n",
    "# Fit the model on training data\n",
    "XGB_gbtree_tuned.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a6101083",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training performance:\n",
      "         RMSE       MAE  R-squared  Adj. R-squared       MAPE\n",
      "0  14.813429  11.50438   0.127496         0.12695  18.953973\n",
      "\n",
      "Validation performance:\n",
      "         RMSE        MAE  R-squared  Adj. R-squared       MAPE\n",
      "0  14.882834  11.546377   0.108255        0.106951  18.931955\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 27;\n",
       "                var nbb_unformatted_code = \"# Calculating different metrics\\nXGB_gbtree_tuned_train_perf = model_performance_regression(\\n    XGB_gbtree_tuned, X_train, y_train\\n)\\nprint(\\\"Training performance:\\\\n\\\", XGB_gbtree_tuned_train_perf)\\nXGB_gbtree_tuned_val_perf = model_performance_regression(XGB_gbtree_tuned, X_val, y_val)\\nprint(\\\"\\\\nValidation performance:\\\\n\\\", XGB_gbtree_tuned_val_perf)\\n\\n# Adding model to model comparison dataframes\\nmodels_train_comp_df[\\\"XGB_gbtree Tuned\\\"] = XGB_gbtree_tuned_train_perf.T\\nmodels_val_comp_df[\\\"XGB_gbtree Tuned\\\"] = XGB_gbtree_tuned_val_perf.T\";\n",
       "                var nbb_formatted_code = \"# Calculating different metrics\\nXGB_gbtree_tuned_train_perf = model_performance_regression(\\n    XGB_gbtree_tuned, X_train, y_train\\n)\\nprint(\\\"Training performance:\\\\n\\\", XGB_gbtree_tuned_train_perf)\\nXGB_gbtree_tuned_val_perf = model_performance_regression(XGB_gbtree_tuned, X_val, y_val)\\nprint(\\\"\\\\nValidation performance:\\\\n\\\", XGB_gbtree_tuned_val_perf)\\n\\n# Adding model to model comparison dataframes\\nmodels_train_comp_df[\\\"XGB_gbtree Tuned\\\"] = XGB_gbtree_tuned_train_perf.T\\nmodels_val_comp_df[\\\"XGB_gbtree Tuned\\\"] = XGB_gbtree_tuned_val_perf.T\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculating different metrics\n",
    "XGB_gbtree_tuned_train_perf = model_performance_regression(\n",
    "    XGB_gbtree_tuned, X_train, y_train\n",
    ")\n",
    "print(\"Training performance:\\n\", XGB_gbtree_tuned_train_perf)\n",
    "XGB_gbtree_tuned_val_perf = model_performance_regression(XGB_gbtree_tuned, X_val, y_val)\n",
    "print(\"\\nValidation performance:\\n\", XGB_gbtree_tuned_val_perf)\n",
    "\n",
    "# Adding model to model comparison dataframes\n",
    "models_train_comp_df[\"XGB_gbtree Tuned\"] = XGB_gbtree_tuned_train_perf.T\n",
    "models_val_comp_df[\"XGB_gbtree Tuned\"] = XGB_gbtree_tuned_val_perf.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "589bde06",
   "metadata": {},
   "source": [
    "#### Observations:\n",
    "- The performance for *XGB_gbtree* is improved with hyperparameter tuning.  \n",
    "- There is a slight increase in overfitting, but the validation metrics are better."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc9bc9d",
   "metadata": {},
   "source": [
    "### *XGB_gblinear Tuned*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5bded9fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gblinear', callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, gamma=None, gpu_id=-1,\n",
       "             grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.5, max_bin=None,\n",
       "             max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "             max_leaves=None, min_child_weight=None, missing=nan,\n",
       "             monotone_constraints=None, n_estimators=100, n_jobs=0,\n",
       "             num_parallel_tree=None, predictor=None, random_state=42,\n",
       "             reg_alpha=0, reg_lambda=0, ...)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 28;\n",
       "                var nbb_unformatted_code = \"# Confirming the model\\nmodels_to_tune[\\\"XGB_gblinear\\\"]\";\n",
       "                var nbb_formatted_code = \"# Confirming the model\\nmodels_to_tune[\\\"XGB_gblinear\\\"]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Confirming the model\n",
    "models_to_tune[\"XGB_gblinear\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b6f73eb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters are {'n_estimators': 439, 'reg_lambda': 0.0009206654892274761} with CV score=0.09196572057161607:\n",
      "CPU times: total: 37.1 s\n",
      "Wall time: 5min 49s\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 29;\n",
       "                var nbb_unformatted_code = \"%%time\\n\\n# Defining model\\nModel = XGBRegressor(random_state=42, booster='gblinear')\\n\\n# Parameter grid to pass in RandomizedSearchCV\\nparam_grid={\\n    'n_estimators': np.arange(100, 500),\\n    'reg_lambda': loguniform(.0001, 1)\\n}\\n\\n# Calling RandomizedSearchCV\\nrandomized_cv = RandomizedSearchCV(\\n    estimator=Model,\\n    param_distributions=param_grid,\\n    n_iter=100,\\n    n_jobs=-1,\\n    scoring=scorer,\\n    cv=5,\\n    random_state=42,\\n)\\n\\n# Fitting parameters in RandomizedSearchCV\\nrandomized_cv.fit(X_train, y_train)\\n\\nprint(\\n    \\\"Best parameters are {} with CV score={}:\\\".format(\\n        randomized_cv.best_params_, randomized_cv.best_score_\\n    )\\n)\\n\\n# Chime notification when cell successfully executes\\nchime.success()\";\n",
       "                var nbb_formatted_code = \"%%time\\n\\n# Defining model\\nModel = XGBRegressor(random_state=42, booster='gblinear')\\n\\n# Parameter grid to pass in RandomizedSearchCV\\nparam_grid={\\n    'n_estimators': np.arange(100, 500),\\n    'reg_lambda': loguniform(.0001, 1)\\n}\\n\\n# Calling RandomizedSearchCV\\nrandomized_cv = RandomizedSearchCV(\\n    estimator=Model,\\n    param_distributions=param_grid,\\n    n_iter=100,\\n    n_jobs=-1,\\n    scoring=scorer,\\n    cv=5,\\n    random_state=42,\\n)\\n\\n# Fitting parameters in RandomizedSearchCV\\nrandomized_cv.fit(X_train, y_train)\\n\\nprint(\\n    \\\"Best parameters are {} with CV score={}:\\\".format(\\n        randomized_cv.best_params_, randomized_cv.best_score_\\n    )\\n)\\n\\n# Chime notification when cell successfully executes\\nchime.success()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Defining model\n",
    "Model = XGBRegressor(random_state=42, booster='gblinear')\n",
    "\n",
    "# Parameter grid to pass in RandomizedSearchCV\n",
    "param_grid={\n",
    "    'n_estimators': np.arange(100, 500),\n",
    "    'reg_lambda': loguniform(.0001, 1)\n",
    "}\n",
    "\n",
    "# Calling RandomizedSearchCV\n",
    "randomized_cv = RandomizedSearchCV(\n",
    "    estimator=Model,\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=100,\n",
    "    n_jobs=-1,\n",
    "    scoring=scorer,\n",
    "    cv=5,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "# Fitting parameters in RandomizedSearchCV\n",
    "randomized_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\n",
    "    \"Best parameters are {} with CV score={}:\".format(\n",
    "        randomized_cv.best_params_, randomized_cv.best_score_\n",
    "    )\n",
    ")\n",
    "\n",
    "# Chime notification when cell successfully executes\n",
    "chime.success()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c5f6c963",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gblinear', callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, gamma=None, gpu_id=-1,\n",
       "             grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.5, max_bin=None,\n",
       "             max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "             max_leaves=None, min_child_weight=None, missing=nan,\n",
       "             monotone_constraints=None, n_estimators=439, n_jobs=0,\n",
       "             num_parallel_tree=None, predictor=None, random_state=42,\n",
       "             reg_alpha=0, reg_lambda=0.0009206654892274761, ...)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 30;\n",
       "                var nbb_unformatted_code = \"# Building model with best parameters\\nXGB_gblinear_tuned = XGBRegressor(\\n    booster=\\\"gblinear\\\",\\n    random_state=42,\\n    n_estimators=439,\\n    reg_lambda=0.0009206654892274761,\\n)\\n\\n# Fit the model on training data\\nXGB_gblinear_tuned.fit(X_train, y_train)\";\n",
       "                var nbb_formatted_code = \"# Building model with best parameters\\nXGB_gblinear_tuned = XGBRegressor(\\n    booster=\\\"gblinear\\\",\\n    random_state=42,\\n    n_estimators=439,\\n    reg_lambda=0.0009206654892274761,\\n)\\n\\n# Fit the model on training data\\nXGB_gblinear_tuned.fit(X_train, y_train)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Building model with best parameters\n",
    "XGB_gblinear_tuned = XGBRegressor(\n",
    "    booster=\"gblinear\",\n",
    "    random_state=42,\n",
    "    n_estimators=439,\n",
    "    reg_lambda=0.0009206654892274761,\n",
    ")\n",
    "\n",
    "# Fit the model on training data\n",
    "XGB_gblinear_tuned.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c03abdd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training performance:\n",
      "         RMSE        MAE  R-squared  Adj. R-squared       MAPE\n",
      "0  15.102707  11.727685   0.093087        0.092519  19.393284\n",
      "\n",
      "Validation performance:\n",
      "       RMSE        MAE  R-squared  Adj. R-squared      MAPE\n",
      "0  14.9948  11.638517   0.094787        0.093464  19.15185\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 31;\n",
       "                var nbb_unformatted_code = \"# Calculating different metrics\\nXGB_gblinear_tuned_train_perf = model_performance_regression(\\n    XGB_gblinear_tuned, X_train, y_train\\n)\\nprint(\\\"Training performance:\\\\n\\\", XGB_gblinear_tuned_train_perf)\\nXGB_gblinear_tuned_val_perf = model_performance_regression(\\n    XGB_gblinear_tuned, X_val, y_val\\n)\\nprint(\\\"\\\\nValidation performance:\\\\n\\\", XGB_gblinear_tuned_val_perf)\\n\\n# Adding model to model comparison dataframes\\nmodels_train_comp_df[\\\"XGB_gblinear Tuned\\\"] = XGB_gblinear_tuned_train_perf.T\\nmodels_val_comp_df[\\\"XGB_gblinear Tuned\\\"] = XGB_gblinear_tuned_val_perf.T\";\n",
       "                var nbb_formatted_code = \"# Calculating different metrics\\nXGB_gblinear_tuned_train_perf = model_performance_regression(\\n    XGB_gblinear_tuned, X_train, y_train\\n)\\nprint(\\\"Training performance:\\\\n\\\", XGB_gblinear_tuned_train_perf)\\nXGB_gblinear_tuned_val_perf = model_performance_regression(\\n    XGB_gblinear_tuned, X_val, y_val\\n)\\nprint(\\\"\\\\nValidation performance:\\\\n\\\", XGB_gblinear_tuned_val_perf)\\n\\n# Adding model to model comparison dataframes\\nmodels_train_comp_df[\\\"XGB_gblinear Tuned\\\"] = XGB_gblinear_tuned_train_perf.T\\nmodels_val_comp_df[\\\"XGB_gblinear Tuned\\\"] = XGB_gblinear_tuned_val_perf.T\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculating different metrics\n",
    "XGB_gblinear_tuned_train_perf = model_performance_regression(\n",
    "    XGB_gblinear_tuned, X_train, y_train\n",
    ")\n",
    "print(\"Training performance:\\n\", XGB_gblinear_tuned_train_perf)\n",
    "XGB_gblinear_tuned_val_perf = model_performance_regression(\n",
    "    XGB_gblinear_tuned, X_val, y_val\n",
    ")\n",
    "print(\"\\nValidation performance:\\n\", XGB_gblinear_tuned_val_perf)\n",
    "\n",
    "# Adding model to model comparison dataframes\n",
    "models_train_comp_df[\"XGB_gblinear Tuned\"] = XGB_gblinear_tuned_train_perf.T\n",
    "models_val_comp_df[\"XGB_gblinear Tuned\"] = XGB_gblinear_tuned_val_perf.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "627e4098",
   "metadata": {},
   "source": [
    "#### Observations:\n",
    "- *XGB_gblinear* also has improved performance with hyperparameter tuning.\n",
    "- Let us compare the models, before and after hyperparameter tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27ff942",
   "metadata": {},
   "source": [
    "## Model Performance Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1dcb341",
   "metadata": {},
   "source": [
    "### Performance of Various Models Tuned and Untuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "eafdbe24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Performance Comparison:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GBM</th>\n",
       "      <th>GBM Tuned</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>Random Forest Tuned</th>\n",
       "      <th>XGB_gblinear</th>\n",
       "      <th>XGB_gblinear Tuned</th>\n",
       "      <th>XGB_gbtree</th>\n",
       "      <th>XGB_gbtree Tuned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>14.971421</td>\n",
       "      <td>14.835035</td>\n",
       "      <td>11.686697</td>\n",
       "      <td>14.578171</td>\n",
       "      <td>15.177929</td>\n",
       "      <td>15.102707</td>\n",
       "      <td>14.237993</td>\n",
       "      <td>14.813429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>11.627512</td>\n",
       "      <td>11.521845</td>\n",
       "      <td>8.736482</td>\n",
       "      <td>11.324773</td>\n",
       "      <td>11.790258</td>\n",
       "      <td>11.727685</td>\n",
       "      <td>11.034927</td>\n",
       "      <td>11.504380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-squared</th>\n",
       "      <td>0.108786</td>\n",
       "      <td>0.124949</td>\n",
       "      <td>0.456950</td>\n",
       "      <td>0.154989</td>\n",
       "      <td>0.084030</td>\n",
       "      <td>0.093087</td>\n",
       "      <td>0.193965</td>\n",
       "      <td>0.127496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Adj. R-squared</th>\n",
       "      <td>0.108228</td>\n",
       "      <td>0.124401</td>\n",
       "      <td>0.456610</td>\n",
       "      <td>0.154460</td>\n",
       "      <td>0.083457</td>\n",
       "      <td>0.092519</td>\n",
       "      <td>0.193461</td>\n",
       "      <td>0.126950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAPE</th>\n",
       "      <td>19.221156</td>\n",
       "      <td>18.989296</td>\n",
       "      <td>13.944396</td>\n",
       "      <td>18.732126</td>\n",
       "      <td>19.427922</td>\n",
       "      <td>19.393284</td>\n",
       "      <td>18.032207</td>\n",
       "      <td>18.953973</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      GBM  GBM Tuned  Random Forest  Random Forest Tuned  \\\n",
       "RMSE            14.971421  14.835035      11.686697            14.578171   \n",
       "MAE             11.627512  11.521845       8.736482            11.324773   \n",
       "R-squared        0.108786   0.124949       0.456950             0.154989   \n",
       "Adj. R-squared   0.108228   0.124401       0.456610             0.154460   \n",
       "MAPE            19.221156  18.989296      13.944396            18.732126   \n",
       "\n",
       "                XGB_gblinear  XGB_gblinear Tuned  XGB_gbtree  XGB_gbtree Tuned  \n",
       "RMSE               15.177929           15.102707   14.237993         14.813429  \n",
       "MAE                11.790258           11.727685   11.034927         11.504380  \n",
       "R-squared           0.084030            0.093087    0.193965          0.127496  \n",
       "Adj. R-squared      0.083457            0.092519    0.193461          0.126950  \n",
       "MAPE               19.427922           19.393284   18.032207         18.953973  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 32;\n",
       "                var nbb_unformatted_code = \"# Displaying train performance of all models\\nprint(\\\"Train Performance Comparison:\\\")\\nmodels_train_comp_df.sort_index(axis=1)\";\n",
       "                var nbb_formatted_code = \"# Displaying train performance of all models\\nprint(\\\"Train Performance Comparison:\\\")\\nmodels_train_comp_df.sort_index(axis=1)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Displaying train performance of all models\n",
    "print(\"Train Performance Comparison:\")\n",
    "models_train_comp_df.sort_index(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ed958b1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Performance Comparison:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GBM</th>\n",
       "      <th>GBM Tuned</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>Random Forest Tuned</th>\n",
       "      <th>XGB_gblinear</th>\n",
       "      <th>XGB_gblinear Tuned</th>\n",
       "      <th>XGB_gbtree</th>\n",
       "      <th>XGB_gbtree Tuned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>14.922006</td>\n",
       "      <td>14.877704</td>\n",
       "      <td>16.271584</td>\n",
       "      <td>14.952656</td>\n",
       "      <td>15.061175</td>\n",
       "      <td>14.994800</td>\n",
       "      <td>15.022284</td>\n",
       "      <td>14.882834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>11.580272</td>\n",
       "      <td>11.542386</td>\n",
       "      <td>12.558769</td>\n",
       "      <td>11.602460</td>\n",
       "      <td>11.702807</td>\n",
       "      <td>11.638517</td>\n",
       "      <td>11.632590</td>\n",
       "      <td>11.546377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-squared</th>\n",
       "      <td>0.103555</td>\n",
       "      <td>0.108870</td>\n",
       "      <td>-0.065931</td>\n",
       "      <td>0.099868</td>\n",
       "      <td>0.086755</td>\n",
       "      <td>0.094787</td>\n",
       "      <td>0.091466</td>\n",
       "      <td>0.108255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Adj. R-squared</th>\n",
       "      <td>0.102244</td>\n",
       "      <td>0.107567</td>\n",
       "      <td>-0.067489</td>\n",
       "      <td>0.098552</td>\n",
       "      <td>0.085420</td>\n",
       "      <td>0.093464</td>\n",
       "      <td>0.090137</td>\n",
       "      <td>0.106951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAPE</th>\n",
       "      <td>19.051063</td>\n",
       "      <td>18.937928</td>\n",
       "      <td>20.193462</td>\n",
       "      <td>19.097816</td>\n",
       "      <td>19.184454</td>\n",
       "      <td>19.151850</td>\n",
       "      <td>19.008358</td>\n",
       "      <td>18.931955</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      GBM  GBM Tuned  Random Forest  Random Forest Tuned  \\\n",
       "RMSE            14.922006  14.877704      16.271584            14.952656   \n",
       "MAE             11.580272  11.542386      12.558769            11.602460   \n",
       "R-squared        0.103555   0.108870      -0.065931             0.099868   \n",
       "Adj. R-squared   0.102244   0.107567      -0.067489             0.098552   \n",
       "MAPE            19.051063  18.937928      20.193462            19.097816   \n",
       "\n",
       "                XGB_gblinear  XGB_gblinear Tuned  XGB_gbtree  XGB_gbtree Tuned  \n",
       "RMSE               15.061175           14.994800   15.022284         14.882834  \n",
       "MAE                11.702807           11.638517   11.632590         11.546377  \n",
       "R-squared           0.086755            0.094787    0.091466          0.108255  \n",
       "Adj. R-squared      0.085420            0.093464    0.090137          0.106951  \n",
       "MAPE               19.184454           19.151850   19.008358         18.931955  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 33;\n",
       "                var nbb_unformatted_code = \"# Displaying validation performance of all models\\nprint(\\\"Validation Performance Comparison:\\\")\\nmodels_val_comp_df.sort_index(axis=1)\";\n",
       "                var nbb_formatted_code = \"# Displaying validation performance of all models\\nprint(\\\"Validation Performance Comparison:\\\")\\nmodels_val_comp_df.sort_index(axis=1)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Displaying validation performance of all models\n",
    "print(\"Validation Performance Comparison:\")\n",
    "models_val_comp_df.sort_index(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db377c5d",
   "metadata": {},
   "source": [
    "#### Observations:\n",
    "- *GBM Tuned* has the highest R$^2$ (0.109) on the validation set, followed by *XGB_gbtree Tuned*, then *GBM*.\n",
    "- As we did not include the Decision Tree here, we can ignore Adjusted R$^2$, and just compare R$^2$.\n",
    "- Of the three models with R$^2$ scores over 10, there is some variation in overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9676dad",
   "metadata": {},
   "source": [
    "#### Comparison of Percentage of Overfitting for R$^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "233dce94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of R-square overfitting:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGB_gblinear            -3.243171\n",
       "XGB_gblinear Tuned      -1.826605\n",
       "GBM                      4.808487\n",
       "GBM Tuned               12.868707\n",
       "XGB_gbtree Tuned        15.091493\n",
       "Random Forest Tuned     35.564337\n",
       "XGB_gbtree              52.844295\n",
       "Random Forest          114.428464\n",
       "Name: R-squared, dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 34;\n",
       "                var nbb_unformatted_code = \"# Subtracting the ratio of validation R-square/train R-square from 1\\noverfit_perc = (\\n    1\\n    - (\\n        models_val_comp_df.loc[\\\"R-squared\\\", :]\\n        / models_train_comp_df.loc[\\\"R-squared\\\", :]\\n    )\\n) * 100\\n\\nprint(f\\\"Percentage of R-square overfitting:\\\")\\noverfit_perc.sort_values()\";\n",
       "                var nbb_formatted_code = \"# Subtracting the ratio of validation R-square/train R-square from 1\\noverfit_perc = (\\n    1\\n    - (\\n        models_val_comp_df.loc[\\\"R-squared\\\", :]\\n        / models_train_comp_df.loc[\\\"R-squared\\\", :]\\n    )\\n) * 100\\n\\nprint(f\\\"Percentage of R-square overfitting:\\\")\\noverfit_perc.sort_values()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Subtracting the ratio of validation R-square/train R-square from 1\n",
    "overfit_perc = (\n",
    "    1\n",
    "    - (\n",
    "        models_val_comp_df.loc[\"R-squared\", :]\n",
    "        / models_train_comp_df.loc[\"R-squared\", :]\n",
    "    )\n",
    ") * 100\n",
    "\n",
    "print(f\"Percentage of R-square overfitting:\")\n",
    "overfit_perc.sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b074931e",
   "metadata": {},
   "source": [
    "#### Observations:\n",
    "- *XGB_gblinear* and *XGB_gblinear Tuned* both performed better on the validation set, than the training set, which is interesting.\n",
    "- Of the top 3 models for R$^2$ score, *GBM* generalized considerably better than *GBM Tuned* and *XGB_gtree Tuned*.  \n",
    "- That said, *GBM Tuned* has the highest R$^2$ score on the validation set.\n",
    "- Next we will try another modeling iteration, replacing the one hot encoded `known_for` predictor with the original `known for` category columns.  For linear regression, we had to drop categorical columns to address multicollinearity, so entries with multiple `known for` categories were grouped in the `known_for` feature, into `two` and `three_to_five` classes.  We retained that approach for the above modeling iteration, but for this iteration we will allow entries to have their original multiple categories.  We will also include the `num_categories` feature in this iteration."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31317d01",
   "metadata": {},
   "source": [
    "## 2nd Modeling Iteration with Original `known for` Category Columns and `num_features`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3bec29e",
   "metadata": {},
   "source": [
    "### Defining Independent and Dependent Variables for Train and Validation Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "13c39fb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 54336 rows and 34 columns in the train set.\n",
      "\n",
      "There are 23288 rows and 34 columns in the validation set.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_references</th>\n",
       "      <th>years</th>\n",
       "      <th>sciences</th>\n",
       "      <th>social</th>\n",
       "      <th>spiritual</th>\n",
       "      <th>academia_humanities</th>\n",
       "      <th>business_farming</th>\n",
       "      <th>arts</th>\n",
       "      <th>sports</th>\n",
       "      <th>law_enf_military_operator</th>\n",
       "      <th>politics_govt_law</th>\n",
       "      <th>crime</th>\n",
       "      <th>num_categories</th>\n",
       "      <th>region_Asia</th>\n",
       "      <th>region_Central Asia</th>\n",
       "      <th>region_Europe</th>\n",
       "      <th>region_Mid-Cent America/Caribbean</th>\n",
       "      <th>region_Middle East</th>\n",
       "      <th>region_North America</th>\n",
       "      <th>region_Oceania</th>\n",
       "      <th>region_Russian Federation</th>\n",
       "      <th>region_South America</th>\n",
       "      <th>region_South East Asia</th>\n",
       "      <th>prior_region_Asia</th>\n",
       "      <th>prior_region_Central Asia</th>\n",
       "      <th>prior_region_Europe</th>\n",
       "      <th>prior_region_Mid-Cent America/Caribbean</th>\n",
       "      <th>prior_region_Middle East</th>\n",
       "      <th>prior_region_No Prior Region</th>\n",
       "      <th>prior_region_North America</th>\n",
       "      <th>prior_region_Oceania</th>\n",
       "      <th>prior_region_Russian Federation</th>\n",
       "      <th>prior_region_South America</th>\n",
       "      <th>prior_region_South East Asia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19776</th>\n",
       "      <td>19.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       num_references  years  sciences  social  spiritual  \\\n",
       "19776            19.0   24.0       0.0     0.0        0.0   \n",
       "\n",
       "       academia_humanities  business_farming  arts  sports  \\\n",
       "19776                  0.0               0.0   0.0     0.0   \n",
       "\n",
       "       law_enf_military_operator  politics_govt_law  crime  num_categories  \\\n",
       "19776                        1.0                0.0    0.0             1.0   \n",
       "\n",
       "       region_Asia  region_Central Asia  region_Europe  \\\n",
       "19776          0.0                  0.0            0.0   \n",
       "\n",
       "       region_Mid-Cent America/Caribbean  region_Middle East  \\\n",
       "19776                                0.0                 0.0   \n",
       "\n",
       "       region_North America  region_Oceania  region_Russian Federation  \\\n",
       "19776                   1.0             0.0                        0.0   \n",
       "\n",
       "       region_South America  region_South East Asia  prior_region_Asia  \\\n",
       "19776                   0.0                     0.0                0.0   \n",
       "\n",
       "       prior_region_Central Asia  prior_region_Europe  \\\n",
       "19776                        0.0                  0.0   \n",
       "\n",
       "       prior_region_Mid-Cent America/Caribbean  prior_region_Middle East  \\\n",
       "19776                                      0.0                       0.0   \n",
       "\n",
       "       prior_region_No Prior Region  prior_region_North America  \\\n",
       "19776                           1.0                         0.0   \n",
       "\n",
       "       prior_region_Oceania  prior_region_Russian Federation  \\\n",
       "19776                   0.0                              0.0   \n",
       "\n",
       "       prior_region_South America  prior_region_South East Asia  \n",
       "19776                         0.0                           0.0  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 35;\n",
       "                var nbb_unformatted_code = \"# Creating list of predictor columns\\npredictor_cols = [\\n    \\\"num_references\\\",\\n    \\\"years\\\",\\n    \\\"region\\\",\\n    \\\"prior_region\\\",\\n    \\\"sciences\\\",\\n    \\\"social\\\",\\n    \\\"spiritual\\\",\\n    \\\"academia_humanities\\\",\\n    \\\"business_farming\\\",\\n    \\\"arts\\\",\\n    \\\"sports\\\",\\n    \\\"law_enf_military_operator\\\",\\n    \\\"politics_govt_law\\\",\\n    \\\"crime\\\",\\n    \\\"num_categories\\\",\\n]\\n\\n# Defining target column\\ntarget = \\\"age\\\"\\n\\n# Defining independent and dependent variables\\nX = df[predictor_cols]\\ny = df[target]\\n\\n# One hot encoding of categorical predictors and typecasting all predictors as float\\nX = pd.get_dummies(X, drop_first=True).astype(\\\"float64\\\")\\n\\n# Splitting into 70:30 train and validation sets\\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=42)\\n\\n# Checking shape of train and validation sets\\nprint(\\n    f\\\"There are {X_train.shape[0]} rows and {X_train.shape[1]} columns in the train set.\\\\n\\\"\\n)\\nprint(\\n    f\\\"There are {X_val.shape[0]} rows and {X_val.shape[1]} columns in the validation set.\\\\n\\\"\\n)\\n\\n# Checking a sample\\nX_train.sample()\";\n",
       "                var nbb_formatted_code = \"# Creating list of predictor columns\\npredictor_cols = [\\n    \\\"num_references\\\",\\n    \\\"years\\\",\\n    \\\"region\\\",\\n    \\\"prior_region\\\",\\n    \\\"sciences\\\",\\n    \\\"social\\\",\\n    \\\"spiritual\\\",\\n    \\\"academia_humanities\\\",\\n    \\\"business_farming\\\",\\n    \\\"arts\\\",\\n    \\\"sports\\\",\\n    \\\"law_enf_military_operator\\\",\\n    \\\"politics_govt_law\\\",\\n    \\\"crime\\\",\\n    \\\"num_categories\\\",\\n]\\n\\n# Defining target column\\ntarget = \\\"age\\\"\\n\\n# Defining independent and dependent variables\\nX = df[predictor_cols]\\ny = df[target]\\n\\n# One hot encoding of categorical predictors and typecasting all predictors as float\\nX = pd.get_dummies(X, drop_first=True).astype(\\\"float64\\\")\\n\\n# Splitting into 70:30 train and validation sets\\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=42)\\n\\n# Checking shape of train and validation sets\\nprint(\\n    f\\\"There are {X_train.shape[0]} rows and {X_train.shape[1]} columns in the train set.\\\\n\\\"\\n)\\nprint(\\n    f\\\"There are {X_val.shape[0]} rows and {X_val.shape[1]} columns in the validation set.\\\\n\\\"\\n)\\n\\n# Checking a sample\\nX_train.sample()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Creating list of predictor columns\n",
    "predictor_cols = [\n",
    "    \"num_references\",\n",
    "    \"years\",\n",
    "    \"region\",\n",
    "    \"prior_region\",\n",
    "    \"sciences\",\n",
    "    \"social\",\n",
    "    \"spiritual\",\n",
    "    \"academia_humanities\",\n",
    "    \"business_farming\",\n",
    "    \"arts\",\n",
    "    \"sports\",\n",
    "    \"law_enf_military_operator\",\n",
    "    \"politics_govt_law\",\n",
    "    \"crime\",\n",
    "    \"num_categories\",\n",
    "]\n",
    "\n",
    "# Defining target column\n",
    "target = \"age\"\n",
    "\n",
    "# Defining independent and dependent variables\n",
    "X = df[predictor_cols]\n",
    "y = df[target]\n",
    "\n",
    "# One hot encoding of categorical predictors and typecasting all predictors as float\n",
    "X = pd.get_dummies(X, drop_first=True).astype(\"float64\")\n",
    "\n",
    "# Splitting into 70:30 train and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Checking shape of train and validation sets\n",
    "print(\n",
    "    f\"There are {X_train.shape[0]} rows and {X_train.shape[1]} columns in the train set.\\n\"\n",
    ")\n",
    "print(\n",
    "    f\"There are {X_val.shape[0]} rows and {X_val.shape[1]} columns in the validation set.\\n\"\n",
    ")\n",
    "\n",
    "# Checking a sample\n",
    "X_train.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f2d0b7",
   "metadata": {},
   "source": [
    "#### Defining Scorer for Cross-validation and Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "091141e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 36;\n",
       "                var nbb_unformatted_code = \"# Type of scoring used to compare parameter combinations--maximizing Adj R-squared\\nscorer = \\\"r2\\\"\";\n",
       "                var nbb_formatted_code = \"# Type of scoring used to compare parameter combinations--maximizing Adj R-squared\\nscorer = \\\"r2\\\"\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Type of scoring used to compare parameter combinations--maximizing Adj R-squared\n",
    "scorer = \"r2\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1737ee02",
   "metadata": {},
   "source": [
    "### Building the Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c72709d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cross-Validation:\n",
      "\n",
      "Dtree2: -0.39988031150791087\n",
      "Random Forest2: -0.055391943965687626\n",
      "Bagging Dtree2: -0.09151226074998306\n",
      "GBM2: 0.10458496917399238\n",
      "AdaBoost Dtree2: -0.04659101299906472\n",
      "XGB_gbtree2: 0.09199892946363704\n",
      "XGB_gblinear2: 0.08892135565755814\n",
      "\n",
      "Validation Performance:\n",
      "\n",
      "Dtree2: -0.3874580410488391\n",
      "Random Forest2: -0.05737130520636269\n",
      "Bagging Dtree2: -0.09428953449035293\n",
      "GBM2: 0.10690165941428653\n",
      "AdaBoost Dtree2: -0.08047644155074885\n",
      "XGB_gbtree2: 0.09741681484821774\n",
      "XGB_gblinear2: 0.09099787528674863\n",
      "CPU times: total: 4min 26s\n",
      "Wall time: 1min 20s\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 37;\n",
       "                var nbb_unformatted_code = \"%%time\\n\\n# Creating list to store the models\\nmodels = []\\n\\n# Appending models to the list\\nmodels.append(('Dtree2', DecisionTreeRegressor(random_state=42)))\\n\\nmodels.append(('Random Forest2', RandomForestRegressor(random_state=42)))\\n\\nmodels.append(('Bagging Dtree2', BaggingRegressor(random_state=42)))\\n\\nmodels.append(('GBM2', GradientBoostingRegressor(random_state=42)))\\n\\nmodels.append(('AdaBoost Dtree2', AdaBoostRegressor(random_state=42)))\\n\\nmodels.append(('XGB_gbtree2', XGBRegressor(random_state=42)))\\n\\nmodels.append(('XGB_gblinear2', XGBRegressor(random_state=42, booster='gblinear')))\\n\\n# Create empty list to store all model's names and CV scores\\nnames = []\\nresults = []\\n\\n# Loop through all models to get the mean cross validated score\\nprint(\\\"\\\\n\\\" \\\"Cross-Validation:\\\" \\\"\\\\n\\\")\\n\\nfor name, model in models:\\n    cv_result = cross_val_score(\\n        estimator=model, X=X_train, y=y_train, scoring=scorer, cv=5\\n    )\\n    results.append(cv_result)\\n    names.append(name)\\n    print(f\\\"{name}: {cv_result.mean()}\\\")\\n    \\nprint(\\\"\\\\n\\\" \\\"Validation Performance:\\\" \\\"\\\\n\\\")\\n\\nfor name, model in models:\\n    model.fit(X_train, y_train)\\n    scores = r2_score(y_val, model.predict(X_val))\\n    print(\\\"{}: {}\\\".format(name, scores))\";\n",
       "                var nbb_formatted_code = \"%%time\\n\\n# Creating list to store the models\\nmodels = []\\n\\n# Appending models to the list\\nmodels.append(('Dtree2', DecisionTreeRegressor(random_state=42)))\\n\\nmodels.append(('Random Forest2', RandomForestRegressor(random_state=42)))\\n\\nmodels.append(('Bagging Dtree2', BaggingRegressor(random_state=42)))\\n\\nmodels.append(('GBM2', GradientBoostingRegressor(random_state=42)))\\n\\nmodels.append(('AdaBoost Dtree2', AdaBoostRegressor(random_state=42)))\\n\\nmodels.append(('XGB_gbtree2', XGBRegressor(random_state=42)))\\n\\nmodels.append(('XGB_gblinear2', XGBRegressor(random_state=42, booster='gblinear')))\\n\\n# Create empty list to store all model's names and CV scores\\nnames = []\\nresults = []\\n\\n# Loop through all models to get the mean cross validated score\\nprint(\\\"\\\\n\\\" \\\"Cross-Validation:\\\" \\\"\\\\n\\\")\\n\\nfor name, model in models:\\n    cv_result = cross_val_score(\\n        estimator=model, X=X_train, y=y_train, scoring=scorer, cv=5\\n    )\\n    results.append(cv_result)\\n    names.append(name)\\n    print(f\\\"{name}: {cv_result.mean()}\\\")\\n    \\nprint(\\\"\\\\n\\\" \\\"Validation Performance:\\\" \\\"\\\\n\\\")\\n\\nfor name, model in models:\\n    model.fit(X_train, y_train)\\n    scores = r2_score(y_val, model.predict(X_val))\\n    print(\\\"{}: {}\\\".format(name, scores))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Creating list to store the models\n",
    "models = []\n",
    "\n",
    "# Appending models to the list\n",
    "models.append(('Dtree2', DecisionTreeRegressor(random_state=42)))\n",
    "\n",
    "models.append(('Random Forest2', RandomForestRegressor(random_state=42)))\n",
    "\n",
    "models.append(('Bagging Dtree2', BaggingRegressor(random_state=42)))\n",
    "\n",
    "models.append(('GBM2', GradientBoostingRegressor(random_state=42)))\n",
    "\n",
    "models.append(('AdaBoost Dtree2', AdaBoostRegressor(random_state=42)))\n",
    "\n",
    "models.append(('XGB_gbtree2', XGBRegressor(random_state=42)))\n",
    "\n",
    "models.append(('XGB_gblinear2', XGBRegressor(random_state=42, booster='gblinear')))\n",
    "\n",
    "# Create empty list to store all model's names and CV scores\n",
    "names = []\n",
    "results = []\n",
    "\n",
    "# Loop through all models to get the mean cross validated score\n",
    "print(\"\\n\" \"Cross-Validation:\" \"\\n\")\n",
    "\n",
    "for name, model in models:\n",
    "    cv_result = cross_val_score(\n",
    "        estimator=model, X=X_train, y=y_train, scoring=scorer, cv=5\n",
    "    )\n",
    "    results.append(cv_result)\n",
    "    names.append(name)\n",
    "    print(f\"{name}: {cv_result.mean()}\")\n",
    "    \n",
    "print(\"\\n\" \"Validation Performance:\" \"\\n\")\n",
    "\n",
    "for name, model in models:\n",
    "    model.fit(X_train, y_train)\n",
    "    scores = r2_score(y_val, model.predict(X_val))\n",
    "    print(\"{}: {}\".format(name, scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8c8051d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x504 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 38;\n",
       "                var nbb_unformatted_code = \"# Plotting boxplots for CV scores of all models defined above\\nfig = plt.figure(figsize=(20, 7))\\n\\nfig.suptitle(\\\"Algorithm Comparison for Cross-validation R-squared Score\\\")\\nax = fig.add_subplot(111)\\n\\nplt.boxplot(results)\\nax.set_xticklabels(names)\\nplt.xticks(rotation=30)\\n\\nplt.show()\";\n",
       "                var nbb_formatted_code = \"# Plotting boxplots for CV scores of all models defined above\\nfig = plt.figure(figsize=(20, 7))\\n\\nfig.suptitle(\\\"Algorithm Comparison for Cross-validation R-squared Score\\\")\\nax = fig.add_subplot(111)\\n\\nplt.boxplot(results)\\nax.set_xticklabels(names)\\nplt.xticks(rotation=30)\\n\\nplt.show()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting boxplots for CV scores of all models defined above\n",
    "fig = plt.figure(figsize=(20, 7))\n",
    "\n",
    "fig.suptitle(\"Algorithm Comparison for Cross-validation R-squared Score\")\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "plt.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "plt.xticks(rotation=30)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad83c51d",
   "metadata": {},
   "source": [
    "#### Observations:\n",
    "- So far, the performances are similar to the first modeling iteration above.\n",
    "- We will perform hyperparameter tuning on the top 3 models and again keep *Random Forest2* in the mix, also."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17777769",
   "metadata": {},
   "source": [
    "#### Collecting Models with Best Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "31644f82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 39;\n",
       "                var nbb_unformatted_code = \"# List of top models so far\\ntop_models = [models[1]] + [models[3]] + models[-2:]\";\n",
       "                var nbb_formatted_code = \"# List of top models so far\\ntop_models = [models[1]] + [models[3]] + models[-2:]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# List of top models so far\n",
    "top_models = [models[1]] + [models[3]] + models[-2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf8ed15",
   "metadata": {},
   "source": [
    "#### Creating Dataframes to Compare Training and Validation Performance of Best Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "eac3f2e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 40;\n",
       "                var nbb_unformatted_code = \"# Creating empty dictionary to hold the models\\nmodels_to_tune = {}\\n\\n# For loop to add models to dictionary\\nfor model in top_models:\\n    key = model[0]\\n    value = model[1]\\n    models_to_tune[key] = value\\n\\n# For loop to add performance results of each top model\\nfor name, model in models_to_tune.items():\\n    models_train_comp_df[name] = model_performance_regression(model, X_train, y_train).T\\n    models_val_comp_df[name] = model_performance_regression(model, X_val, y_val).T\";\n",
       "                var nbb_formatted_code = \"# Creating empty dictionary to hold the models\\nmodels_to_tune = {}\\n\\n# For loop to add models to dictionary\\nfor model in top_models:\\n    key = model[0]\\n    value = model[1]\\n    models_to_tune[key] = value\\n\\n# For loop to add performance results of each top model\\nfor name, model in models_to_tune.items():\\n    models_train_comp_df[name] = model_performance_regression(model, X_train, y_train).T\\n    models_val_comp_df[name] = model_performance_regression(model, X_val, y_val).T\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Creating empty dictionary to hold the models\n",
    "models_to_tune = {}\n",
    "\n",
    "# For loop to add models to dictionary\n",
    "for model in top_models:\n",
    "    key = model[0]\n",
    "    value = model[1]\n",
    "    models_to_tune[key] = value\n",
    "\n",
    "# For loop to add performance results of each top model\n",
    "for name, model in models_to_tune.items():\n",
    "    models_train_comp_df[name] = model_performance_regression(model, X_train, y_train).T\n",
    "    models_val_comp_df[name] = model_performance_regression(model, X_val, y_val).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17466a60",
   "metadata": {},
   "source": [
    "#### Comparing Top Models Before Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d7a2bc20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Performance:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Random Forest2</th>\n",
       "      <th>GBM2</th>\n",
       "      <th>XGB_gbtree2</th>\n",
       "      <th>XGB_gblinear2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>11.328976</td>\n",
       "      <td>14.937480</td>\n",
       "      <td>14.196740</td>\n",
       "      <td>15.129664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>8.362030</td>\n",
       "      <td>11.599899</td>\n",
       "      <td>10.984573</td>\n",
       "      <td>11.741451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-squared</th>\n",
       "      <td>0.489686</td>\n",
       "      <td>0.112822</td>\n",
       "      <td>0.198629</td>\n",
       "      <td>0.089846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Adj. R-squared</th>\n",
       "      <td>0.489367</td>\n",
       "      <td>0.112266</td>\n",
       "      <td>0.198128</td>\n",
       "      <td>0.089276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAPE</th>\n",
       "      <td>13.404005</td>\n",
       "      <td>19.178492</td>\n",
       "      <td>17.982195</td>\n",
       "      <td>19.384544</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Random Forest2       GBM2  XGB_gbtree2  XGB_gblinear2\n",
       "RMSE                 11.328976  14.937480    14.196740      15.129664\n",
       "MAE                   8.362030  11.599899    10.984573      11.741451\n",
       "R-squared             0.489686   0.112822     0.198629       0.089846\n",
       "Adj. R-squared        0.489367   0.112266     0.198128       0.089276\n",
       "MAPE                 13.404005  19.178492    17.982195      19.384544"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 41;\n",
       "                var nbb_unformatted_code = \"# Comparing train performance\\nprint(f\\\"Training Performance:\\\")\\nmodels_train_comp_df[[key for key in models_to_tune.keys()]]\";\n",
       "                var nbb_formatted_code = \"# Comparing train performance\\nprint(f\\\"Training Performance:\\\")\\nmodels_train_comp_df[[key for key in models_to_tune.keys()]]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Comparing train performance\n",
    "print(f\"Training Performance:\")\n",
    "models_train_comp_df[[key for key in models_to_tune.keys()]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2afc9145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Performance:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Random Forest2</th>\n",
       "      <th>GBM2</th>\n",
       "      <th>XGB_gbtree2</th>\n",
       "      <th>XGB_gblinear2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>16.206121</td>\n",
       "      <td>14.894124</td>\n",
       "      <td>14.973004</td>\n",
       "      <td>15.026151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>12.476262</td>\n",
       "      <td>11.552854</td>\n",
       "      <td>11.582826</td>\n",
       "      <td>11.654557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-squared</th>\n",
       "      <td>-0.057371</td>\n",
       "      <td>0.106902</td>\n",
       "      <td>0.097417</td>\n",
       "      <td>0.090998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Adj. R-squared</th>\n",
       "      <td>-0.058917</td>\n",
       "      <td>0.105596</td>\n",
       "      <td>0.096097</td>\n",
       "      <td>0.089669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAPE</th>\n",
       "      <td>20.071146</td>\n",
       "      <td>19.011210</td>\n",
       "      <td>18.941080</td>\n",
       "      <td>19.158585</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Random Forest2       GBM2  XGB_gbtree2  XGB_gblinear2\n",
       "RMSE                 16.206121  14.894124    14.973004      15.026151\n",
       "MAE                  12.476262  11.552854    11.582826      11.654557\n",
       "R-squared            -0.057371   0.106902     0.097417       0.090998\n",
       "Adj. R-squared       -0.058917   0.105596     0.096097       0.089669\n",
       "MAPE                 20.071146  19.011210    18.941080      19.158585"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 42;\n",
       "                var nbb_unformatted_code = \"# Comparing validation performance\\nprint(f\\\"Validation Performance:\\\")\\nmodels_val_comp_df[[key for key in models_to_tune.keys()]]\";\n",
       "                var nbb_formatted_code = \"# Comparing validation performance\\nprint(f\\\"Validation Performance:\\\")\\nmodels_val_comp_df[[key for key in models_to_tune.keys()]]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Comparing validation performance\n",
    "print(f\"Validation Performance:\")\n",
    "models_val_comp_df[[key for key in models_to_tune.keys()]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e812ca",
   "metadata": {},
   "source": [
    "#### Observations:\n",
    "- Here, we compare the performance on the whole train set to the validation set.\n",
    "- As with the first iteration above, only *GBM2* and *XGB_gblinear2* are giving generalized performances on the two sets.\n",
    "- We will proceed with hyperparameter tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59aace1",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c9645e8",
   "metadata": {},
   "source": [
    "### *Random Forest2 Tuned*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fdc0fd0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(random_state=42)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 43;\n",
       "                var nbb_unformatted_code = \"# Confirming the model\\nmodels_to_tune[\\\"Random Forest2\\\"]\";\n",
       "                var nbb_formatted_code = \"# Confirming the model\\nmodels_to_tune[\\\"Random Forest2\\\"]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Confirming the model\n",
    "models_to_tune[\"Random Forest2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c0c1d615",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Teres\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "5 fits failed out of a total of 50.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Teres\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Teres\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 450, in fit\n",
      "    trees = Parallel(\n",
      "  File \"C:\\Users\\Teres\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Teres\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Teres\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Teres\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Teres\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Teres\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Teres\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Teres\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 216, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\Teres\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 185, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Teres\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1315, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\Teres\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 241, in fit\n",
      "    if not 0.0 < self.min_samples_leaf <= 0.5:\n",
      "TypeError: '<' not supported between instances of 'float' and 'NoneType'\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\Teres\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.10342598 0.10211994 0.10160088 0.10362196 0.05381091 0.10627175\n",
      " 0.10560085 0.10495005        nan 0.09923682]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters are {'criterion': 'squared_error', 'max_depth': None, 'max_features': 'sqrt', 'max_samples': 0.7162213204002108, 'min_samples_leaf': 5, 'n_estimators': 485} with CV score=0.10627175102316326:\n",
      "CPU times: total: 7.36 s\n",
      "Wall time: 58.1 s\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 44;\n",
       "                var nbb_unformatted_code = \"%%time\\n\\n# Defining model\\nModel = RandomForestRegressor(random_state=42)\\n\\n# Parameter grid to pass in RandomizedSearchCV\\nparam_grid = { \\n    \\\"n_estimators\\\": np.arange(100, 500), \\n    \\\"min_samples_leaf\\\": [None] + np.arange(1, 10).tolist(),\\n    \\\"max_features\\\": ['sqrt'], \\n    \\\"max_samples\\\": uniform(loc=0.3, scale=0.5),\\n    'criterion': ['squared_error'],\\n    \\\"max_depth\\\": [None]\\n}\\n\\n# Calling RandomizedSearchCV\\nrandomized_cv = RandomizedSearchCV(\\n    estimator=Model,\\n    param_distributions=param_grid,\\n    n_iter=10,\\n    n_jobs=-1,\\n    scoring=scorer,\\n    cv=5,\\n    random_state=42,\\n)\\n\\n# Fitting parameters in RandomizedSearchCV\\nrandomized_cv.fit(X_train, y_train)\\n\\nprint(\\n    \\\"Best parameters are {} with CV score={}:\\\".format(\\n        randomized_cv.best_params_, randomized_cv.best_score_\\n    )\\n)\\n\\n# Chime notification when cell successfully executes\\nchime.success()\";\n",
       "                var nbb_formatted_code = \"%%time\\n\\n# Defining model\\nModel = RandomForestRegressor(random_state=42)\\n\\n# Parameter grid to pass in RandomizedSearchCV\\nparam_grid = { \\n    \\\"n_estimators\\\": np.arange(100, 500), \\n    \\\"min_samples_leaf\\\": [None] + np.arange(1, 10).tolist(),\\n    \\\"max_features\\\": ['sqrt'], \\n    \\\"max_samples\\\": uniform(loc=0.3, scale=0.5),\\n    'criterion': ['squared_error'],\\n    \\\"max_depth\\\": [None]\\n}\\n\\n# Calling RandomizedSearchCV\\nrandomized_cv = RandomizedSearchCV(\\n    estimator=Model,\\n    param_distributions=param_grid,\\n    n_iter=10,\\n    n_jobs=-1,\\n    scoring=scorer,\\n    cv=5,\\n    random_state=42,\\n)\\n\\n# Fitting parameters in RandomizedSearchCV\\nrandomized_cv.fit(X_train, y_train)\\n\\nprint(\\n    \\\"Best parameters are {} with CV score={}:\\\".format(\\n        randomized_cv.best_params_, randomized_cv.best_score_\\n    )\\n)\\n\\n# Chime notification when cell successfully executes\\nchime.success()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Defining model\n",
    "Model = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Parameter grid to pass in RandomizedSearchCV\n",
    "param_grid = { \n",
    "    \"n_estimators\": np.arange(100, 500), \n",
    "    \"min_samples_leaf\": [None] + np.arange(1, 10).tolist(),\n",
    "    \"max_features\": ['sqrt'], \n",
    "    \"max_samples\": uniform(loc=0.3, scale=0.5),\n",
    "    'criterion': ['squared_error'],\n",
    "    \"max_depth\": [None]\n",
    "}\n",
    "\n",
    "# Calling RandomizedSearchCV\n",
    "randomized_cv = RandomizedSearchCV(\n",
    "    estimator=Model,\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=10,\n",
    "    n_jobs=-1,\n",
    "    scoring=scorer,\n",
    "    cv=5,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "# Fitting parameters in RandomizedSearchCV\n",
    "randomized_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\n",
    "    \"Best parameters are {} with CV score={}:\".format(\n",
    "        randomized_cv.best_params_, randomized_cv.best_score_\n",
    "    )\n",
    ")\n",
    "\n",
    "# Chime notification when cell successfully executes\n",
    "chime.success()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ff8ed9c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(max_features='sqrt', max_samples=0.7162213204002108,\n",
       "                      min_samples_leaf=5, n_estimators=485)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 45;\n",
       "                var nbb_unformatted_code = \"# Building model with best parameters\\nRandom_Forest2_tuned = RandomForestRegressor(\\n    criterion=\\\"squared_error\\\",\\n    max_depth=None,\\n    max_features=\\\"sqrt\\\",\\n    max_samples=0.7162213204002108,\\n    min_samples_leaf=5,\\n    n_estimators=485,\\n)\\n\\n# Fit the model on training data\\nRandom_Forest2_tuned.fit(X_train, y_train)\";\n",
       "                var nbb_formatted_code = \"# Building model with best parameters\\nRandom_Forest2_tuned = RandomForestRegressor(\\n    criterion=\\\"squared_error\\\",\\n    max_depth=None,\\n    max_features=\\\"sqrt\\\",\\n    max_samples=0.7162213204002108,\\n    min_samples_leaf=5,\\n    n_estimators=485,\\n)\\n\\n# Fit the model on training data\\nRandom_Forest2_tuned.fit(X_train, y_train)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Building model with best parameters\n",
    "Random_Forest2_tuned = RandomForestRegressor(\n",
    "    criterion=\"squared_error\",\n",
    "    max_depth=None,\n",
    "    max_features=\"sqrt\",\n",
    "    max_samples=0.7162213204002108,\n",
    "    min_samples_leaf=5,\n",
    "    n_estimators=485,\n",
    ")\n",
    "\n",
    "# Fit the model on training data\n",
    "Random_Forest2_tuned.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7bb844d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training performance:\n",
      "         RMSE        MAE  R-squared  Adj. R-squared       MAPE\n",
      "0  14.485455  11.250801   0.165703        0.165181  18.596652\n",
      "\n",
      "Validation performance:\n",
      "         RMSE        MAE  R-squared  Adj. R-squared       MAPE\n",
      "0  14.906245  11.559593   0.105447        0.104139  19.019887\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 46;\n",
       "                var nbb_unformatted_code = \"# Calculating different metrics\\nRandom_Forest2_tuned_train_perf = model_performance_regression(\\n    Random_Forest2_tuned, X_train, y_train\\n)\\nprint(\\\"Training performance:\\\\n\\\", Random_Forest2_tuned_train_perf)\\nRandom_Forest2_tuned_val_perf = model_performance_regression(\\n    Random_Forest2_tuned, X_val, y_val\\n)\\nprint(\\\"\\\\nValidation performance:\\\\n\\\", Random_Forest2_tuned_val_perf)\\n\\n# Adding model to model comparison dataframes\\nmodels_train_comp_df[\\\"Random Forest2 Tuned\\\"] = Random_Forest2_tuned_train_perf.T\\nmodels_val_comp_df[\\\"Random Forest2 Tuned\\\"] = Random_Forest2_tuned_val_perf.T\";\n",
       "                var nbb_formatted_code = \"# Calculating different metrics\\nRandom_Forest2_tuned_train_perf = model_performance_regression(\\n    Random_Forest2_tuned, X_train, y_train\\n)\\nprint(\\\"Training performance:\\\\n\\\", Random_Forest2_tuned_train_perf)\\nRandom_Forest2_tuned_val_perf = model_performance_regression(\\n    Random_Forest2_tuned, X_val, y_val\\n)\\nprint(\\\"\\\\nValidation performance:\\\\n\\\", Random_Forest2_tuned_val_perf)\\n\\n# Adding model to model comparison dataframes\\nmodels_train_comp_df[\\\"Random Forest2 Tuned\\\"] = Random_Forest2_tuned_train_perf.T\\nmodels_val_comp_df[\\\"Random Forest2 Tuned\\\"] = Random_Forest2_tuned_val_perf.T\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculating different metrics\n",
    "Random_Forest2_tuned_train_perf = model_performance_regression(\n",
    "    Random_Forest2_tuned, X_train, y_train\n",
    ")\n",
    "print(\"Training performance:\\n\", Random_Forest2_tuned_train_perf)\n",
    "Random_Forest2_tuned_val_perf = model_performance_regression(\n",
    "    Random_Forest2_tuned, X_val, y_val\n",
    ")\n",
    "print(\"\\nValidation performance:\\n\", Random_Forest2_tuned_val_perf)\n",
    "\n",
    "# Adding model to model comparison dataframes\n",
    "models_train_comp_df[\"Random Forest2 Tuned\"] = Random_Forest2_tuned_train_perf.T\n",
    "models_val_comp_df[\"Random Forest2 Tuned\"] = Random_Forest2_tuned_val_perf.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd5517f3",
   "metadata": {},
   "source": [
    "#### Observations:\n",
    "- Hyperparameter tuning improved performance for *Random Forest2*.\n",
    "- The algorithm is still overfitting the train set, compared to the validation set.\n",
    "- Note that we again had a 10% fit fail during cross-validation (\"UserWarning: One or more of the test scores are non-finite..\") indicating cross-validation had some folds for which hyperparameter combinations led to Nan values.  We are going to allow it here, and go with the results of the successful iterations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3bbffed",
   "metadata": {},
   "source": [
    "### *GBM2 Tuned*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5a7278d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(random_state=42)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 47;\n",
       "                var nbb_unformatted_code = \"# Confirming the model\\nmodels_to_tune[\\\"GBM2\\\"]\";\n",
       "                var nbb_formatted_code = \"# Confirming the model\\nmodels_to_tune[\\\"GBM2\\\"]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Confirming the model\n",
    "models_to_tune[\"GBM2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "164a6ac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters are {'learning_rate': 0.08171272700715591, 'max_features': 0.6630456668613307, 'n_estimators': 368, 'subsample': 0.7847684335570795} with CV score=0.11041556668246581:\n",
      "CPU times: total: 14.8 s\n",
      "Wall time: 7min 27s\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 48;\n",
       "                var nbb_unformatted_code = \"%%time\\n\\n# Defining model\\nModel = GradientBoostingRegressor(random_state=42)\\n\\n# Parameter grid to pass in RandomizedSearchCV\\nparam_grid = {\\n    \\\"n_estimators\\\": np.arange(100, 500),\\n    \\\"learning_rate\\\": loguniform(0.001, 1),\\n    \\\"subsample\\\": uniform(loc=0.3, scale=0.5),\\n    \\\"max_features\\\": uniform(loc=0.3, scale=0.5),\\n}\\n\\n# Calling RandomizedSearchCV\\nrandomized_cv = RandomizedSearchCV(\\n    estimator=Model,\\n    param_distributions=param_grid,\\n    n_iter=100,\\n    n_jobs=-1,\\n    scoring=scorer,\\n    cv=5,\\n    random_state=42,\\n)\\n\\n# Fitting parameters in RandomizedSearchCV\\nrandomized_cv.fit(X_train, y_train)\\n\\nprint(\\n    \\\"Best parameters are {} with CV score={}:\\\".format(\\n        randomized_cv.best_params_, randomized_cv.best_score_\\n    )\\n)\\n\\n# Chime notification when cell successfully executes\\nchime.success()\";\n",
       "                var nbb_formatted_code = \"%%time\\n\\n# Defining model\\nModel = GradientBoostingRegressor(random_state=42)\\n\\n# Parameter grid to pass in RandomizedSearchCV\\nparam_grid = {\\n    \\\"n_estimators\\\": np.arange(100, 500),\\n    \\\"learning_rate\\\": loguniform(0.001, 1),\\n    \\\"subsample\\\": uniform(loc=0.3, scale=0.5),\\n    \\\"max_features\\\": uniform(loc=0.3, scale=0.5),\\n}\\n\\n# Calling RandomizedSearchCV\\nrandomized_cv = RandomizedSearchCV(\\n    estimator=Model,\\n    param_distributions=param_grid,\\n    n_iter=100,\\n    n_jobs=-1,\\n    scoring=scorer,\\n    cv=5,\\n    random_state=42,\\n)\\n\\n# Fitting parameters in RandomizedSearchCV\\nrandomized_cv.fit(X_train, y_train)\\n\\nprint(\\n    \\\"Best parameters are {} with CV score={}:\\\".format(\\n        randomized_cv.best_params_, randomized_cv.best_score_\\n    )\\n)\\n\\n# Chime notification when cell successfully executes\\nchime.success()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Defining model\n",
    "Model = GradientBoostingRegressor(random_state=42)\n",
    "\n",
    "# Parameter grid to pass in RandomizedSearchCV\n",
    "param_grid = {\n",
    "    \"n_estimators\": np.arange(100, 500),\n",
    "    \"learning_rate\": loguniform(0.001, 1),\n",
    "    \"subsample\": uniform(loc=0.3, scale=0.5),\n",
    "    \"max_features\": uniform(loc=0.3, scale=0.5),\n",
    "}\n",
    "\n",
    "# Calling RandomizedSearchCV\n",
    "randomized_cv = RandomizedSearchCV(\n",
    "    estimator=Model,\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=100,\n",
    "    n_jobs=-1,\n",
    "    scoring=scorer,\n",
    "    cv=5,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "# Fitting parameters in RandomizedSearchCV\n",
    "randomized_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\n",
    "    \"Best parameters are {} with CV score={}:\".format(\n",
    "        randomized_cv.best_params_, randomized_cv.best_score_\n",
    "    )\n",
    ")\n",
    "\n",
    "# Chime notification when cell successfully executes\n",
    "chime.success()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "83072624",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(learning_rate=0.08171272700715591,\n",
       "                          max_features=0.6630456668613307, n_estimators=368,\n",
       "                          random_state=42, subsample=0.7847684335570795)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 49;\n",
       "                var nbb_unformatted_code = \"# Building model with best parameters\\nGBM2_tuned = GradientBoostingRegressor(\\n    random_state=42,\\n    learning_rate=0.08171272700715591,\\n    max_features=0.6630456668613307,\\n    n_estimators=368,\\n    subsample=0.7847684335570795,\\n)\\n\\n# Fit the model on training data\\nGBM2_tuned.fit(X_train, y_train)\";\n",
       "                var nbb_formatted_code = \"# Building model with best parameters\\nGBM2_tuned = GradientBoostingRegressor(\\n    random_state=42,\\n    learning_rate=0.08171272700715591,\\n    max_features=0.6630456668613307,\\n    n_estimators=368,\\n    subsample=0.7847684335570795,\\n)\\n\\n# Fit the model on training data\\nGBM2_tuned.fit(X_train, y_train)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Building model with best parameters\n",
    "GBM2_tuned = GradientBoostingRegressor(\n",
    "    random_state=42,\n",
    "    learning_rate=0.08171272700715591,\n",
    "    max_features=0.6630456668613307,\n",
    "    n_estimators=368,\n",
    "    subsample=0.7847684335570795,\n",
    ")\n",
    "\n",
    "# Fit the model on training data\n",
    "GBM2_tuned.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "41f9f376",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training performance:\n",
      "         RMSE       MAE  R-squared  Adj. R-squared      MAPE\n",
      "0  14.803396  11.49037   0.128678        0.128132  18.95094\n",
      "\n",
      "Validation performance:\n",
      "         RMSE        MAE  R-squared  Adj. R-squared       MAPE\n",
      "0  14.853802  11.512155   0.111731        0.110432  18.898856\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 50;\n",
       "                var nbb_unformatted_code = \"# Calculating different metrics\\nGBM2_tuned_train_perf = model_performance_regression(GBM2_tuned, X_train, y_train)\\nprint(\\\"Training performance:\\\\n\\\", GBM2_tuned_train_perf)\\nGBM2_tuned_val_perf = model_performance_regression(GBM2_tuned, X_val, y_val)\\nprint(\\\"\\\\nValidation performance:\\\\n\\\", GBM2_tuned_val_perf)\\n\\n# Adding model to model comparison dataframes\\nmodels_train_comp_df[\\\"GBM2 Tuned\\\"] = GBM2_tuned_train_perf.T\\nmodels_val_comp_df[\\\"GBM2 Tuned\\\"] = GBM2_tuned_val_perf.T\";\n",
       "                var nbb_formatted_code = \"# Calculating different metrics\\nGBM2_tuned_train_perf = model_performance_regression(GBM2_tuned, X_train, y_train)\\nprint(\\\"Training performance:\\\\n\\\", GBM2_tuned_train_perf)\\nGBM2_tuned_val_perf = model_performance_regression(GBM2_tuned, X_val, y_val)\\nprint(\\\"\\\\nValidation performance:\\\\n\\\", GBM2_tuned_val_perf)\\n\\n# Adding model to model comparison dataframes\\nmodels_train_comp_df[\\\"GBM2 Tuned\\\"] = GBM2_tuned_train_perf.T\\nmodels_val_comp_df[\\\"GBM2 Tuned\\\"] = GBM2_tuned_val_perf.T\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculating different metrics\n",
    "GBM2_tuned_train_perf = model_performance_regression(GBM2_tuned, X_train, y_train)\n",
    "print(\"Training performance:\\n\", GBM2_tuned_train_perf)\n",
    "GBM2_tuned_val_perf = model_performance_regression(GBM2_tuned, X_val, y_val)\n",
    "print(\"\\nValidation performance:\\n\", GBM2_tuned_val_perf)\n",
    "\n",
    "# Adding model to model comparison dataframes\n",
    "models_train_comp_df[\"GBM2 Tuned\"] = GBM2_tuned_train_perf.T\n",
    "models_val_comp_df[\"GBM2 Tuned\"] = GBM2_tuned_val_perf.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d33085",
   "metadata": {},
   "source": [
    "#### Observations:\n",
    "- The performance for *GBM2* is improved with hyperparameter tuning.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ea9612",
   "metadata": {},
   "source": [
    "### *XGB_gbtree2 Tuned*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "629f0ae4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', callbacks=None,\n",
       "             colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "             early_stopping_rounds=None, enable_categorical=False,\n",
       "             eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n",
       "             importance_type=None, interaction_constraints='',\n",
       "             learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n",
       "             max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,\n",
       "             missing=nan, monotone_constraints='()', n_estimators=100, n_jobs=0,\n",
       "             num_parallel_tree=1, predictor='auto', random_state=42,\n",
       "             reg_alpha=0, reg_lambda=1, ...)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 51;\n",
       "                var nbb_unformatted_code = \"# Confirming the model\\nmodels_to_tune[\\\"XGB_gbtree2\\\"]\";\n",
       "                var nbb_formatted_code = \"# Confirming the model\\nmodels_to_tune[\\\"XGB_gbtree2\\\"]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Confirming the model\n",
    "models_to_tune[\"XGB_gbtree2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "567e4678",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters are {'colsample_bytree': 0.6861223846483286, 'gamma': 0.22153944050588595, 'learning_rate': 0.10165663513708073, 'max_depth': 5, 'n_estimators': 180, 'subsample': 0.74226839054973} with CV score=0.11086998659519617:\n",
      "CPU times: total: 44.8 s\n",
      "Wall time: 9h 26min 53s\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 52;\n",
       "                var nbb_unformatted_code = \"%%time\\n\\n# Defining model\\nModel = XGBRegressor(random_state=42, booster='gbtree')\\n\\n# Parameter grid to pass in RandomizedSearchCV\\nparam_grid={\\n    'n_estimators': np.arange(100, 500),\\n    \\\"learning_rate\\\": uniform(0.1, 0.3), # aka eta\\n    'gamma': expon(), # aka min_split_loss\\n    'subsample': uniform(loc=0.6, scale=0.2), # proportion of train set to randomly sample prior to growing trees\\n    'max_depth': np.arange(3, 8).tolist(),\\n    'colsample_bytree': uniform(loc=0.3, scale=0.5)\\n}\\n\\n# Calling RandomizedSearchCV\\nrandomized_cv = RandomizedSearchCV(\\n    estimator=Model,\\n    param_distributions=param_grid,\\n    n_iter=100,\\n    n_jobs=-1,\\n    scoring=scorer,\\n    cv=5,\\n    random_state=42,\\n)\\n\\n# Fitting parameters in RandomizedSearchCV\\nrandomized_cv.fit(X_train, y_train)\\n\\nprint(\\n    \\\"Best parameters are {} with CV score={}:\\\".format(\\n        randomized_cv.best_params_, randomized_cv.best_score_\\n    )\\n)\\n\\n# Chime notification when cell successfully executes\\nchime.success()\";\n",
       "                var nbb_formatted_code = \"%%time\\n\\n# Defining model\\nModel = XGBRegressor(random_state=42, booster='gbtree')\\n\\n# Parameter grid to pass in RandomizedSearchCV\\nparam_grid={\\n    'n_estimators': np.arange(100, 500),\\n    \\\"learning_rate\\\": uniform(0.1, 0.3), # aka eta\\n    'gamma': expon(), # aka min_split_loss\\n    'subsample': uniform(loc=0.6, scale=0.2), # proportion of train set to randomly sample prior to growing trees\\n    'max_depth': np.arange(3, 8).tolist(),\\n    'colsample_bytree': uniform(loc=0.3, scale=0.5)\\n}\\n\\n# Calling RandomizedSearchCV\\nrandomized_cv = RandomizedSearchCV(\\n    estimator=Model,\\n    param_distributions=param_grid,\\n    n_iter=100,\\n    n_jobs=-1,\\n    scoring=scorer,\\n    cv=5,\\n    random_state=42,\\n)\\n\\n# Fitting parameters in RandomizedSearchCV\\nrandomized_cv.fit(X_train, y_train)\\n\\nprint(\\n    \\\"Best parameters are {} with CV score={}:\\\".format(\\n        randomized_cv.best_params_, randomized_cv.best_score_\\n    )\\n)\\n\\n# Chime notification when cell successfully executes\\nchime.success()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Defining model\n",
    "Model = XGBRegressor(random_state=42, booster='gbtree')\n",
    "\n",
    "# Parameter grid to pass in RandomizedSearchCV\n",
    "param_grid={\n",
    "    'n_estimators': np.arange(100, 500),\n",
    "    \"learning_rate\": uniform(0.1, 0.3), # aka eta\n",
    "    'gamma': expon(), # aka min_split_loss\n",
    "    'subsample': uniform(loc=0.6, scale=0.2), # proportion of train set to randomly sample prior to growing trees\n",
    "    'max_depth': np.arange(3, 8).tolist(),\n",
    "    'colsample_bytree': uniform(loc=0.3, scale=0.5)\n",
    "}\n",
    "\n",
    "# Calling RandomizedSearchCV\n",
    "randomized_cv = RandomizedSearchCV(\n",
    "    estimator=Model,\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=100,\n",
    "    n_jobs=-1,\n",
    "    scoring=scorer,\n",
    "    cv=5,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "# Fitting parameters in RandomizedSearchCV\n",
    "randomized_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\n",
    "    \"Best parameters are {} with CV score={}:\".format(\n",
    "        randomized_cv.best_params_, randomized_cv.best_score_\n",
    "    )\n",
    ")\n",
    "\n",
    "# Chime notification when cell successfully executes\n",
    "chime.success()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ff25695c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', callbacks=None,\n",
       "             colsample_bylevel=1, colsample_bynode=1,\n",
       "             colsample_bytree=0.6861223846483286, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None,\n",
       "             gamma=0.22153944050588595, gpu_id=-1, grow_policy='depthwise',\n",
       "             importance_type=None, interaction_constraints='',\n",
       "             learning_rate=0.10165663513708073, max_bin=256,\n",
       "             max_cat_to_onehot=4, max_delta_step=0, max_depth=5, max_leaves=0,\n",
       "             min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "             n_estimators=180, n_jobs=0, num_parallel_tree=1, predictor='auto',\n",
       "             random_state=42, reg_alpha=0, reg_lambda=1, ...)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 53;\n",
       "                var nbb_unformatted_code = \"# Building model with best parameters\\nXGB_gbtree2_tuned = XGBRegressor(\\n    booster=\\\"gbtree\\\",\\n    random_state=42,\\n    colsample_bytree=0.6861223846483286,\\n    gamma=0.22153944050588595,\\n    learning_rate=0.10165663513708073,\\n    max_depth=5,\\n    n_estimators=180,\\n    subsample=0.74226839054973,\\n)\\n\\n# Fit the model on training data\\nXGB_gbtree2_tuned.fit(X_train, y_train)\";\n",
       "                var nbb_formatted_code = \"# Building model with best parameters\\nXGB_gbtree2_tuned = XGBRegressor(\\n    booster=\\\"gbtree\\\",\\n    random_state=42,\\n    colsample_bytree=0.6861223846483286,\\n    gamma=0.22153944050588595,\\n    learning_rate=0.10165663513708073,\\n    max_depth=5,\\n    n_estimators=180,\\n    subsample=0.74226839054973,\\n)\\n\\n# Fit the model on training data\\nXGB_gbtree2_tuned.fit(X_train, y_train)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Building model with best parameters\n",
    "XGB_gbtree2_tuned = XGBRegressor(\n",
    "    booster=\"gbtree\",\n",
    "    random_state=42,\n",
    "    colsample_bytree=0.6861223846483286,\n",
    "    gamma=0.22153944050588595,\n",
    "    learning_rate=0.10165663513708073,\n",
    "    max_depth=5,\n",
    "    n_estimators=180,\n",
    "    subsample=0.74226839054973,\n",
    ")\n",
    "\n",
    "# Fit the model on training data\n",
    "XGB_gbtree2_tuned.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3c4bbcb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training performance:\n",
      "         RMSE        MAE  R-squared  Adj. R-squared       MAPE\n",
      "0  14.596533  11.326033   0.152859        0.152329  18.630614\n",
      "\n",
      "Validation performance:\n",
      "         RMSE        MAE  R-squared  Adj. R-squared       MAPE\n",
      "0  14.867475  11.517005   0.110095        0.108794  18.881056\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 54;\n",
       "                var nbb_unformatted_code = \"# Calculating different metrics\\nXGB_gbtree2_tuned_train_perf = model_performance_regression(\\n    XGB_gbtree2_tuned, X_train, y_train\\n)\\nprint(\\\"Training performance:\\\\n\\\", XGB_gbtree2_tuned_train_perf)\\nXGB_gbtree2_tuned_val_perf = model_performance_regression(\\n    XGB_gbtree2_tuned, X_val, y_val\\n)\\nprint(\\\"\\\\nValidation performance:\\\\n\\\", XGB_gbtree2_tuned_val_perf)\\n\\n# Adding model to model comparison dataframes\\nmodels_train_comp_df[\\\"XGB_gbtree2 Tuned\\\"] = XGB_gbtree2_tuned_train_perf.T\\nmodels_val_comp_df[\\\"XGB_gbtree2 Tuned\\\"] = XGB_gbtree2_tuned_val_perf.T\";\n",
       "                var nbb_formatted_code = \"# Calculating different metrics\\nXGB_gbtree2_tuned_train_perf = model_performance_regression(\\n    XGB_gbtree2_tuned, X_train, y_train\\n)\\nprint(\\\"Training performance:\\\\n\\\", XGB_gbtree2_tuned_train_perf)\\nXGB_gbtree2_tuned_val_perf = model_performance_regression(\\n    XGB_gbtree2_tuned, X_val, y_val\\n)\\nprint(\\\"\\\\nValidation performance:\\\\n\\\", XGB_gbtree2_tuned_val_perf)\\n\\n# Adding model to model comparison dataframes\\nmodels_train_comp_df[\\\"XGB_gbtree2 Tuned\\\"] = XGB_gbtree2_tuned_train_perf.T\\nmodels_val_comp_df[\\\"XGB_gbtree2 Tuned\\\"] = XGB_gbtree2_tuned_val_perf.T\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculating different metrics\n",
    "XGB_gbtree2_tuned_train_perf = model_performance_regression(\n",
    "    XGB_gbtree2_tuned, X_train, y_train\n",
    ")\n",
    "print(\"Training performance:\\n\", XGB_gbtree2_tuned_train_perf)\n",
    "XGB_gbtree2_tuned_val_perf = model_performance_regression(\n",
    "    XGB_gbtree2_tuned, X_val, y_val\n",
    ")\n",
    "print(\"\\nValidation performance:\\n\", XGB_gbtree2_tuned_val_perf)\n",
    "\n",
    "# Adding model to model comparison dataframes\n",
    "models_train_comp_df[\"XGB_gbtree2 Tuned\"] = XGB_gbtree2_tuned_train_perf.T\n",
    "models_val_comp_df[\"XGB_gbtree2 Tuned\"] = XGB_gbtree2_tuned_val_perf.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b65f6e3",
   "metadata": {},
   "source": [
    "#### Observations:\n",
    "- The performance for *XGB_gbtree2* is improved with hyperparameter tuning.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150d6c55",
   "metadata": {},
   "source": [
    "### *XGB_gblinear2 Tuned*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "283c6ebe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gblinear', callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, gamma=None, gpu_id=-1,\n",
       "             grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.5, max_bin=None,\n",
       "             max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "             max_leaves=None, min_child_weight=None, missing=nan,\n",
       "             monotone_constraints=None, n_estimators=100, n_jobs=0,\n",
       "             num_parallel_tree=None, predictor=None, random_state=42,\n",
       "             reg_alpha=0, reg_lambda=0, ...)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 55;\n",
       "                var nbb_unformatted_code = \"# Confirming the model\\nmodels_to_tune[\\\"XGB_gblinear2\\\"]\";\n",
       "                var nbb_formatted_code = \"# Confirming the model\\nmodels_to_tune[\\\"XGB_gblinear2\\\"]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Confirming the model\n",
    "models_to_tune[\"XGB_gblinear2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8ceb7df9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters are {'n_estimators': 439, 'reg_lambda': 0.0009206654892274761} with CV score=0.09239924785728368:\n",
      "CPU times: total: 38.8 s\n",
      "Wall time: 4min 29s\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 64;\n",
       "                var nbb_unformatted_code = \"%%time\\n\\n# Defining model\\nModel = XGBRegressor(random_state=42, booster='gblinear')\\n\\n# Parameter grid to pass in RandomizedSearchCV\\nparam_grid={\\n    'n_estimators': np.arange(100, 500),\\n    'reg_lambda': loguniform(.0001, 1)\\n}\\n\\n# Calling RandomizedSearchCV\\nrandomized_cv = RandomizedSearchCV(\\n    estimator=Model,\\n    param_distributions=param_grid,\\n    n_iter=100,\\n    n_jobs=-1,\\n    scoring=scorer,\\n    cv=5,\\n    random_state=42,\\n)\\n\\n# Fitting parameters in RandomizedSearchCV\\nrandomized_cv.fit(X_train, y_train)\\n\\nprint(\\n    \\\"Best parameters are {} with CV score={}:\\\".format(\\n        randomized_cv.best_params_, randomized_cv.best_score_\\n    )\\n)\\n\\n# Chime notification when cell successfully executes\\nchime.success()\";\n",
       "                var nbb_formatted_code = \"%%time\\n\\n# Defining model\\nModel = XGBRegressor(random_state=42, booster='gblinear')\\n\\n# Parameter grid to pass in RandomizedSearchCV\\nparam_grid={\\n    'n_estimators': np.arange(100, 500),\\n    'reg_lambda': loguniform(.0001, 1)\\n}\\n\\n# Calling RandomizedSearchCV\\nrandomized_cv = RandomizedSearchCV(\\n    estimator=Model,\\n    param_distributions=param_grid,\\n    n_iter=100,\\n    n_jobs=-1,\\n    scoring=scorer,\\n    cv=5,\\n    random_state=42,\\n)\\n\\n# Fitting parameters in RandomizedSearchCV\\nrandomized_cv.fit(X_train, y_train)\\n\\nprint(\\n    \\\"Best parameters are {} with CV score={}:\\\".format(\\n        randomized_cv.best_params_, randomized_cv.best_score_\\n    )\\n)\\n\\n# Chime notification when cell successfully executes\\nchime.success()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Defining model\n",
    "Model = XGBRegressor(random_state=42, booster='gblinear')\n",
    "\n",
    "# Parameter grid to pass in RandomizedSearchCV\n",
    "param_grid={\n",
    "    'n_estimators': np.arange(100, 500),\n",
    "    'reg_lambda': loguniform(.0001, 1)\n",
    "}\n",
    "\n",
    "# Calling RandomizedSearchCV\n",
    "randomized_cv = RandomizedSearchCV(\n",
    "    estimator=Model,\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=100,\n",
    "    n_jobs=-1,\n",
    "    scoring=scorer,\n",
    "    cv=5,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "# Fitting parameters in RandomizedSearchCV\n",
    "randomized_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\n",
    "    \"Best parameters are {} with CV score={}:\".format(\n",
    "        randomized_cv.best_params_, randomized_cv.best_score_\n",
    "    )\n",
    ")\n",
    "\n",
    "# Chime notification when cell successfully executes\n",
    "chime.success()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "19ae25e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gblinear', callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, gamma=None, gpu_id=-1,\n",
       "             grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.5, max_bin=None,\n",
       "             max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "             max_leaves=None, min_child_weight=None, missing=nan,\n",
       "             monotone_constraints=None, n_estimators=439, n_jobs=0,\n",
       "             num_parallel_tree=None, predictor=None, random_state=42,\n",
       "             reg_alpha=0, reg_lambda=0.0009206654892274761, ...)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 65;\n",
       "                var nbb_unformatted_code = \"# Building model with best parameters\\nXGB_gblinear2_tuned = XGBRegressor(\\n    booster=\\\"gblinear\\\",\\n    random_state=42,\\n    n_estimators=439,\\n    reg_lambda=0.0009206654892274761,\\n)\\n\\n# Fit the model on training data\\nXGB_gblinear2_tuned.fit(X_train, y_train)\";\n",
       "                var nbb_formatted_code = \"# Building model with best parameters\\nXGB_gblinear2_tuned = XGBRegressor(\\n    booster=\\\"gblinear\\\",\\n    random_state=42,\\n    n_estimators=439,\\n    reg_lambda=0.0009206654892274761,\\n)\\n\\n# Fit the model on training data\\nXGB_gblinear2_tuned.fit(X_train, y_train)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Building model with best parameters\n",
    "XGB_gblinear2_tuned = XGBRegressor(\n",
    "    booster=\"gblinear\",\n",
    "    random_state=42,\n",
    "    n_estimators=439,\n",
    "    reg_lambda=0.0009206654892274761,\n",
    ")\n",
    "\n",
    "# Fit the model on training data\n",
    "XGB_gblinear2_tuned.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "45ab8538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training performance:\n",
      "         RMSE        MAE  R-squared  Adj. R-squared    MAPE\n",
      "0  15.101745  11.725615   0.093202        0.092635  19.392\n",
      "\n",
      "Validation performance:\n",
      "         RMSE        MAE  R-squared  Adj. R-squared       MAPE\n",
      "0  15.009157  11.641346   0.093053        0.091727  19.169478\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 66;\n",
       "                var nbb_unformatted_code = \"# Calculating different metrics\\nXGB_gblinear2_tuned_train_perf = model_performance_regression(\\n    XGB_gblinear2_tuned, X_train, y_train\\n)\\nprint(\\\"Training performance:\\\\n\\\", XGB_gblinear2_tuned_train_perf)\\nXGB_gblinear2_tuned_val_perf = model_performance_regression(\\n    XGB_gblinear2_tuned, X_val, y_val\\n)\\nprint(\\\"\\\\nValidation performance:\\\\n\\\", XGB_gblinear2_tuned_val_perf)\\n\\n# Adding model to model comparison dataframes\\nmodels_train_comp_df[\\\"XGB_gblinear2 Tuned\\\"] = XGB_gblinear2_tuned_train_perf.T\\nmodels_val_comp_df[\\\"XGB_gblinear2 Tuned\\\"] = XGB_gblinear2_tuned_val_perf.T\";\n",
       "                var nbb_formatted_code = \"# Calculating different metrics\\nXGB_gblinear2_tuned_train_perf = model_performance_regression(\\n    XGB_gblinear2_tuned, X_train, y_train\\n)\\nprint(\\\"Training performance:\\\\n\\\", XGB_gblinear2_tuned_train_perf)\\nXGB_gblinear2_tuned_val_perf = model_performance_regression(\\n    XGB_gblinear2_tuned, X_val, y_val\\n)\\nprint(\\\"\\\\nValidation performance:\\\\n\\\", XGB_gblinear2_tuned_val_perf)\\n\\n# Adding model to model comparison dataframes\\nmodels_train_comp_df[\\\"XGB_gblinear2 Tuned\\\"] = XGB_gblinear2_tuned_train_perf.T\\nmodels_val_comp_df[\\\"XGB_gblinear2 Tuned\\\"] = XGB_gblinear2_tuned_val_perf.T\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculating different metrics\n",
    "XGB_gblinear2_tuned_train_perf = model_performance_regression(\n",
    "    XGB_gblinear2_tuned, X_train, y_train\n",
    ")\n",
    "print(\"Training performance:\\n\", XGB_gblinear2_tuned_train_perf)\n",
    "XGB_gblinear2_tuned_val_perf = model_performance_regression(\n",
    "    XGB_gblinear2_tuned, X_val, y_val\n",
    ")\n",
    "print(\"\\nValidation performance:\\n\", XGB_gblinear2_tuned_val_perf)\n",
    "\n",
    "# Adding model to model comparison dataframes\n",
    "models_train_comp_df[\"XGB_gblinear2 Tuned\"] = XGB_gblinear2_tuned_train_perf.T\n",
    "models_val_comp_df[\"XGB_gblinear2 Tuned\"] = XGB_gblinear2_tuned_val_perf.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef992f89",
   "metadata": {},
   "source": [
    "#### Observations:\n",
    "- The performance of *XGB_gblinear1* is improved with hyperparameter tuning.\n",
    "- Let us compare the performance of this iteration's models before and after hyperparameter tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce915567",
   "metadata": {},
   "source": [
    "## Model Performance Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd758c1",
   "metadata": {},
   "source": [
    "### Performance of Various Models Tuned and Untuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "53f2ff81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Performance Comparison:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GBM2</th>\n",
       "      <th>GBM2 Tuned</th>\n",
       "      <th>Random Forest2</th>\n",
       "      <th>Random Forest2 Tuned</th>\n",
       "      <th>XGB_gblinear2</th>\n",
       "      <th>XGB_gblinear2 Tuned</th>\n",
       "      <th>XGB_gbtree2</th>\n",
       "      <th>XGB_gbtree2 Tuned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>14.937480</td>\n",
       "      <td>14.803396</td>\n",
       "      <td>11.328976</td>\n",
       "      <td>14.485455</td>\n",
       "      <td>15.129664</td>\n",
       "      <td>15.101745</td>\n",
       "      <td>14.196740</td>\n",
       "      <td>14.596533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>11.599899</td>\n",
       "      <td>11.490370</td>\n",
       "      <td>8.362030</td>\n",
       "      <td>11.250801</td>\n",
       "      <td>11.741451</td>\n",
       "      <td>11.725615</td>\n",
       "      <td>10.984573</td>\n",
       "      <td>11.326033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-squared</th>\n",
       "      <td>0.112822</td>\n",
       "      <td>0.128678</td>\n",
       "      <td>0.489686</td>\n",
       "      <td>0.165703</td>\n",
       "      <td>0.089846</td>\n",
       "      <td>0.093202</td>\n",
       "      <td>0.198629</td>\n",
       "      <td>0.152859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Adj. R-squared</th>\n",
       "      <td>0.112266</td>\n",
       "      <td>0.128132</td>\n",
       "      <td>0.489367</td>\n",
       "      <td>0.165181</td>\n",
       "      <td>0.089276</td>\n",
       "      <td>0.092635</td>\n",
       "      <td>0.198128</td>\n",
       "      <td>0.152329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAPE</th>\n",
       "      <td>19.178492</td>\n",
       "      <td>18.950940</td>\n",
       "      <td>13.404005</td>\n",
       "      <td>18.596652</td>\n",
       "      <td>19.384544</td>\n",
       "      <td>19.392000</td>\n",
       "      <td>17.982195</td>\n",
       "      <td>18.630614</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     GBM2  GBM2 Tuned  Random Forest2  Random Forest2 Tuned  \\\n",
       "RMSE            14.937480   14.803396       11.328976             14.485455   \n",
       "MAE             11.599899   11.490370        8.362030             11.250801   \n",
       "R-squared        0.112822    0.128678        0.489686              0.165703   \n",
       "Adj. R-squared   0.112266    0.128132        0.489367              0.165181   \n",
       "MAPE            19.178492   18.950940       13.404005             18.596652   \n",
       "\n",
       "                XGB_gblinear2  XGB_gblinear2 Tuned  XGB_gbtree2  \\\n",
       "RMSE                15.129664            15.101745    14.196740   \n",
       "MAE                 11.741451            11.725615    10.984573   \n",
       "R-squared            0.089846             0.093202     0.198629   \n",
       "Adj. R-squared       0.089276             0.092635     0.198128   \n",
       "MAPE                19.384544            19.392000    17.982195   \n",
       "\n",
       "                XGB_gbtree2 Tuned  \n",
       "RMSE                    14.596533  \n",
       "MAE                     11.326033  \n",
       "R-squared                0.152859  \n",
       "Adj. R-squared           0.152329  \n",
       "MAPE                    18.630614  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 67;\n",
       "                var nbb_unformatted_code = \"# Displaying train performance of all models\\nprint(\\\"Train Performance Comparison:\\\")\\ncols = [column for column in models_train_comp_df.columns if \\\"2\\\" in column]\\nmodels_train_comp_df[cols].sort_index(axis=1)\";\n",
       "                var nbb_formatted_code = \"# Displaying train performance of all models\\nprint(\\\"Train Performance Comparison:\\\")\\ncols = [column for column in models_train_comp_df.columns if \\\"2\\\" in column]\\nmodels_train_comp_df[cols].sort_index(axis=1)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Displaying train performance of all models\n",
    "print(\"Train Performance Comparison:\")\n",
    "cols = [column for column in models_train_comp_df.columns if \"2\" in column]\n",
    "models_train_comp_df[cols].sort_index(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ad87ba49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Performance Comparison:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GBM2</th>\n",
       "      <th>GBM2 Tuned</th>\n",
       "      <th>Random Forest2</th>\n",
       "      <th>Random Forest2 Tuned</th>\n",
       "      <th>XGB_gblinear2</th>\n",
       "      <th>XGB_gblinear2 Tuned</th>\n",
       "      <th>XGB_gbtree2</th>\n",
       "      <th>XGB_gbtree2 Tuned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>14.894124</td>\n",
       "      <td>14.853802</td>\n",
       "      <td>16.206121</td>\n",
       "      <td>14.906245</td>\n",
       "      <td>15.026151</td>\n",
       "      <td>15.009157</td>\n",
       "      <td>14.973004</td>\n",
       "      <td>14.867475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>11.552854</td>\n",
       "      <td>11.512155</td>\n",
       "      <td>12.476262</td>\n",
       "      <td>11.559593</td>\n",
       "      <td>11.654557</td>\n",
       "      <td>11.641346</td>\n",
       "      <td>11.582826</td>\n",
       "      <td>11.517005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-squared</th>\n",
       "      <td>0.106902</td>\n",
       "      <td>0.111731</td>\n",
       "      <td>-0.057371</td>\n",
       "      <td>0.105447</td>\n",
       "      <td>0.090998</td>\n",
       "      <td>0.093053</td>\n",
       "      <td>0.097417</td>\n",
       "      <td>0.110095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Adj. R-squared</th>\n",
       "      <td>0.105596</td>\n",
       "      <td>0.110432</td>\n",
       "      <td>-0.058917</td>\n",
       "      <td>0.104139</td>\n",
       "      <td>0.089669</td>\n",
       "      <td>0.091727</td>\n",
       "      <td>0.096097</td>\n",
       "      <td>0.108794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAPE</th>\n",
       "      <td>19.011210</td>\n",
       "      <td>18.898856</td>\n",
       "      <td>20.071146</td>\n",
       "      <td>19.019887</td>\n",
       "      <td>19.158585</td>\n",
       "      <td>19.169478</td>\n",
       "      <td>18.941080</td>\n",
       "      <td>18.881056</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     GBM2  GBM2 Tuned  Random Forest2  Random Forest2 Tuned  \\\n",
       "RMSE            14.894124   14.853802       16.206121             14.906245   \n",
       "MAE             11.552854   11.512155       12.476262             11.559593   \n",
       "R-squared        0.106902    0.111731       -0.057371              0.105447   \n",
       "Adj. R-squared   0.105596    0.110432       -0.058917              0.104139   \n",
       "MAPE            19.011210   18.898856       20.071146             19.019887   \n",
       "\n",
       "                XGB_gblinear2  XGB_gblinear2 Tuned  XGB_gbtree2  \\\n",
       "RMSE                15.026151            15.009157    14.973004   \n",
       "MAE                 11.654557            11.641346    11.582826   \n",
       "R-squared            0.090998             0.093053     0.097417   \n",
       "Adj. R-squared       0.089669             0.091727     0.096097   \n",
       "MAPE                19.158585            19.169478    18.941080   \n",
       "\n",
       "                XGB_gbtree2 Tuned  \n",
       "RMSE                    14.867475  \n",
       "MAE                     11.517005  \n",
       "R-squared                0.110095  \n",
       "Adj. R-squared           0.108794  \n",
       "MAPE                    18.881056  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 68;\n",
       "                var nbb_unformatted_code = \"# Displaying validation performance of all models\\nprint(\\\"Validation Performance Comparison:\\\")\\nmodels_val_comp_df[cols].sort_index(axis=1)\";\n",
       "                var nbb_formatted_code = \"# Displaying validation performance of all models\\nprint(\\\"Validation Performance Comparison:\\\")\\nmodels_val_comp_df[cols].sort_index(axis=1)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Displaying validation performance of all models\n",
    "print(\"Validation Performance Comparison:\")\n",
    "models_val_comp_df[cols].sort_index(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff0499f5",
   "metadata": {},
   "source": [
    "#### Observations:\n",
    "- We see improvement across the board with hyperparameter tuning.  Even *Random Forest2** improved enough to be a contender.\n",
    "- Let us narrow down the model contenders to those with validation R$^2$ scores of at least 0.105, from both modeling iterations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59979b39",
   "metadata": {},
   "source": [
    "### Performance of Contender Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "24075b2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Performance Comparison:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GBM Tuned</th>\n",
       "      <th>GBM2</th>\n",
       "      <th>GBM2 Tuned</th>\n",
       "      <th>Random Forest2 Tuned</th>\n",
       "      <th>XGB_gbtree Tuned</th>\n",
       "      <th>XGB_gbtree2 Tuned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>14.835035</td>\n",
       "      <td>14.937480</td>\n",
       "      <td>14.803396</td>\n",
       "      <td>14.485455</td>\n",
       "      <td>14.813429</td>\n",
       "      <td>14.596533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>11.521845</td>\n",
       "      <td>11.599899</td>\n",
       "      <td>11.490370</td>\n",
       "      <td>11.250801</td>\n",
       "      <td>11.504380</td>\n",
       "      <td>11.326033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-squared</th>\n",
       "      <td>0.124949</td>\n",
       "      <td>0.112822</td>\n",
       "      <td>0.128678</td>\n",
       "      <td>0.165703</td>\n",
       "      <td>0.127496</td>\n",
       "      <td>0.152859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAPE</th>\n",
       "      <td>18.989296</td>\n",
       "      <td>19.178492</td>\n",
       "      <td>18.950940</td>\n",
       "      <td>18.596652</td>\n",
       "      <td>18.953973</td>\n",
       "      <td>18.630614</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           GBM Tuned       GBM2  GBM2 Tuned  Random Forest2 Tuned  \\\n",
       "RMSE       14.835035  14.937480   14.803396             14.485455   \n",
       "MAE        11.521845  11.599899   11.490370             11.250801   \n",
       "R-squared   0.124949   0.112822    0.128678              0.165703   \n",
       "MAPE       18.989296  19.178492   18.950940             18.596652   \n",
       "\n",
       "           XGB_gbtree Tuned  XGB_gbtree2 Tuned  \n",
       "RMSE              14.813429          14.596533  \n",
       "MAE               11.504380          11.326033  \n",
       "R-squared          0.127496           0.152859  \n",
       "MAPE              18.953973          18.630614  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 75;\n",
       "                var nbb_unformatted_code = \"# Displaying train performance of contender models\\nprint(\\\"Train Performance Comparison:\\\")\\ncols = [\\n    column\\n    for column in models_train_comp_df.columns\\n    if models_val_comp_df.loc[\\\"R-squared\\\", column] >= 0.105\\n]\\nmodels_train_comp_df.drop('Adj. R-squared')[cols].sort_index(axis=1)\";\n",
       "                var nbb_formatted_code = \"# Displaying train performance of contender models\\nprint(\\\"Train Performance Comparison:\\\")\\ncols = [\\n    column\\n    for column in models_train_comp_df.columns\\n    if models_val_comp_df.loc[\\\"R-squared\\\", column] >= 0.105\\n]\\nmodels_train_comp_df.drop(\\\"Adj. R-squared\\\")[cols].sort_index(axis=1)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Displaying train performance of contender models\n",
    "print(\"Train Performance Comparison:\")\n",
    "cols = [\n",
    "    column\n",
    "    for column in models_train_comp_df.columns\n",
    "    if models_val_comp_df.loc[\"R-squared\", column] >= 0.105\n",
    "]\n",
    "models_train_comp_df.drop(\"Adj. R-squared\")[cols].sort_index(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "df9d1057",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Performance Comparison:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GBM Tuned</th>\n",
       "      <th>GBM2</th>\n",
       "      <th>GBM2 Tuned</th>\n",
       "      <th>Random Forest2 Tuned</th>\n",
       "      <th>XGB_gbtree Tuned</th>\n",
       "      <th>XGB_gbtree2 Tuned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>14.877704</td>\n",
       "      <td>14.894124</td>\n",
       "      <td>14.853802</td>\n",
       "      <td>14.906245</td>\n",
       "      <td>14.882834</td>\n",
       "      <td>14.867475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>11.542386</td>\n",
       "      <td>11.552854</td>\n",
       "      <td>11.512155</td>\n",
       "      <td>11.559593</td>\n",
       "      <td>11.546377</td>\n",
       "      <td>11.517005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-squared</th>\n",
       "      <td>0.108870</td>\n",
       "      <td>0.106902</td>\n",
       "      <td>0.111731</td>\n",
       "      <td>0.105447</td>\n",
       "      <td>0.108255</td>\n",
       "      <td>0.110095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAPE</th>\n",
       "      <td>18.937928</td>\n",
       "      <td>19.011210</td>\n",
       "      <td>18.898856</td>\n",
       "      <td>19.019887</td>\n",
       "      <td>18.931955</td>\n",
       "      <td>18.881056</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           GBM Tuned       GBM2  GBM2 Tuned  Random Forest2 Tuned  \\\n",
       "RMSE       14.877704  14.894124   14.853802             14.906245   \n",
       "MAE        11.542386  11.552854   11.512155             11.559593   \n",
       "R-squared   0.108870   0.106902    0.111731              0.105447   \n",
       "MAPE       18.937928  19.011210   18.898856             19.019887   \n",
       "\n",
       "           XGB_gbtree Tuned  XGB_gbtree2 Tuned  \n",
       "RMSE              14.882834          14.867475  \n",
       "MAE               11.546377          11.517005  \n",
       "R-squared          0.108255           0.110095  \n",
       "MAPE              18.931955          18.881056  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 76;\n",
       "                var nbb_unformatted_code = \"# Displaying validation performance of contender models\\nprint(\\\"Validation Performance Comparison:\\\")\\nmodels_val_comp_df.drop('Adj. R-squared')[cols].sort_index(axis=1)\";\n",
       "                var nbb_formatted_code = \"# Displaying validation performance of contender models\\nprint(\\\"Validation Performance Comparison:\\\")\\nmodels_val_comp_df.drop(\\\"Adj. R-squared\\\")[cols].sort_index(axis=1)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Displaying validation performance of contender models\n",
    "print(\"Validation Performance Comparison:\")\n",
    "models_val_comp_df.drop(\"Adj. R-squared\")[cols].sort_index(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ab6f60",
   "metadata": {},
   "source": [
    "#### Observations:\n",
    "- *GBM* and *GBM Tuned* has one additional feature than the other models, after one hot encoding.  Therefore Ajusted $R^2$ is more relevant here comparing those two models with the others, than previously.\n",
    "- Regardless, the top models are the same for R$^2$ and Adjusted R$^2$, *GBM2 Tuned*, followed by *XGB_gtree2 Tuned*, then *GBM Tuned*.\n",
    "- Using the original `known for` category columns instead of `known_for`, with the inclusion of `num_categories`, brought the validation R$^2$ scores over 0.11 for two of the models.\n",
    "- There is some variation in overfitting between the contender models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff59cc71",
   "metadata": {},
   "source": [
    "#### Comparison of Percentage of Overfit for All 4 Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "85654b60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['RMSE', 'MAE', 'R-squared', 'MAPE'], dtype='object')"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 119;\n",
       "                var nbb_unformatted_code = \"models_val_comp_df.drop('Adj. R-squared').index\";\n",
       "                var nbb_formatted_code = \"models_val_comp_df.drop(\\\"Adj. R-squared\\\").index\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "models_val_comp_df.drop(\"Adj. R-squared\").index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "8c576bcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of Overfit:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R-squared % overfit</th>\n",
       "      <th>RMSE % overfit</th>\n",
       "      <th>MAE % overfit</th>\n",
       "      <th>MAPE % overfit</th>\n",
       "      <th>% Overfit Average of All 4 Metrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GBM2</th>\n",
       "      <td>5.2</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>-0.9</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GBM Tuned</th>\n",
       "      <td>12.9</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>3.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GBM2 Tuned</th>\n",
       "      <td>13.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>3.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGB_gbtree Tuned</th>\n",
       "      <td>15.1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGB_gbtree2 Tuned</th>\n",
       "      <td>28.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1.7</td>\n",
       "      <td>1.3</td>\n",
       "      <td>8.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest2 Tuned</th>\n",
       "      <td>36.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2.7</td>\n",
       "      <td>2.2</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      R-squared % overfit  RMSE % overfit  MAE % overfit  \\\n",
       "GBM2                                  5.2            -0.3           -0.4   \n",
       "GBM Tuned                            12.9             0.3            0.2   \n",
       "GBM2 Tuned                           13.2             0.3            0.2   \n",
       "XGB_gbtree Tuned                     15.1             0.5            0.4   \n",
       "XGB_gbtree2 Tuned                    28.0             1.8            1.7   \n",
       "Random Forest2 Tuned                 36.4             2.8            2.7   \n",
       "\n",
       "                      MAPE % overfit  % Overfit Average of All 4 Metrics  \n",
       "GBM2                            -0.9                                 0.9  \n",
       "GBM Tuned                       -0.3                                 3.3  \n",
       "GBM2 Tuned                      -0.3                                 3.4  \n",
       "XGB_gbtree Tuned                -0.1                                 4.0  \n",
       "XGB_gbtree2 Tuned                1.3                                 8.2  \n",
       "Random Forest2 Tuned             2.2                                11.0  "
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 166;\n",
       "                var nbb_unformatted_code = \"# Subtracting the ratio of validation R-square/train R-square from 1\\noverfit_perc = pd.DataFrame()\\noverfit_perc[\\\"R-squared % overfit\\\"] = np.round(\\n    (\\n        1\\n        - (\\n            models_val_comp_df[cols].T[\\\"R-squared\\\"]\\n            / models_train_comp_df[cols].T[\\\"R-squared\\\"]\\n        )\\n    )\\n    * 100,\\n    1,\\n)\\nfor metric in [\\\"RMSE\\\", \\\"MAE\\\", \\\"MAPE\\\"]:\\n    overfit_perc[f\\\"{metric} % overfit\\\"] = np.round(\\n        (1 - (models_train_comp_df.T[metric] / models_val_comp_df.T[metric])) * 100, 1\\n    )\\n\\noverfit_perc[\\\"% Overfit Average of All 4 Metrics\\\"] = np.round(\\n    overfit_perc.sum(axis=1) / 4, 1\\n)\\n\\nprint(f\\\"Percentage of Overfit:\\\")\\noverfit_perc.sort_values(by=\\\"R-squared % overfit\\\")\";\n",
       "                var nbb_formatted_code = \"# Subtracting the ratio of validation R-square/train R-square from 1\\noverfit_perc = pd.DataFrame()\\noverfit_perc[\\\"R-squared % overfit\\\"] = np.round(\\n    (\\n        1\\n        - (\\n            models_val_comp_df[cols].T[\\\"R-squared\\\"]\\n            / models_train_comp_df[cols].T[\\\"R-squared\\\"]\\n        )\\n    )\\n    * 100,\\n    1,\\n)\\nfor metric in [\\\"RMSE\\\", \\\"MAE\\\", \\\"MAPE\\\"]:\\n    overfit_perc[f\\\"{metric} % overfit\\\"] = np.round(\\n        (1 - (models_train_comp_df.T[metric] / models_val_comp_df.T[metric])) * 100, 1\\n    )\\n\\noverfit_perc[\\\"% Overfit Average of All 4 Metrics\\\"] = np.round(\\n    overfit_perc.sum(axis=1) / 4, 1\\n)\\n\\nprint(f\\\"Percentage of Overfit:\\\")\\noverfit_perc.sort_values(by=\\\"R-squared % overfit\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Subtracting the ratio of validation R-square/train R-square from 1\n",
    "overfit_perc = pd.DataFrame()\n",
    "overfit_perc[\"R-squared % overfit\"] = np.round(\n",
    "    (\n",
    "        1\n",
    "        - (\n",
    "            models_val_comp_df[cols].T[\"R-squared\"]\n",
    "            / models_train_comp_df[cols].T[\"R-squared\"]\n",
    "        )\n",
    "    )\n",
    "    * 100,\n",
    "    1,\n",
    ")\n",
    "for metric in [\"RMSE\", \"MAE\", \"MAPE\"]:\n",
    "    overfit_perc[f\"{metric} % overfit\"] = np.round(\n",
    "        (1 - (models_train_comp_df.T[metric] / models_val_comp_df.T[metric])) * 100, 1\n",
    "    )\n",
    "\n",
    "overfit_perc[\"% Overfit Average of All 4 Metrics\"] = np.round(\n",
    "    overfit_perc.sum(axis=1) / 4, 1\n",
    ")\n",
    "\n",
    "print(f\"Percentage of Overfit:\")\n",
    "overfit_perc.sort_values(by=\"R-squared % overfit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c347e38b",
   "metadata": {},
   "source": [
    "#### Observations:\n",
    "- Of the top 3 models for R$^2$ score, *GBM2* generalized considerably better than *GBM2 Tuned* and *XGB_gtree Tuned*.  \n",
    "- That said, *GBM2 Tuned* has the highest R$^2$ score on the validation set.\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3195e171",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67fac016",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1cd0c82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26fd544",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42adfacf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b825f7ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c14ccbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85f8094",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a09adf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78a38ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b176c9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb43ad2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff1c6f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29cd878",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1a1fd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de521a9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d950457d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd237ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6a9b5162",
   "metadata": {},
   "source": [
    "### *GBM2 Tuned* Performance on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8e3bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking performance of champion model on test set\n",
    "GBM2_tuned_test_perf = model_performance_regression(GBM2_tuned, X_test, y_test)\n",
    "print(\"Test performance:\\n\", GBM2_tuned_test_perf)\n",
    "\n",
    "# Creating test and train performance df\n",
    "champion_df = pd.DataFrame()\n",
    "champion_df[\"GBM2 Tuned Train\"] = GBM2_tuned_train_perf.T\n",
    "champion_df[\"GBM2 Tuned Test\"] = GBM2_tuned_test_perf.T\n",
    "champion_df[\"Overfit Percentage\"] = (\n",
    "    1 - (champion_df[\"GBM2 Tuned Test\"] / champion_df[\"GBM2 Tuned Train\"])\n",
    ") * 100\n",
    "champion_df.drop(\"Adj. R-squared\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8496606",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance on train and test sets\n",
    "print(\n",
    "    f'Average overfit of the 4 metrics is {np.round(champion_df[\"Overfit Percentage\"].sum()/4, 2)}%.'\n",
    ")\n",
    "champion_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32efcd3",
   "metadata": {},
   "source": [
    "#### Observations:\n",
    "- *GBM Tuned*'s performance is holding up on the unseen test data.\n",
    "- We have a model that explains 10.7% of the variation in life span of notable Wikipedia individuals, who meet inclusion criteria.\n",
    "- The model predicts life expectancy within average errors of 11.5 years and 18.8%.\n",
    "- Let us check the most important predictive features of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9154ab0",
   "metadata": {},
   "source": [
    "### Feature Importance of *GBM Tuned*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3873454",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting feature importances of final model\n",
    "feature_names = X_train.columns\n",
    "importances = GBM_tuned.feature_importances_\n",
    "indices = np.argsort(importances)\n",
    "\n",
    "plt.figure(figsize=(12, 12))\n",
    "plt.title(\"Feature Importances\")\n",
    "plt.barh(range(len(indices)), importances[indices], color=\"violet\", align=\"center\")\n",
    "plt.yticks(range(len(indices)), [feature_names[i] for i in indices])\n",
    "plt.xlabel(\"Relative Importance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24bdf4d7",
   "metadata": {},
   "source": [
    "#### Observations:\n",
    "- Before deciding on a champion model, we will try another very similar approach.\n",
    "- Instead of using the extracted feature `known_for`, that grouped entries with multiple `known for` categories, we will let the original features stand.  This approach would not have worked for the basic linear regression model, because we had to drop columns to avoid multicollinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36c0663",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Complete\")\n",
    "\n",
    "# Chime notification when cell executes\n",
    "chime.success()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11aacfcc",
   "metadata": {},
   "source": [
    "# [Proceed to Data Cleaning Part ]()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
