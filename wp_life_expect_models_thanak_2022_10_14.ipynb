{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "316a0779",
   "metadata": {},
   "source": [
    "# Wikipedia Notable Life Expectancies\n",
    "# [Notebook  13: Models](https://github.com/teresahanak/wikipedia-life-expectancy/blob/main/wp_life_expect_models_thanak_2022_10_14.ipynb)\n",
    "### Context\n",
    "\n",
    "The\n",
    "### Objective\n",
    "\n",
    "The\n",
    "### Data Dictionary\n",
    "- Feature: Description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99245d51",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "453bba83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1;\n",
       "                var nbb_unformatted_code = \"# To structure code automatically\\n%load_ext nb_black\\n\\n# To import/export sqlite databases\\n# import sqlite3 as sql\\n\\n# To save/open python objects in pickle file\\nimport pickle\\n\\n# To help with reading, cleaning, and manipulating data\\nimport pandas as pd\\nimport numpy as np\\n\\n# To help with data visualization\\nimport matplotlib.pyplot as plt\\nimport seaborn as sns\\n\\n# To be used for missing value imputation\\nfrom sklearn.impute import SimpleImputer\\n\\n# To help with model building\\nfrom sklearn.tree import DecisionTreeRegressor\\nfrom sklearn.linear_model import LinearRegression\\n\\nfrom sklearn.ensemble import (\\n    AdaBoostRegressor,\\n    GradientBoostingRegressor,\\n    RandomForestRegressor,\\n    BaggingRegressor,\\n)\\nfrom xgboost import XGBRegressor\\n\\n# To randomly split data, for cross validation, and to check model performance\\nfrom sklearn import metrics\\nfrom sklearn.model_selection import train_test_split, KFold, cross_val_score\\nfrom sklearn.metrics import (\\n    mean_absolute_error,\\n    mean_squared_error,\\n    r2_score,\\n    mean_absolute_percentage_error,\\n)\\n\\n# To be used for data scaling and one hot encoding\\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder\\n\\n# To be used for tuning the model\\nfrom sklearn.model_selection import GridSearchCV, RandomizedSearchCV\\n\\n# To be used for hyperparameter tuning searches\\nfrom scipy.stats import loguniform\\nfrom scipy.stats import uniform\\nfrom scipy.stats import expon\\n\\n# To be used for creating pipelines and personalizing them\\nfrom sklearn.pipeline import Pipeline\\nfrom sklearn.compose import ColumnTransformer\\n\\n# To define maximum number of columns to be displayed in a dataframe\\npd.set_option(\\\"display.max_columns\\\", None)\\n# To define the maximum number of rows to be displayed in a dataframe\\npd.set_option(\\\"display.max_rows\\\", 211)\\n\\n# To set some dataframe visualization attributes\\npd.set_option(\\\"max_colwidth\\\", 150)\\n\\n# To supress scientific notations for a dataframe\\n# pd.set_option(\\\"display.float_format\\\", lambda x: \\\"%.3f\\\" % x)\\n\\n# To supress warnings\\n# import warnings\\n\\n# warnings.filterwarnings(\\\"ignore\\\")\\n\\n# To set some plot visualization attributes\\nsns.set_theme()\\nsns.set(font_scale=1.4)\\nsns.set_palette(\\n    (\\n        \\\"midnightblue\\\",\\n        \\\"goldenrod\\\",\\n        \\\"maroon\\\",\\n        \\\"darkolivegreen\\\",\\n        \\\"cadetblue\\\",\\n        \\\"tab:purple\\\",\\n        \\\"yellowgreen\\\",\\n    )\\n)\\n# plt.rc(\\\"font\\\", size=12)\\n# plt.rc(\\\"axes\\\", titlesize=15)\\n# plt.rc(\\\"axes\\\", labelsize=14)\\n# plt.rc(\\\"xtick\\\", labelsize=13)\\n# plt.rc(\\\"ytick\\\", labelsize=13)\\n# plt.rc(\\\"legend\\\", fontsize=13)\\n# plt.rc(\\\"legend\\\", fontsize=14)\\n# plt.rc(\\\"figure\\\", titlesize=16)\\n\\n# To play auditory cue when cell has executed, has warning, or has error and set chime theme\\nimport chime\\n\\nchime.theme(\\\"zelda\\\")\";\n",
       "                var nbb_formatted_code = \"# To structure code automatically\\n%load_ext nb_black\\n\\n# To import/export sqlite databases\\n# import sqlite3 as sql\\n\\n# To save/open python objects in pickle file\\nimport pickle\\n\\n# To help with reading, cleaning, and manipulating data\\nimport pandas as pd\\nimport numpy as np\\n\\n# To help with data visualization\\nimport matplotlib.pyplot as plt\\nimport seaborn as sns\\n\\n# To be used for missing value imputation\\nfrom sklearn.impute import SimpleImputer\\n\\n# To help with model building\\nfrom sklearn.tree import DecisionTreeRegressor\\nfrom sklearn.linear_model import LinearRegression\\n\\nfrom sklearn.ensemble import (\\n    AdaBoostRegressor,\\n    GradientBoostingRegressor,\\n    RandomForestRegressor,\\n    BaggingRegressor,\\n)\\nfrom xgboost import XGBRegressor\\n\\n# To randomly split data, for cross validation, and to check model performance\\nfrom sklearn import metrics\\nfrom sklearn.model_selection import train_test_split, KFold, cross_val_score\\nfrom sklearn.metrics import (\\n    mean_absolute_error,\\n    mean_squared_error,\\n    r2_score,\\n    mean_absolute_percentage_error,\\n)\\n\\n# To be used for data scaling and one hot encoding\\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder\\n\\n# To be used for tuning the model\\nfrom sklearn.model_selection import GridSearchCV, RandomizedSearchCV\\n\\n# To be used for hyperparameter tuning searches\\nfrom scipy.stats import loguniform\\nfrom scipy.stats import uniform\\nfrom scipy.stats import expon\\n\\n# To be used for creating pipelines and personalizing them\\nfrom sklearn.pipeline import Pipeline\\nfrom sklearn.compose import ColumnTransformer\\n\\n# To define maximum number of columns to be displayed in a dataframe\\npd.set_option(\\\"display.max_columns\\\", None)\\n# To define the maximum number of rows to be displayed in a dataframe\\npd.set_option(\\\"display.max_rows\\\", 211)\\n\\n# To set some dataframe visualization attributes\\npd.set_option(\\\"max_colwidth\\\", 150)\\n\\n# To supress scientific notations for a dataframe\\n# pd.set_option(\\\"display.float_format\\\", lambda x: \\\"%.3f\\\" % x)\\n\\n# To supress warnings\\n# import warnings\\n\\n# warnings.filterwarnings(\\\"ignore\\\")\\n\\n# To set some plot visualization attributes\\nsns.set_theme()\\nsns.set(font_scale=1.4)\\nsns.set_palette(\\n    (\\n        \\\"midnightblue\\\",\\n        \\\"goldenrod\\\",\\n        \\\"maroon\\\",\\n        \\\"darkolivegreen\\\",\\n        \\\"cadetblue\\\",\\n        \\\"tab:purple\\\",\\n        \\\"yellowgreen\\\",\\n    )\\n)\\n# plt.rc(\\\"font\\\", size=12)\\n# plt.rc(\\\"axes\\\", titlesize=15)\\n# plt.rc(\\\"axes\\\", labelsize=14)\\n# plt.rc(\\\"xtick\\\", labelsize=13)\\n# plt.rc(\\\"ytick\\\", labelsize=13)\\n# plt.rc(\\\"legend\\\", fontsize=13)\\n# plt.rc(\\\"legend\\\", fontsize=14)\\n# plt.rc(\\\"figure\\\", titlesize=16)\\n\\n# To play auditory cue when cell has executed, has warning, or has error and set chime theme\\nimport chime\\n\\nchime.theme(\\\"zelda\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# To structure code automatically\n",
    "%load_ext nb_black\n",
    "\n",
    "# To import/export sqlite databases\n",
    "# import sqlite3 as sql\n",
    "\n",
    "# To save/open python objects in pickle file\n",
    "import pickle\n",
    "\n",
    "# To help with reading, cleaning, and manipulating data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# To help with data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# To be used for missing value imputation\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# To help with model building\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from sklearn.ensemble import (\n",
    "    AdaBoostRegressor,\n",
    "    GradientBoostingRegressor,\n",
    "    RandomForestRegressor,\n",
    "    BaggingRegressor,\n",
    ")\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# To randomly split data, for cross validation, and to check model performance\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.metrics import (\n",
    "    mean_absolute_error,\n",
    "    mean_squared_error,\n",
    "    r2_score,\n",
    "    mean_absolute_percentage_error,\n",
    ")\n",
    "\n",
    "# To be used for data scaling and one hot encoding\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder\n",
    "\n",
    "# To be used for tuning the model\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "# To be used for hyperparameter tuning searches\n",
    "from scipy.stats import loguniform\n",
    "from scipy.stats import uniform\n",
    "from scipy.stats import expon\n",
    "\n",
    "# To be used for creating pipelines and personalizing them\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# To define maximum number of columns to be displayed in a dataframe\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "# To define the maximum number of rows to be displayed in a dataframe\n",
    "pd.set_option(\"display.max_rows\", 211)\n",
    "\n",
    "# To set some dataframe visualization attributes\n",
    "pd.set_option(\"max_colwidth\", 150)\n",
    "\n",
    "# To supress scientific notations for a dataframe\n",
    "# pd.set_option(\"display.float_format\", lambda x: \"%.3f\" % x)\n",
    "\n",
    "# To supress warnings\n",
    "# import warnings\n",
    "\n",
    "# warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# To set some plot visualization attributes\n",
    "sns.set_theme()\n",
    "sns.set(font_scale=1.4)\n",
    "sns.set_palette(\n",
    "    (\n",
    "        \"midnightblue\",\n",
    "        \"goldenrod\",\n",
    "        \"maroon\",\n",
    "        \"darkolivegreen\",\n",
    "        \"cadetblue\",\n",
    "        \"tab:purple\",\n",
    "        \"yellowgreen\",\n",
    "    )\n",
    ")\n",
    "# plt.rc(\"font\", size=12)\n",
    "# plt.rc(\"axes\", titlesize=15)\n",
    "# plt.rc(\"axes\", labelsize=14)\n",
    "# plt.rc(\"xtick\", labelsize=13)\n",
    "# plt.rc(\"ytick\", labelsize=13)\n",
    "# plt.rc(\"legend\", fontsize=13)\n",
    "# plt.rc(\"legend\", fontsize=14)\n",
    "# plt.rc(\"figure\", titlesize=16)\n",
    "\n",
    "# To play auditory cue when cell has executed, has warning, or has error and set chime theme\n",
    "import chime\n",
    "\n",
    "chime.theme(\"zelda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc818a82",
   "metadata": {},
   "source": [
    "## Data Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed005f6",
   "metadata": {},
   "source": [
    "### [Reading](https://github.com/teresahanak/wikipedia-life-expectancy/blob/main/wp_life_expect_train_preproc.csv), Sampling, and Checking Data Shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ca58a95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 77624 rows and 20 columns.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_references</th>\n",
       "      <th>age</th>\n",
       "      <th>sciences</th>\n",
       "      <th>social</th>\n",
       "      <th>spiritual</th>\n",
       "      <th>academia_humanities</th>\n",
       "      <th>business_farming</th>\n",
       "      <th>arts</th>\n",
       "      <th>sports</th>\n",
       "      <th>law_enf_military_operator</th>\n",
       "      <th>politics_govt_law</th>\n",
       "      <th>crime</th>\n",
       "      <th>num_categories</th>\n",
       "      <th>age_sqrd</th>\n",
       "      <th>recip_num_references</th>\n",
       "      <th>years</th>\n",
       "      <th>years_sqrd</th>\n",
       "      <th>region</th>\n",
       "      <th>prior_region</th>\n",
       "      <th>known_for</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>73.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5329.0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>8</td>\n",
       "      <td>64</td>\n",
       "      <td>Europe</td>\n",
       "      <td>No Prior Region</td>\n",
       "      <td>spiritual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>90.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>8100.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>13</td>\n",
       "      <td>169</td>\n",
       "      <td>North America</td>\n",
       "      <td>No Prior Region</td>\n",
       "      <td>two</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_references   age  sciences  social  spiritual  academia_humanities  \\\n",
       "0               4  73.0         0       0          1                    0   \n",
       "1               3  90.0         1       0          0                    1   \n",
       "\n",
       "   business_farming  arts  sports  law_enf_military_operator  \\\n",
       "0                 0     0       0                          0   \n",
       "1                 0     0       0                          0   \n",
       "\n",
       "   politics_govt_law  crime  num_categories  age_sqrd  recip_num_references  \\\n",
       "0                  0      0               1    5329.0              0.250000   \n",
       "1                  0      0               2    8100.0              0.333333   \n",
       "\n",
       "   years  years_sqrd         region     prior_region  known_for  \n",
       "0      8          64         Europe  No Prior Region  spiritual  \n",
       "1     13         169  North America  No Prior Region        two  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2;\n",
       "                var nbb_unformatted_code = \"# Reading the dataset\\ndata = pd.read_csv(\\\"wp_life_expect_train_preproc.csv\\\")\\n\\n# Making a working copy\\ndf = data.copy()\\n\\n# Checking the shape\\nprint(f\\\"There are {df.shape[0]} rows and {df.shape[1]} columns.\\\")\\n\\n# Checking first 2 rows of the data\\ndf.head(2)\";\n",
       "                var nbb_formatted_code = \"# Reading the dataset\\ndata = pd.read_csv(\\\"wp_life_expect_train_preproc.csv\\\")\\n\\n# Making a working copy\\ndf = data.copy()\\n\\n# Checking the shape\\nprint(f\\\"There are {df.shape[0]} rows and {df.shape[1]} columns.\\\")\\n\\n# Checking first 2 rows of the data\\ndf.head(2)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Reading the dataset\n",
    "data = pd.read_csv(\"wp_life_expect_train_preproc.csv\")\n",
    "\n",
    "# Making a working copy\n",
    "df = data.copy()\n",
    "\n",
    "# Checking the shape\n",
    "print(f\"There are {df.shape[0]} rows and {df.shape[1]} columns.\")\n",
    "\n",
    "# Checking first 2 rows of the data\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6cca416f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_references</th>\n",
       "      <th>age</th>\n",
       "      <th>sciences</th>\n",
       "      <th>social</th>\n",
       "      <th>spiritual</th>\n",
       "      <th>academia_humanities</th>\n",
       "      <th>business_farming</th>\n",
       "      <th>arts</th>\n",
       "      <th>sports</th>\n",
       "      <th>law_enf_military_operator</th>\n",
       "      <th>politics_govt_law</th>\n",
       "      <th>crime</th>\n",
       "      <th>num_categories</th>\n",
       "      <th>age_sqrd</th>\n",
       "      <th>recip_num_references</th>\n",
       "      <th>years</th>\n",
       "      <th>years_sqrd</th>\n",
       "      <th>region</th>\n",
       "      <th>prior_region</th>\n",
       "      <th>known_for</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>77622</th>\n",
       "      <td>7</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5476.0</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>North America</td>\n",
       "      <td>No Prior Region</td>\n",
       "      <td>arts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77623</th>\n",
       "      <td>5</td>\n",
       "      <td>92.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8464.0</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>8</td>\n",
       "      <td>64</td>\n",
       "      <td>Europe</td>\n",
       "      <td>No Prior Region</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       num_references   age  sciences  social  spiritual  academia_humanities  \\\n",
       "77622               7  74.0         0       0          0                    0   \n",
       "77623               5  92.0         0       0          0                    0   \n",
       "\n",
       "       business_farming  arts  sports  law_enf_military_operator  \\\n",
       "77622                 0     1       0                          0   \n",
       "77623                 0     0       1                          0   \n",
       "\n",
       "       politics_govt_law  crime  num_categories  age_sqrd  \\\n",
       "77622                  0      0               1    5476.0   \n",
       "77623                  0      0               1    8464.0   \n",
       "\n",
       "       recip_num_references  years  years_sqrd         region  \\\n",
       "77622              0.142857      0           0  North America   \n",
       "77623              0.200000      8          64         Europe   \n",
       "\n",
       "          prior_region known_for  \n",
       "77622  No Prior Region      arts  \n",
       "77623  No Prior Region    sports  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 3;\n",
       "                var nbb_unformatted_code = \"# Checking last 2 rows of the data\\ndf.tail(2)\";\n",
       "                var nbb_formatted_code = \"# Checking last 2 rows of the data\\ndf.tail(2)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Checking last 2 rows of the data\n",
    "df.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de6e8ee5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_references</th>\n",
       "      <th>age</th>\n",
       "      <th>sciences</th>\n",
       "      <th>social</th>\n",
       "      <th>spiritual</th>\n",
       "      <th>academia_humanities</th>\n",
       "      <th>business_farming</th>\n",
       "      <th>arts</th>\n",
       "      <th>sports</th>\n",
       "      <th>law_enf_military_operator</th>\n",
       "      <th>politics_govt_law</th>\n",
       "      <th>crime</th>\n",
       "      <th>num_categories</th>\n",
       "      <th>age_sqrd</th>\n",
       "      <th>recip_num_references</th>\n",
       "      <th>years</th>\n",
       "      <th>years_sqrd</th>\n",
       "      <th>region</th>\n",
       "      <th>prior_region</th>\n",
       "      <th>known_for</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4210</th>\n",
       "      <td>11</td>\n",
       "      <td>96.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9216.0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>15</td>\n",
       "      <td>225</td>\n",
       "      <td>North America</td>\n",
       "      <td>No Prior Region</td>\n",
       "      <td>arts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35236</th>\n",
       "      <td>13</td>\n",
       "      <td>96.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9216.0</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>27</td>\n",
       "      <td>729</td>\n",
       "      <td>Asia</td>\n",
       "      <td>No Prior Region</td>\n",
       "      <td>sciences</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72538</th>\n",
       "      <td>3</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4489.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>17</td>\n",
       "      <td>289</td>\n",
       "      <td>Europe</td>\n",
       "      <td>No Prior Region</td>\n",
       "      <td>arts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68214</th>\n",
       "      <td>11</td>\n",
       "      <td>84.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>7056.0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>21</td>\n",
       "      <td>441</td>\n",
       "      <td>Oceania</td>\n",
       "      <td>No Prior Region</td>\n",
       "      <td>two</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15169</th>\n",
       "      <td>3</td>\n",
       "      <td>94.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8836.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>20</td>\n",
       "      <td>400</td>\n",
       "      <td>North America</td>\n",
       "      <td>No Prior Region</td>\n",
       "      <td>academia_humanities</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       num_references   age  sciences  social  spiritual  academia_humanities  \\\n",
       "4210               11  96.0         0       0          0                    0   \n",
       "35236              13  96.0         1       0          0                    0   \n",
       "72538               3  67.0         0       0          0                    0   \n",
       "68214              11  84.0         1       0          0                    1   \n",
       "15169               3  94.0         0       0          0                    1   \n",
       "\n",
       "       business_farming  arts  sports  law_enf_military_operator  \\\n",
       "4210                  0     1       0                          0   \n",
       "35236                 0     0       0                          0   \n",
       "72538                 0     1       0                          0   \n",
       "68214                 0     0       0                          0   \n",
       "15169                 0     0       0                          0   \n",
       "\n",
       "       politics_govt_law  crime  num_categories  age_sqrd  \\\n",
       "4210                   0      0               1    9216.0   \n",
       "35236                  0      0               1    9216.0   \n",
       "72538                  0      0               1    4489.0   \n",
       "68214                  0      0               2    7056.0   \n",
       "15169                  0      0               1    8836.0   \n",
       "\n",
       "       recip_num_references  years  years_sqrd         region  \\\n",
       "4210               0.090909     15         225  North America   \n",
       "35236              0.076923     27         729           Asia   \n",
       "72538              0.333333     17         289         Europe   \n",
       "68214              0.090909     21         441        Oceania   \n",
       "15169              0.333333     20         400  North America   \n",
       "\n",
       "          prior_region            known_for  \n",
       "4210   No Prior Region                 arts  \n",
       "35236  No Prior Region             sciences  \n",
       "72538  No Prior Region                 arts  \n",
       "68214  No Prior Region                  two  \n",
       "15169  No Prior Region  academia_humanities  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 4;\n",
       "                var nbb_unformatted_code = \"# Checking a sample of the data\\ndf.sample(5)\";\n",
       "                var nbb_formatted_code = \"# Checking a sample of the data\\ndf.sample(5)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Checking a sample of the data\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d5f29da",
   "metadata": {},
   "source": [
    "### Checking Data Types and Null Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf505f87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 77624 entries, 0 to 77623\n",
      "Data columns (total 20 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   num_references             77624 non-null  int64  \n",
      " 1   age                        77624 non-null  float64\n",
      " 2   sciences                   77624 non-null  int64  \n",
      " 3   social                     77624 non-null  int64  \n",
      " 4   spiritual                  77624 non-null  int64  \n",
      " 5   academia_humanities        77624 non-null  int64  \n",
      " 6   business_farming           77624 non-null  int64  \n",
      " 7   arts                       77624 non-null  int64  \n",
      " 8   sports                     77624 non-null  int64  \n",
      " 9   law_enf_military_operator  77624 non-null  int64  \n",
      " 10  politics_govt_law          77624 non-null  int64  \n",
      " 11  crime                      77624 non-null  int64  \n",
      " 12  num_categories             77624 non-null  int64  \n",
      " 13  age_sqrd                   77624 non-null  float64\n",
      " 14  recip_num_references       77624 non-null  float64\n",
      " 15  years                      77624 non-null  int64  \n",
      " 16  years_sqrd                 77624 non-null  int64  \n",
      " 17  region                     77624 non-null  object \n",
      " 18  prior_region               77624 non-null  object \n",
      " 19  known_for                  77624 non-null  object \n",
      "dtypes: float64(3), int64(14), object(3)\n",
      "memory usage: 11.8+ MB\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 5;\n",
       "                var nbb_unformatted_code = \"# Checking data types and null values\\ndf.info()\";\n",
       "                var nbb_formatted_code = \"# Checking data types and null values\\ndf.info()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Checking data types and null values\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c459d7f8",
   "metadata": {},
   "source": [
    "#### Observations:\n",
    "- With our dataset loaded, we are ready for modeling.\n",
    "- We have three variables that need typcasting from object to category, then one hot encoding just prior to modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bdf2565",
   "metadata": {},
   "source": [
    "#### Typecasting `region`, `prior_region`, and `known_for` as Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2aef3f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 77624 entries, 0 to 77623\n",
      "Data columns (total 20 columns):\n",
      " #   Column                     Non-Null Count  Dtype   \n",
      "---  ------                     --------------  -----   \n",
      " 0   num_references             77624 non-null  int64   \n",
      " 1   age                        77624 non-null  float64 \n",
      " 2   sciences                   77624 non-null  int64   \n",
      " 3   social                     77624 non-null  int64   \n",
      " 4   spiritual                  77624 non-null  int64   \n",
      " 5   academia_humanities        77624 non-null  int64   \n",
      " 6   business_farming           77624 non-null  int64   \n",
      " 7   arts                       77624 non-null  int64   \n",
      " 8   sports                     77624 non-null  int64   \n",
      " 9   law_enf_military_operator  77624 non-null  int64   \n",
      " 10  politics_govt_law          77624 non-null  int64   \n",
      " 11  crime                      77624 non-null  int64   \n",
      " 12  num_categories             77624 non-null  int64   \n",
      " 13  age_sqrd                   77624 non-null  float64 \n",
      " 14  recip_num_references       77624 non-null  float64 \n",
      " 15  years                      77624 non-null  int64   \n",
      " 16  years_sqrd                 77624 non-null  int64   \n",
      " 17  region                     77624 non-null  category\n",
      " 18  prior_region               77624 non-null  category\n",
      " 19  known_for                  77624 non-null  category\n",
      "dtypes: category(3), float64(3), int64(14)\n",
      "memory usage: 10.3 MB\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 6;\n",
       "                var nbb_unformatted_code = \"# Typcasting prior_region and region as categorical\\ndf[[\\\"prior_region\\\", \\\"region\\\", \\\"known_for\\\"]] = df[\\n    [\\\"prior_region\\\", \\\"region\\\", \\\"known_for\\\"]\\n].astype(\\\"category\\\")\\n\\n# Re-check info\\ndf.info()\";\n",
       "                var nbb_formatted_code = \"# Typcasting prior_region and region as categorical\\ndf[[\\\"prior_region\\\", \\\"region\\\", \\\"known_for\\\"]] = df[\\n    [\\\"prior_region\\\", \\\"region\\\", \\\"known_for\\\"]\\n].astype(\\\"category\\\")\\n\\n# Re-check info\\ndf.info()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Typcasting prior_region and region as categorical\n",
    "df[[\"prior_region\", \"region\", \"known_for\"]] = df[\n",
    "    [\"prior_region\", \"region\", \"known_for\"]\n",
    "].astype(\"category\")\n",
    "\n",
    "# Re-check info\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1eafaa",
   "metadata": {},
   "source": [
    "## Data Preparation for Modeling\n",
    "In contrast to building the [linear regression model](https://github.com/teresahanak/wikipedia-life-expectancy/blob/main/wp_life_expect_olsmodel_thanak_2022_10_9.ipynb), we will be tuning these models.  So, we will split the train set into train and validation sets and utilize the `test` set only to check out-of-sample performance of the champion model.  We will load and treat the test set at that point."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef2eaa0",
   "metadata": {},
   "source": [
    "### Defining Independent and Dependent Variables for Train and Validation Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "71fbe26e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 54336 rows and 34 columns in the train set.\n",
      "\n",
      "There are 23288 rows and 34 columns in the validation set.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_references</th>\n",
       "      <th>years</th>\n",
       "      <th>region_Asia</th>\n",
       "      <th>region_Central Asia</th>\n",
       "      <th>region_Europe</th>\n",
       "      <th>region_Mid-Cent America/Caribbean</th>\n",
       "      <th>region_Middle East</th>\n",
       "      <th>region_North America</th>\n",
       "      <th>region_Oceania</th>\n",
       "      <th>region_Russian Federation</th>\n",
       "      <th>region_South America</th>\n",
       "      <th>region_South East Asia</th>\n",
       "      <th>prior_region_Asia</th>\n",
       "      <th>prior_region_Central Asia</th>\n",
       "      <th>prior_region_Europe</th>\n",
       "      <th>prior_region_Mid-Cent America/Caribbean</th>\n",
       "      <th>prior_region_Middle East</th>\n",
       "      <th>prior_region_No Prior Region</th>\n",
       "      <th>prior_region_North America</th>\n",
       "      <th>prior_region_Oceania</th>\n",
       "      <th>prior_region_Russian Federation</th>\n",
       "      <th>prior_region_South America</th>\n",
       "      <th>prior_region_South East Asia</th>\n",
       "      <th>known_for_arts</th>\n",
       "      <th>known_for_business_farming</th>\n",
       "      <th>known_for_crime</th>\n",
       "      <th>known_for_law_enf_military_operator</th>\n",
       "      <th>known_for_politics_govt_law</th>\n",
       "      <th>known_for_sciences</th>\n",
       "      <th>known_for_social</th>\n",
       "      <th>known_for_spiritual</th>\n",
       "      <th>known_for_sports</th>\n",
       "      <th>known_for_three_to_five</th>\n",
       "      <th>known_for_two</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>75611</th>\n",
       "      <td>11.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       num_references  years  region_Asia  region_Central Asia  region_Europe  \\\n",
       "75611            11.0   17.0          0.0                  0.0            0.0   \n",
       "\n",
       "       region_Mid-Cent America/Caribbean  region_Middle East  \\\n",
       "75611                                0.0                 0.0   \n",
       "\n",
       "       region_North America  region_Oceania  region_Russian Federation  \\\n",
       "75611                   1.0             0.0                        0.0   \n",
       "\n",
       "       region_South America  region_South East Asia  prior_region_Asia  \\\n",
       "75611                   0.0                     0.0                0.0   \n",
       "\n",
       "       prior_region_Central Asia  prior_region_Europe  \\\n",
       "75611                        0.0                  0.0   \n",
       "\n",
       "       prior_region_Mid-Cent America/Caribbean  prior_region_Middle East  \\\n",
       "75611                                      0.0                       0.0   \n",
       "\n",
       "       prior_region_No Prior Region  prior_region_North America  \\\n",
       "75611                           1.0                         0.0   \n",
       "\n",
       "       prior_region_Oceania  prior_region_Russian Federation  \\\n",
       "75611                   0.0                              0.0   \n",
       "\n",
       "       prior_region_South America  prior_region_South East Asia  \\\n",
       "75611                         0.0                           0.0   \n",
       "\n",
       "       known_for_arts  known_for_business_farming  known_for_crime  \\\n",
       "75611             1.0                         0.0              0.0   \n",
       "\n",
       "       known_for_law_enf_military_operator  known_for_politics_govt_law  \\\n",
       "75611                                  0.0                          0.0   \n",
       "\n",
       "       known_for_sciences  known_for_social  known_for_spiritual  \\\n",
       "75611                 0.0               0.0                  0.0   \n",
       "\n",
       "       known_for_sports  known_for_three_to_five  known_for_two  \n",
       "75611               0.0                      0.0            0.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 7;\n",
       "                var nbb_unformatted_code = \"# Creating list of predictor columns\\npredictor_cols = [\\n    \\\"num_references\\\",\\n    \\\"years\\\",\\n    \\\"region\\\",\\n    \\\"prior_region\\\",\\n    \\\"known_for\\\",\\n]\\n\\n# Defining target column\\ntarget = \\\"age\\\"\\n\\n# Defining independent and dependent variables\\nX = df[predictor_cols]\\ny = df[target]\\n\\n# One hot encoding of categorical predictors and typecasting all predictors as float\\nX = pd.get_dummies(X, drop_first=True).astype(\\\"float64\\\")\\n\\n# Splitting into 70:30 train and validation sets\\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=42)\\n\\n# Checking shape of train and validation sets\\nprint(\\n    f\\\"There are {X_train.shape[0]} rows and {X_train.shape[1]} columns in the train set.\\\\n\\\"\\n)\\nprint(\\n    f\\\"There are {X_val.shape[0]} rows and {X_val.shape[1]} columns in the validation set.\\\\n\\\"\\n)\\n\\n# Checking a sample\\nX_train.sample()\";\n",
       "                var nbb_formatted_code = \"# Creating list of predictor columns\\npredictor_cols = [\\n    \\\"num_references\\\",\\n    \\\"years\\\",\\n    \\\"region\\\",\\n    \\\"prior_region\\\",\\n    \\\"known_for\\\",\\n]\\n\\n# Defining target column\\ntarget = \\\"age\\\"\\n\\n# Defining independent and dependent variables\\nX = df[predictor_cols]\\ny = df[target]\\n\\n# One hot encoding of categorical predictors and typecasting all predictors as float\\nX = pd.get_dummies(X, drop_first=True).astype(\\\"float64\\\")\\n\\n# Splitting into 70:30 train and validation sets\\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=42)\\n\\n# Checking shape of train and validation sets\\nprint(\\n    f\\\"There are {X_train.shape[0]} rows and {X_train.shape[1]} columns in the train set.\\\\n\\\"\\n)\\nprint(\\n    f\\\"There are {X_val.shape[0]} rows and {X_val.shape[1]} columns in the validation set.\\\\n\\\"\\n)\\n\\n# Checking a sample\\nX_train.sample()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Creating list of predictor columns\n",
    "predictor_cols = [\n",
    "    \"num_references\",\n",
    "    \"years\",\n",
    "    \"region\",\n",
    "    \"prior_region\",\n",
    "    \"known_for\",\n",
    "]\n",
    "\n",
    "# Defining target column\n",
    "target = \"age\"\n",
    "\n",
    "# Defining independent and dependent variables\n",
    "X = df[predictor_cols]\n",
    "y = df[target]\n",
    "\n",
    "# One hot encoding of categorical predictors and typecasting all predictors as float\n",
    "X = pd.get_dummies(X, drop_first=True).astype(\"float64\")\n",
    "\n",
    "# Splitting into 70:30 train and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Checking shape of train and validation sets\n",
    "print(\n",
    "    f\"There are {X_train.shape[0]} rows and {X_train.shape[1]} columns in the train set.\\n\"\n",
    ")\n",
    "print(\n",
    "    f\"There are {X_val.shape[0]} rows and {X_val.shape[1]} columns in the validation set.\\n\"\n",
    ")\n",
    "\n",
    "# Checking a sample\n",
    "X_train.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318bcc3d",
   "metadata": {},
   "source": [
    "## Model Building\n",
    "#### Model Evaluation Criterion\n",
    "The predictions made by the regressors will have the following performance metrics:\n",
    "- RMSE\n",
    "- MAE\n",
    "- R$^2$\n",
    "- Ajusted R$^2$\n",
    "- MAPE\n",
    "\n",
    "#### Which Metric to Optimize?\n",
    "- For hyperparameter tuning, we will optimize R$^2$, which is the proportion of variation in the target that is explained by the predictors.  \n",
    "\n",
    "- To select the champion model, will compare Adjusted R$^2$.  It is the metric that represents the amount of variation in the target that is explained by the predictors, with a penalty for more predictors.  The number of included predictors may vary between algorithms, especially as we are building including examples of decion tree regressors.  R$^2$ will improve with the addition of predictors, even if they contribute very little to the model, whereas, the penalty in Adjusted R$^2$ offsets such an increase."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bdb1386",
   "metadata": {},
   "source": [
    "#### Functions for Checking and Tuning Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e40e3f27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 8;\n",
       "                var nbb_unformatted_code = \"# Function to compute adjusted R-squared\\ndef adj_r2_score(predictors, targets, predictions):\\n    r2 = r2_score(targets, predictions)\\n    n = predictors.shape[0]\\n    k = predictors.shape[1]\\n    return 1 - ((1 - r2) * (n - 1) / (n - k - 1))\\n\\n\\n# Function to compute MAPE\\ndef mape_score(targets, predictions):\\n    return np.mean(np.abs((targets - predictions) / targets)) * 100\\n\\n\\n# Function to compute and display different metrics to check performance of a regression model\\ndef model_performance_regression(model, predictors, target):\\n    \\\"\\\"\\\"\\n    Function to compute and return a dataframe of different metrics to check\\n    regression model performance\\n    \\n    model: regressor\\n    predictors: independent variables\\n    target: dependent variable\\n    \\\"\\\"\\\"\\n    # Predictions\\n    pred = model.predict(predictors)\\n\\n    r2 = r2_score(target, pred)  # To compute R-squared\\n    adjr2 = adj_r2_score(predictors, target, pred)  # To compute adjusted R-squared\\n    rmse = np.sqrt(mean_squared_error(target, pred))  # To compute RMSE\\n    mae = mean_absolute_error(target, pred)  # To compute MAE\\n    mape = mape_score(target, pred)  # To compute MAPE\\n\\n    # Creating a dataframe of metrics\\n    df_perf = pd.DataFrame(\\n        {\\n            \\\"RMSE\\\": rmse,\\n            \\\"MAE\\\": mae,\\n            \\\"R-squared\\\": r2,\\n            \\\"Adj. R-squared\\\": adjr2,\\n            \\\"MAPE\\\": mape,\\n        },\\n        index=[0],\\n    )\\n\\n    return df_perf\";\n",
       "                var nbb_formatted_code = \"# Function to compute adjusted R-squared\\ndef adj_r2_score(predictors, targets, predictions):\\n    r2 = r2_score(targets, predictions)\\n    n = predictors.shape[0]\\n    k = predictors.shape[1]\\n    return 1 - ((1 - r2) * (n - 1) / (n - k - 1))\\n\\n\\n# Function to compute MAPE\\ndef mape_score(targets, predictions):\\n    return np.mean(np.abs((targets - predictions) / targets)) * 100\\n\\n\\n# Function to compute and display different metrics to check performance of a regression model\\ndef model_performance_regression(model, predictors, target):\\n    \\\"\\\"\\\"\\n    Function to compute and return a dataframe of different metrics to check\\n    regression model performance\\n    \\n    model: regressor\\n    predictors: independent variables\\n    target: dependent variable\\n    \\\"\\\"\\\"\\n    # Predictions\\n    pred = model.predict(predictors)\\n\\n    r2 = r2_score(target, pred)  # To compute R-squared\\n    adjr2 = adj_r2_score(predictors, target, pred)  # To compute adjusted R-squared\\n    rmse = np.sqrt(mean_squared_error(target, pred))  # To compute RMSE\\n    mae = mean_absolute_error(target, pred)  # To compute MAE\\n    mape = mape_score(target, pred)  # To compute MAPE\\n\\n    # Creating a dataframe of metrics\\n    df_perf = pd.DataFrame(\\n        {\\n            \\\"RMSE\\\": rmse,\\n            \\\"MAE\\\": mae,\\n            \\\"R-squared\\\": r2,\\n            \\\"Adj. R-squared\\\": adjr2,\\n            \\\"MAPE\\\": mape,\\n        },\\n        index=[0],\\n    )\\n\\n    return df_perf\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Function to compute adjusted R-squared\n",
    "def adj_r2_score(predictors, targets, predictions):\n",
    "    r2 = r2_score(targets, predictions)\n",
    "    n = predictors.shape[0]\n",
    "    k = predictors.shape[1]\n",
    "    return 1 - ((1 - r2) * (n - 1) / (n - k - 1))\n",
    "\n",
    "\n",
    "# Function to compute MAPE\n",
    "def mape_score(targets, predictions):\n",
    "    return np.mean(np.abs((targets - predictions) / targets)) * 100\n",
    "\n",
    "\n",
    "# Function to compute and display different metrics to check performance of a regression model\n",
    "def model_performance_regression(model, predictors, target):\n",
    "    \"\"\"\n",
    "    Function to compute and return a dataframe of different metrics to check\n",
    "    regression model performance\n",
    "    \n",
    "    model: regressor\n",
    "    predictors: independent variables\n",
    "    target: dependent variable\n",
    "    \"\"\"\n",
    "    # Predictions\n",
    "    pred = model.predict(predictors)\n",
    "\n",
    "    r2 = r2_score(target, pred)  # To compute R-squared\n",
    "    adjr2 = adj_r2_score(predictors, target, pred)  # To compute adjusted R-squared\n",
    "    rmse = np.sqrt(mean_squared_error(target, pred))  # To compute RMSE\n",
    "    mae = mean_absolute_error(target, pred)  # To compute MAE\n",
    "    mape = mape_score(target, pred)  # To compute MAPE\n",
    "\n",
    "    # Creating a dataframe of metrics\n",
    "    df_perf = pd.DataFrame(\n",
    "        {\n",
    "            \"RMSE\": rmse,\n",
    "            \"MAE\": mae,\n",
    "            \"R-squared\": r2,\n",
    "            \"Adj. R-squared\": adjr2,\n",
    "            \"MAPE\": mape,\n",
    "        },\n",
    "        index=[0],\n",
    "    )\n",
    "\n",
    "    return df_perf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc98943",
   "metadata": {},
   "source": [
    "#### Defining Scorer for Cross-validation and Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea396d00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 9;\n",
       "                var nbb_unformatted_code = \"# Type of scoring used to compare parameter combinations--maximizing Adj R-squared\\nscorer = \\\"r2\\\"\";\n",
       "                var nbb_formatted_code = \"# Type of scoring used to compare parameter combinations--maximizing Adj R-squared\\nscorer = \\\"r2\\\"\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Type of scoring used to compare parameter combinations--maximizing Adj R-squared\n",
    "scorer = \"r2\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef465812",
   "metadata": {},
   "source": [
    "### Building the Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "294e79f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cross-Validation:\n",
      "\n",
      "Dtree: -0.3729288388785845\n",
      "Random Forest: -0.06498999161620542\n",
      "Bagging Dtree: -0.09780574269930184\n",
      "GBM: 0.10092407348408765\n",
      "AdaBoost Dtree: -0.041942386214516916\n",
      "XGB_gbtree: 0.08816799208071073\n",
      "XGB_gblinear: 0.08319873674270592\n",
      "\n",
      "Validation Performance:\n",
      "\n",
      "Dtree: -0.3725798827812159\n",
      "Random Forest: -0.06593088660036917\n",
      "Bagging Dtree: -0.09925861808350978\n",
      "GBM: 0.10355465508610728\n",
      "AdaBoost Dtree: -0.05608653156428711\n",
      "XGB_gbtree: 0.09146574210948322\n",
      "XGB_gblinear: 0.08716558110407124\n",
      "CPU times: total: 3min 4s\n",
      "Wall time: 1min 4s\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 10;\n",
       "                var nbb_unformatted_code = \"%%time\\n\\n# Creating list to store the models\\nmodels = []\\n\\n# Appending models to the list\\nmodels.append(('Dtree', DecisionTreeRegressor(random_state=42)))\\n\\nmodels.append(('Random Forest', RandomForestRegressor(random_state=42)))\\n\\nmodels.append(('Bagging Dtree', BaggingRegressor(random_state=42)))\\n\\nmodels.append(('GBM', GradientBoostingRegressor(random_state=42)))\\n\\nmodels.append(('AdaBoost Dtree', AdaBoostRegressor(random_state=42)))\\n\\nmodels.append(('XGB_gbtree', XGBRegressor(random_state=42)))\\n\\nmodels.append(('XGB_gblinear', XGBRegressor(random_state=42, booster='gblinear')))\\n\\n# Create empty list to store all model's names and CV scores\\nnames = []\\nresults = []\\n\\n# Loop through all models to get the mean cross validated score\\nprint(\\\"\\\\n\\\" \\\"Cross-Validation:\\\" \\\"\\\\n\\\")\\n\\nfor name, model in models:\\n    cv_result = cross_val_score(\\n        estimator=model, X=X_train, y=y_train, scoring=scorer, cv=5\\n    )\\n    results.append(cv_result)\\n    names.append(name)\\n    print(f\\\"{name}: {cv_result.mean()}\\\")\\n    \\nprint(\\\"\\\\n\\\" \\\"Validation Performance:\\\" \\\"\\\\n\\\")\\n\\nfor name, model in models:\\n    model.fit(X_train, y_train)\\n    scores = r2_score(y_val, model.predict(X_val))\\n    print(\\\"{}: {}\\\".format(name, scores))\";\n",
       "                var nbb_formatted_code = \"%%time\\n\\n# Creating list to store the models\\nmodels = []\\n\\n# Appending models to the list\\nmodels.append(('Dtree', DecisionTreeRegressor(random_state=42)))\\n\\nmodels.append(('Random Forest', RandomForestRegressor(random_state=42)))\\n\\nmodels.append(('Bagging Dtree', BaggingRegressor(random_state=42)))\\n\\nmodels.append(('GBM', GradientBoostingRegressor(random_state=42)))\\n\\nmodels.append(('AdaBoost Dtree', AdaBoostRegressor(random_state=42)))\\n\\nmodels.append(('XGB_gbtree', XGBRegressor(random_state=42)))\\n\\nmodels.append(('XGB_gblinear', XGBRegressor(random_state=42, booster='gblinear')))\\n\\n# Create empty list to store all model's names and CV scores\\nnames = []\\nresults = []\\n\\n# Loop through all models to get the mean cross validated score\\nprint(\\\"\\\\n\\\" \\\"Cross-Validation:\\\" \\\"\\\\n\\\")\\n\\nfor name, model in models:\\n    cv_result = cross_val_score(\\n        estimator=model, X=X_train, y=y_train, scoring=scorer, cv=5\\n    )\\n    results.append(cv_result)\\n    names.append(name)\\n    print(f\\\"{name}: {cv_result.mean()}\\\")\\n    \\nprint(\\\"\\\\n\\\" \\\"Validation Performance:\\\" \\\"\\\\n\\\")\\n\\nfor name, model in models:\\n    model.fit(X_train, y_train)\\n    scores = r2_score(y_val, model.predict(X_val))\\n    print(\\\"{}: {}\\\".format(name, scores))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Creating list to store the models\n",
    "models = []\n",
    "\n",
    "# Appending models to the list\n",
    "models.append(('Dtree', DecisionTreeRegressor(random_state=42)))\n",
    "\n",
    "models.append(('Random Forest', RandomForestRegressor(random_state=42)))\n",
    "\n",
    "models.append(('Bagging Dtree', BaggingRegressor(random_state=42)))\n",
    "\n",
    "models.append(('GBM', GradientBoostingRegressor(random_state=42)))\n",
    "\n",
    "models.append(('AdaBoost Dtree', AdaBoostRegressor(random_state=42)))\n",
    "\n",
    "models.append(('XGB_gbtree', XGBRegressor(random_state=42)))\n",
    "\n",
    "models.append(('XGB_gblinear', XGBRegressor(random_state=42, booster='gblinear')))\n",
    "\n",
    "# Create empty list to store all model's names and CV scores\n",
    "names = []\n",
    "results = []\n",
    "\n",
    "# Loop through all models to get the mean cross validated score\n",
    "print(\"\\n\" \"Cross-Validation:\" \"\\n\")\n",
    "\n",
    "for name, model in models:\n",
    "    cv_result = cross_val_score(\n",
    "        estimator=model, X=X_train, y=y_train, scoring=scorer, cv=5\n",
    "    )\n",
    "    results.append(cv_result)\n",
    "    names.append(name)\n",
    "    print(f\"{name}: {cv_result.mean()}\")\n",
    "    \n",
    "print(\"\\n\" \"Validation Performance:\" \"\\n\")\n",
    "\n",
    "for name, model in models:\n",
    "    model.fit(X_train, y_train)\n",
    "    scores = r2_score(y_val, model.predict(X_val))\n",
    "    print(\"{}: {}\".format(name, scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2f009f68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x504 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 11;\n",
       "                var nbb_unformatted_code = \"# Plotting boxplots for CV scores of all models defined above\\nfig = plt.figure(figsize=(20, 7))\\n\\nfig.suptitle(\\\"Algorithm Comparison for Cross-validation R-squared Score\\\")\\nax = fig.add_subplot(111)\\n\\nplt.boxplot(results)\\nax.set_xticklabels(names)\\nplt.xticks(rotation=30)\\n\\nplt.show()\";\n",
       "                var nbb_formatted_code = \"# Plotting boxplots for CV scores of all models defined above\\nfig = plt.figure(figsize=(20, 7))\\n\\nfig.suptitle(\\\"Algorithm Comparison for Cross-validation R-squared Score\\\")\\nax = fig.add_subplot(111)\\n\\nplt.boxplot(results)\\nax.set_xticklabels(names)\\nplt.xticks(rotation=30)\\n\\nplt.show()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting boxplots for CV scores of all models defined above\n",
    "fig = plt.figure(figsize=(20, 7))\n",
    "\n",
    "fig.suptitle(\"Algorithm Comparison for Cross-validation R-squared Score\")\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "plt.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "plt.xticks(rotation=30)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31587e35",
   "metadata": {},
   "source": [
    "#### Observations:\n",
    "- We have negative R$^2$ values for four of the models.  This means they are performing worse than a model that merely equates the predicted values to the constant mean value of the target.\n",
    "- The remaining three models, *GBM*, *XGB_gbtree*, and *XGB_gblinear* are giving generalized performances on train and validation sets, with similar, albeit very low, R$^2$ scores as [*olsmodel3*](https://github.com/teresahanak/wikipedia-life-expectancy/blob/main/wp_life_expect_olsmodel_thanak_2022_10_9.ipynb) (0.087).  Before hyperparameter tuning, *GBM* is outperforming the other models, including *olsmodel3*, with both train and validation R$^2$ scores of ~0.10.\n",
    "- We will perform hyperparameter tuning on the top 3 models.  Purely as an exercise we will also keep *Random Forest* in the mix."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70e8a88",
   "metadata": {},
   "source": [
    "#### Collecting Models with Best Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d7591d99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 12;\n",
       "                var nbb_unformatted_code = \"# List of top models so far\\ntop_models = [models[1]] + [models[3]] + models[-2:]\";\n",
       "                var nbb_formatted_code = \"# List of top models so far\\ntop_models = [models[1]] + [models[3]] + models[-2:]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# List of top models so far\n",
    "top_models = [models[1]] + [models[3]] + models[-2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93e521f",
   "metadata": {},
   "source": [
    "#### Creating Dataframes to Compare Training and Validation Performance of Best Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4d39e401",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 13;\n",
       "                var nbb_unformatted_code = \"# Creating empty dictionary to hold the models\\nmodels_to_tune = {}\\n\\n# For loop to add models to dictionary\\nfor model in top_models:\\n    key = model[0]\\n    value = model[1]\\n    models_to_tune[key] = value\\n\\n# Initializing dataframes to compare performance of all models\\nmodels_train_comp_df = pd.DataFrame()\\nmodels_val_comp_df = pd.DataFrame()\\n\\n# For loop to add performance results of each top model\\nfor name, model in models_to_tune.items():\\n    models_train_comp_df[name] = model_performance_regression(model, X_train, y_train).T\\n    models_val_comp_df[name] = model_performance_regression(model, X_val, y_val).T\";\n",
       "                var nbb_formatted_code = \"# Creating empty dictionary to hold the models\\nmodels_to_tune = {}\\n\\n# For loop to add models to dictionary\\nfor model in top_models:\\n    key = model[0]\\n    value = model[1]\\n    models_to_tune[key] = value\\n\\n# Initializing dataframes to compare performance of all models\\nmodels_train_comp_df = pd.DataFrame()\\nmodels_val_comp_df = pd.DataFrame()\\n\\n# For loop to add performance results of each top model\\nfor name, model in models_to_tune.items():\\n    models_train_comp_df[name] = model_performance_regression(model, X_train, y_train).T\\n    models_val_comp_df[name] = model_performance_regression(model, X_val, y_val).T\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Creating empty dictionary to hold the models\n",
    "models_to_tune = {}\n",
    "\n",
    "# For loop to add models to dictionary\n",
    "for model in top_models:\n",
    "    key = model[0]\n",
    "    value = model[1]\n",
    "    models_to_tune[key] = value\n",
    "\n",
    "# Initializing dataframes to compare performance of all models\n",
    "models_train_comp_df = pd.DataFrame()\n",
    "models_val_comp_df = pd.DataFrame()\n",
    "\n",
    "# For loop to add performance results of each top model\n",
    "for name, model in models_to_tune.items():\n",
    "    models_train_comp_df[name] = model_performance_regression(model, X_train, y_train).T\n",
    "    models_val_comp_df[name] = model_performance_regression(model, X_val, y_val).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b06410",
   "metadata": {},
   "source": [
    "#### Comparing Top Models Before Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d7bcfe83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Performance:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>GBM</th>\n",
       "      <th>XGB_gbtree</th>\n",
       "      <th>XGB_gblinear</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>11.686697</td>\n",
       "      <td>14.971421</td>\n",
       "      <td>14.237993</td>\n",
       "      <td>15.175572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>8.736482</td>\n",
       "      <td>11.627512</td>\n",
       "      <td>11.034927</td>\n",
       "      <td>11.784714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-squared</th>\n",
       "      <td>0.456950</td>\n",
       "      <td>0.108786</td>\n",
       "      <td>0.193965</td>\n",
       "      <td>0.084315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Adj. R-squared</th>\n",
       "      <td>0.456610</td>\n",
       "      <td>0.108228</td>\n",
       "      <td>0.193461</td>\n",
       "      <td>0.083741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAPE</th>\n",
       "      <td>13.944396</td>\n",
       "      <td>19.221156</td>\n",
       "      <td>18.032207</td>\n",
       "      <td>19.426149</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Random Forest        GBM  XGB_gbtree  XGB_gblinear\n",
       "RMSE                11.686697  14.971421   14.237993     15.175572\n",
       "MAE                  8.736482  11.627512   11.034927     11.784714\n",
       "R-squared            0.456950   0.108786    0.193965      0.084315\n",
       "Adj. R-squared       0.456610   0.108228    0.193461      0.083741\n",
       "MAPE                13.944396  19.221156   18.032207     19.426149"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 14;\n",
       "                var nbb_unformatted_code = \"# Comparing train performance\\nprint(f\\\"Training Performance:\\\")\\nmodels_train_comp_df\";\n",
       "                var nbb_formatted_code = \"# Comparing train performance\\nprint(f\\\"Training Performance:\\\")\\nmodels_train_comp_df\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Comparing train performance\n",
    "print(f\"Training Performance:\")\n",
    "models_train_comp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a67f0163",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Performance:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>GBM</th>\n",
       "      <th>XGB_gbtree</th>\n",
       "      <th>XGB_gblinear</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>16.271584</td>\n",
       "      <td>14.922006</td>\n",
       "      <td>15.022284</td>\n",
       "      <td>15.057793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>12.558769</td>\n",
       "      <td>11.580272</td>\n",
       "      <td>11.632590</td>\n",
       "      <td>11.696734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-squared</th>\n",
       "      <td>-0.065931</td>\n",
       "      <td>0.103555</td>\n",
       "      <td>0.091466</td>\n",
       "      <td>0.087166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Adj. R-squared</th>\n",
       "      <td>-0.067489</td>\n",
       "      <td>0.102244</td>\n",
       "      <td>0.090137</td>\n",
       "      <td>0.085831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAPE</th>\n",
       "      <td>20.193462</td>\n",
       "      <td>19.051063</td>\n",
       "      <td>19.008358</td>\n",
       "      <td>19.182297</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Random Forest        GBM  XGB_gbtree  XGB_gblinear\n",
       "RMSE                16.271584  14.922006   15.022284     15.057793\n",
       "MAE                 12.558769  11.580272   11.632590     11.696734\n",
       "R-squared           -0.065931   0.103555    0.091466      0.087166\n",
       "Adj. R-squared      -0.067489   0.102244    0.090137      0.085831\n",
       "MAPE                20.193462  19.051063   19.008358     19.182297"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 15;\n",
       "                var nbb_unformatted_code = \"# Comparing validation performance\\nprint(f\\\"Validation Performance:\\\")\\nmodels_val_comp_df\";\n",
       "                var nbb_formatted_code = \"# Comparing validation performance\\nprint(f\\\"Validation Performance:\\\")\\nmodels_val_comp_df\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Comparing validation performance\n",
    "print(f\"Validation Performance:\")\n",
    "models_val_comp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec420b4",
   "metadata": {},
   "source": [
    "#### Observations:\n",
    "- Here, we compare the performance on the whole train set to the validation set.\n",
    "- Only *GBM* and *XGB_gblinear* are giving generalized performances on the two sets.\n",
    "- These two are performing on par or slightly better than [*olsmodel3*](https://github.com/teresahanak/wikipedia-life-expectancy/blob/main/wp_life_expect_olsmodel_thanak_2022_10_9.ipynb), our linear regression model, for all metrics.\n",
    "- We will see if hyperparameter tuning improves their performance, again keeping *Random Forest* and *XGB_gbtree* in the mix for demonstration and comparison."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25b1cfa",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea25fe9",
   "metadata": {},
   "source": [
    "### *Random Forest Tuned*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6e1581b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(random_state=42)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 16;\n",
       "                var nbb_unformatted_code = \"# Confirming the model\\nmodels_to_tune[\\\"Random Forest\\\"]\";\n",
       "                var nbb_formatted_code = \"# Confirming the model\\nmodels_to_tune[\\\"Random Forest\\\"]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Confirming the model\n",
    "models_to_tune[\"Random Forest\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "98b005d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Teres\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "5 fits failed out of a total of 50.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Teres\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Teres\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 450, in fit\n",
      "    trees = Parallel(\n",
      "  File \"C:\\Users\\Teres\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Teres\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Teres\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Teres\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Teres\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Teres\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Teres\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Teres\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 216, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\Teres\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 185, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Teres\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1315, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\Teres\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 241, in fit\n",
      "    if not 0.0 < self.min_samples_leaf <= 0.5:\n",
      "TypeError: '<' not supported between instances of 'float' and 'NoneType'\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\Teres\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.09803003 0.09738486 0.0968302  0.09849117 0.0438569  0.09959073\n",
      " 0.09967033 0.09943607        nan 0.08892088]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters are {'criterion': 'squared_error', 'max_depth': None, 'max_features': 'sqrt', 'max_samples': 0.3909124836035503, 'min_samples_leaf': 4, 'n_estimators': 260} with CV score=0.09967033141183923:\n",
      "CPU times: total: 4.64 s\n",
      "Wall time: 1min 26s\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 17;\n",
       "                var nbb_unformatted_code = \"%%time\\n\\n# Defining model\\nModel = RandomForestRegressor(random_state=42)\\n\\n# Parameter grid to pass in RandomizedSearchCV\\nparam_grid = { \\n    \\\"n_estimators\\\": np.arange(100, 500), \\n    \\\"min_samples_leaf\\\": [None] + np.arange(1, 10).tolist(),\\n    \\\"max_features\\\": ['sqrt'], \\n    \\\"max_samples\\\": uniform(loc=0.3, scale=0.5),\\n    'criterion': ['squared_error'],\\n    \\\"max_depth\\\": [None]\\n}\\n\\n# Calling RandomizedSearchCV\\nrandomized_cv = RandomizedSearchCV(\\n    estimator=Model,\\n    param_distributions=param_grid,\\n    n_iter=10,\\n    n_jobs=-1,\\n    scoring=scorer,\\n    cv=5,\\n    random_state=42,\\n)\\n\\n# Fitting parameters in RandomizedSearchCV\\nrandomized_cv.fit(X_train, y_train)\\n\\nprint(\\n    \\\"Best parameters are {} with CV score={}:\\\".format(\\n        randomized_cv.best_params_, randomized_cv.best_score_\\n    )\\n)\\n\\n# Chime notification when cell successfully executes\\nchime.success()\";\n",
       "                var nbb_formatted_code = \"%%time\\n\\n# Defining model\\nModel = RandomForestRegressor(random_state=42)\\n\\n# Parameter grid to pass in RandomizedSearchCV\\nparam_grid = { \\n    \\\"n_estimators\\\": np.arange(100, 500), \\n    \\\"min_samples_leaf\\\": [None] + np.arange(1, 10).tolist(),\\n    \\\"max_features\\\": ['sqrt'], \\n    \\\"max_samples\\\": uniform(loc=0.3, scale=0.5),\\n    'criterion': ['squared_error'],\\n    \\\"max_depth\\\": [None]\\n}\\n\\n# Calling RandomizedSearchCV\\nrandomized_cv = RandomizedSearchCV(\\n    estimator=Model,\\n    param_distributions=param_grid,\\n    n_iter=10,\\n    n_jobs=-1,\\n    scoring=scorer,\\n    cv=5,\\n    random_state=42,\\n)\\n\\n# Fitting parameters in RandomizedSearchCV\\nrandomized_cv.fit(X_train, y_train)\\n\\nprint(\\n    \\\"Best parameters are {} with CV score={}:\\\".format(\\n        randomized_cv.best_params_, randomized_cv.best_score_\\n    )\\n)\\n\\n# Chime notification when cell successfully executes\\nchime.success()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Defining model\n",
    "Model = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Parameter grid to pass in RandomizedSearchCV\n",
    "param_grid = { \n",
    "    \"n_estimators\": np.arange(100, 500), \n",
    "    \"min_samples_leaf\": [None] + np.arange(1, 10).tolist(),\n",
    "    \"max_features\": ['sqrt'], \n",
    "    \"max_samples\": uniform(loc=0.3, scale=0.5),\n",
    "    'criterion': ['squared_error'],\n",
    "    \"max_depth\": [None]\n",
    "}\n",
    "\n",
    "# Calling RandomizedSearchCV\n",
    "randomized_cv = RandomizedSearchCV(\n",
    "    estimator=Model,\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=10,\n",
    "    n_jobs=-1,\n",
    "    scoring=scorer,\n",
    "    cv=5,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "# Fitting parameters in RandomizedSearchCV\n",
    "randomized_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\n",
    "    \"Best parameters are {} with CV score={}:\".format(\n",
    "        randomized_cv.best_params_, randomized_cv.best_score_\n",
    "    )\n",
    ")\n",
    "\n",
    "# Chime notification when cell successfully executes\n",
    "chime.success()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "70b8ba4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(max_features='sqrt', max_samples=0.3909124836035503,\n",
       "                      min_samples_leaf=4, n_estimators=260)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 18;\n",
       "                var nbb_unformatted_code = \"# Building model with best parameters\\nRandom_Forest_tuned = RandomForestRegressor(\\n    criterion=\\\"squared_error\\\",\\n    max_depth=None,\\n    max_features=\\\"sqrt\\\",\\n    max_samples=0.3909124836035503,\\n    min_samples_leaf=4,\\n    n_estimators=260,\\n)\\n\\n# Fit the model on training data\\nRandom_Forest_tuned.fit(X_train, y_train)\";\n",
       "                var nbb_formatted_code = \"# Building model with best parameters\\nRandom_Forest_tuned = RandomForestRegressor(\\n    criterion=\\\"squared_error\\\",\\n    max_depth=None,\\n    max_features=\\\"sqrt\\\",\\n    max_samples=0.3909124836035503,\\n    min_samples_leaf=4,\\n    n_estimators=260,\\n)\\n\\n# Fit the model on training data\\nRandom_Forest_tuned.fit(X_train, y_train)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Building model with best parameters\n",
    "Random_Forest_tuned = RandomForestRegressor(\n",
    "    criterion=\"squared_error\",\n",
    "    max_depth=None,\n",
    "    max_features=\"sqrt\",\n",
    "    max_samples=0.3909124836035503,\n",
    "    min_samples_leaf=4,\n",
    "    n_estimators=260,\n",
    ")\n",
    "\n",
    "# Fit the model on training data\n",
    "Random_Forest_tuned.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4b02b1d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training performance:\n",
      "         RMSE        MAE  R-squared  Adj. R-squared      MAPE\n",
      "0  14.562659  11.314155   0.156787        0.156259  18.70785\n",
      "\n",
      "Validation performance:\n",
      "         RMSE        MAE  R-squared  Adj. R-squared       MAPE\n",
      "0  14.952845  11.602043   0.099846        0.098529  19.093536\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 19;\n",
       "                var nbb_unformatted_code = \"# Calculating different metrics\\nRandom_Forest_tuned_train_perf = model_performance_regression(\\n    Random_Forest_tuned, X_train, y_train\\n)\\nprint(\\\"Training performance:\\\\n\\\", Random_Forest_tuned_train_perf)\\nRandom_Forest_tuned_val_perf = model_performance_regression(\\n    Random_Forest_tuned, X_val, y_val\\n)\\nprint(\\\"\\\\nValidation performance:\\\\n\\\", Random_Forest_tuned_val_perf)\\n\\n# Adding model to model comparison dataframes\\nmodels_train_comp_df[\\\"Random Forest Tuned\\\"] = Random_Forest_tuned_train_perf.T\\nmodels_val_comp_df[\\\"Random Forest Tuned\\\"] = Random_Forest_tuned_val_perf.T\";\n",
       "                var nbb_formatted_code = \"# Calculating different metrics\\nRandom_Forest_tuned_train_perf = model_performance_regression(\\n    Random_Forest_tuned, X_train, y_train\\n)\\nprint(\\\"Training performance:\\\\n\\\", Random_Forest_tuned_train_perf)\\nRandom_Forest_tuned_val_perf = model_performance_regression(\\n    Random_Forest_tuned, X_val, y_val\\n)\\nprint(\\\"\\\\nValidation performance:\\\\n\\\", Random_Forest_tuned_val_perf)\\n\\n# Adding model to model comparison dataframes\\nmodels_train_comp_df[\\\"Random Forest Tuned\\\"] = Random_Forest_tuned_train_perf.T\\nmodels_val_comp_df[\\\"Random Forest Tuned\\\"] = Random_Forest_tuned_val_perf.T\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculating different metrics\n",
    "Random_Forest_tuned_train_perf = model_performance_regression(\n",
    "    Random_Forest_tuned, X_train, y_train\n",
    ")\n",
    "print(\"Training performance:\\n\", Random_Forest_tuned_train_perf)\n",
    "Random_Forest_tuned_val_perf = model_performance_regression(\n",
    "    Random_Forest_tuned, X_val, y_val\n",
    ")\n",
    "print(\"\\nValidation performance:\\n\", Random_Forest_tuned_val_perf)\n",
    "\n",
    "# Adding model to model comparison dataframes\n",
    "models_train_comp_df[\"Random Forest Tuned\"] = Random_Forest_tuned_train_perf.T\n",
    "models_val_comp_df[\"Random Forest Tuned\"] = Random_Forest_tuned_val_perf.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b37c92f",
   "metadata": {},
   "source": [
    "#### Observations:\n",
    "- Hyperparameter tuning improved performance for *Random Forest*.\n",
    "- The algorithm is still overfitting the train set, compared to the validation set.\n",
    "- Note that we had a 10% fit fail during cross-validation (\"UserWarning: One or more of the test scores are non-finite..\") indicating cross-validation had some folds for which hyperparameter combinations led to Nan values.  We are going to allow it here, and go with the results of the successful iterations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208028f9",
   "metadata": {},
   "source": [
    "### *GBM Tuned*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "59c48bf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(random_state=42)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 20;\n",
       "                var nbb_unformatted_code = \"# Confirming the model\\nmodels_to_tune[\\\"GBM\\\"]\";\n",
       "                var nbb_formatted_code = \"# Confirming the model\\nmodels_to_tune[\\\"GBM\\\"]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Confirming the model\n",
    "models_to_tune[\"GBM\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "47553f87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters are {'learning_rate': 0.08171272700715591, 'max_features': 0.6630456668613307, 'n_estimators': 368, 'subsample': 0.7847684335570795} with CV score=0.1063224214498147:\n",
      "CPU times: total: 15.4 s\n",
      "Wall time: 8min 9s\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 21;\n",
       "                var nbb_unformatted_code = \"%%time\\n\\n# Defining model\\nModel = GradientBoostingRegressor(random_state=42)\\n\\n# Parameter grid to pass in RandomizedSearchCV\\nparam_grid = {\\n    \\\"n_estimators\\\": np.arange(100, 500),\\n    \\\"learning_rate\\\": loguniform(0.001, 1),\\n    \\\"subsample\\\": uniform(loc=0.3, scale=0.5),\\n    \\\"max_features\\\": uniform(loc=0.3, scale=0.5),\\n}\\n\\n# Calling RandomizedSearchCV\\nrandomized_cv = RandomizedSearchCV(\\n    estimator=Model,\\n    param_distributions=param_grid,\\n    n_iter=100,\\n    n_jobs=-1,\\n    scoring=scorer,\\n    cv=5,\\n    random_state=42,\\n)\\n\\n# Fitting parameters in RandomizedSearchCV\\nrandomized_cv.fit(X_train, y_train)\\n\\nprint(\\n    \\\"Best parameters are {} with CV score={}:\\\".format(\\n        randomized_cv.best_params_, randomized_cv.best_score_\\n    )\\n)\\n\\n# Chime notification when cell successfully executes\\nchime.success()\";\n",
       "                var nbb_formatted_code = \"%%time\\n\\n# Defining model\\nModel = GradientBoostingRegressor(random_state=42)\\n\\n# Parameter grid to pass in RandomizedSearchCV\\nparam_grid = {\\n    \\\"n_estimators\\\": np.arange(100, 500),\\n    \\\"learning_rate\\\": loguniform(0.001, 1),\\n    \\\"subsample\\\": uniform(loc=0.3, scale=0.5),\\n    \\\"max_features\\\": uniform(loc=0.3, scale=0.5),\\n}\\n\\n# Calling RandomizedSearchCV\\nrandomized_cv = RandomizedSearchCV(\\n    estimator=Model,\\n    param_distributions=param_grid,\\n    n_iter=100,\\n    n_jobs=-1,\\n    scoring=scorer,\\n    cv=5,\\n    random_state=42,\\n)\\n\\n# Fitting parameters in RandomizedSearchCV\\nrandomized_cv.fit(X_train, y_train)\\n\\nprint(\\n    \\\"Best parameters are {} with CV score={}:\\\".format(\\n        randomized_cv.best_params_, randomized_cv.best_score_\\n    )\\n)\\n\\n# Chime notification when cell successfully executes\\nchime.success()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Defining model\n",
    "Model = GradientBoostingRegressor(random_state=42)\n",
    "\n",
    "# Parameter grid to pass in RandomizedSearchCV\n",
    "param_grid = {\n",
    "    \"n_estimators\": np.arange(100, 500),\n",
    "    \"learning_rate\": loguniform(0.001, 1),\n",
    "    \"subsample\": uniform(loc=0.3, scale=0.5),\n",
    "    \"max_features\": uniform(loc=0.3, scale=0.5),\n",
    "}\n",
    "\n",
    "# Calling RandomizedSearchCV\n",
    "randomized_cv = RandomizedSearchCV(\n",
    "    estimator=Model,\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=100,\n",
    "    n_jobs=-1,\n",
    "    scoring=scorer,\n",
    "    cv=5,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "# Fitting parameters in RandomizedSearchCV\n",
    "randomized_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\n",
    "    \"Best parameters are {} with CV score={}:\".format(\n",
    "        randomized_cv.best_params_, randomized_cv.best_score_\n",
    "    )\n",
    ")\n",
    "\n",
    "# Chime notification when cell successfully executes\n",
    "chime.success()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6916dcf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(learning_rate=0.08171272700715591,\n",
       "                          max_features=0.6630456668613307, n_estimators=368,\n",
       "                          random_state=42, subsample=0.7847684335570795)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 22;\n",
       "                var nbb_unformatted_code = \"# Building model with best parameters\\nGBM_tuned = GradientBoostingRegressor(\\n    random_state=42,\\n    learning_rate=0.08171272700715591,\\n    max_features=0.6630456668613307,\\n    n_estimators=368,\\n    subsample=0.7847684335570795,\\n)\\n\\n# Fit the model on training data\\nGBM_tuned.fit(X_train, y_train)\";\n",
       "                var nbb_formatted_code = \"# Building model with best parameters\\nGBM_tuned = GradientBoostingRegressor(\\n    random_state=42,\\n    learning_rate=0.08171272700715591,\\n    max_features=0.6630456668613307,\\n    n_estimators=368,\\n    subsample=0.7847684335570795,\\n)\\n\\n# Fit the model on training data\\nGBM_tuned.fit(X_train, y_train)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Building model with best parameters\n",
    "GBM_tuned = GradientBoostingRegressor(\n",
    "    random_state=42,\n",
    "    learning_rate=0.08171272700715591,\n",
    "    max_features=0.6630456668613307,\n",
    "    n_estimators=368,\n",
    "    subsample=0.7847684335570795,\n",
    ")\n",
    "\n",
    "# Fit the model on training data\n",
    "GBM_tuned.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d47c87fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training performance:\n",
      "         RMSE        MAE  R-squared  Adj. R-squared       MAPE\n",
      "0  14.835035  11.521845   0.124949        0.124401  18.989296\n",
      "\n",
      "Validation performance:\n",
      "         RMSE        MAE  R-squared  Adj. R-squared       MAPE\n",
      "0  14.877704  11.542386    0.10887        0.107567  18.937928\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 23;\n",
       "                var nbb_unformatted_code = \"# Calculating different metrics\\nGBM_tuned_train_perf = model_performance_regression(GBM_tuned, X_train, y_train)\\nprint(\\\"Training performance:\\\\n\\\", GBM_tuned_train_perf)\\nGBM_tuned_val_perf = model_performance_regression(GBM_tuned, X_val, y_val)\\nprint(\\\"\\\\nValidation performance:\\\\n\\\", GBM_tuned_val_perf)\\n\\n# Adding model to model comparison dataframes\\nmodels_train_comp_df[\\\"GBM Tuned\\\"] = GBM_tuned_train_perf.T\\nmodels_val_comp_df[\\\"GBM Tuned\\\"] = GBM_tuned_val_perf.T\";\n",
       "                var nbb_formatted_code = \"# Calculating different metrics\\nGBM_tuned_train_perf = model_performance_regression(GBM_tuned, X_train, y_train)\\nprint(\\\"Training performance:\\\\n\\\", GBM_tuned_train_perf)\\nGBM_tuned_val_perf = model_performance_regression(GBM_tuned, X_val, y_val)\\nprint(\\\"\\\\nValidation performance:\\\\n\\\", GBM_tuned_val_perf)\\n\\n# Adding model to model comparison dataframes\\nmodels_train_comp_df[\\\"GBM Tuned\\\"] = GBM_tuned_train_perf.T\\nmodels_val_comp_df[\\\"GBM Tuned\\\"] = GBM_tuned_val_perf.T\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculating different metrics\n",
    "GBM_tuned_train_perf = model_performance_regression(GBM_tuned, X_train, y_train)\n",
    "print(\"Training performance:\\n\", GBM_tuned_train_perf)\n",
    "GBM_tuned_val_perf = model_performance_regression(GBM_tuned, X_val, y_val)\n",
    "print(\"\\nValidation performance:\\n\", GBM_tuned_val_perf)\n",
    "\n",
    "# Adding model to model comparison dataframes\n",
    "models_train_comp_df[\"GBM Tuned\"] = GBM_tuned_train_perf.T\n",
    "models_val_comp_df[\"GBM Tuned\"] = GBM_tuned_val_perf.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e76f44e0",
   "metadata": {},
   "source": [
    "#### Observations:\n",
    "- The performance for *GBM* is improved with hyperparameter tuning.  \n",
    "- There is a slight increase in overfitting, but the validation metrics are better."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d345d350",
   "metadata": {},
   "source": [
    "### *XGB_gbtree Tuned*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8a847975",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', callbacks=None,\n",
       "             colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "             early_stopping_rounds=None, enable_categorical=False,\n",
       "             eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n",
       "             importance_type=None, interaction_constraints='',\n",
       "             learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n",
       "             max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,\n",
       "             missing=nan, monotone_constraints='()', n_estimators=100, n_jobs=0,\n",
       "             num_parallel_tree=1, predictor='auto', random_state=42,\n",
       "             reg_alpha=0, reg_lambda=1, ...)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 24;\n",
       "                var nbb_unformatted_code = \"# Confirming the model\\nmodels_to_tune[\\\"XGB_gbtree\\\"]\";\n",
       "                var nbb_formatted_code = \"# Confirming the model\\nmodels_to_tune[\\\"XGB_gbtree\\\"]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Confirming the model\n",
    "models_to_tune[\"XGB_gbtree\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "06dbfd3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters are {'colsample_bytree': 0.42649508399462055, 'gamma': 1.188792356281234, 'learning_rate': 0.12263036412693079, 'max_depth': 3, 'n_estimators': 404, 'subsample': 0.7391497377969234} with CV score=0.10679644601394585:\n",
      "CPU times: total: 1min\n",
      "Wall time: 21min 57s\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 25;\n",
       "                var nbb_unformatted_code = \"%%time\\n\\n# Defining model\\nModel = XGBRegressor(random_state=42, booster='gbtree')\\n\\n# Parameter grid to pass in RandomizedSearchCV\\nparam_grid={\\n    'n_estimators': np.arange(100, 500),\\n    \\\"learning_rate\\\": uniform(0.1, 0.3), # aka eta\\n    'gamma': expon(), # aka min_split_loss\\n    'subsample': uniform(loc=0.6, scale=0.2), # proportion of train set to randomly sample prior to growing trees\\n    'max_depth': np.arange(3, 8).tolist(),\\n    'colsample_bytree': uniform(loc=0.3, scale=0.5)\\n}\\n\\n# Calling RandomizedSearchCV\\nrandomized_cv = RandomizedSearchCV(\\n    estimator=Model,\\n    param_distributions=param_grid,\\n    n_iter=100,\\n    n_jobs=-1,\\n    scoring=scorer,\\n    cv=5,\\n    random_state=42,\\n)\\n\\n# Fitting parameters in RandomizedSearchCV\\nrandomized_cv.fit(X_train, y_train)\\n\\nprint(\\n    \\\"Best parameters are {} with CV score={}:\\\".format(\\n        randomized_cv.best_params_, randomized_cv.best_score_\\n    )\\n)\\n\\n# Chime notification when cell successfully executes\\nchime.success()\";\n",
       "                var nbb_formatted_code = \"%%time\\n\\n# Defining model\\nModel = XGBRegressor(random_state=42, booster='gbtree')\\n\\n# Parameter grid to pass in RandomizedSearchCV\\nparam_grid={\\n    'n_estimators': np.arange(100, 500),\\n    \\\"learning_rate\\\": uniform(0.1, 0.3), # aka eta\\n    'gamma': expon(), # aka min_split_loss\\n    'subsample': uniform(loc=0.6, scale=0.2), # proportion of train set to randomly sample prior to growing trees\\n    'max_depth': np.arange(3, 8).tolist(),\\n    'colsample_bytree': uniform(loc=0.3, scale=0.5)\\n}\\n\\n# Calling RandomizedSearchCV\\nrandomized_cv = RandomizedSearchCV(\\n    estimator=Model,\\n    param_distributions=param_grid,\\n    n_iter=100,\\n    n_jobs=-1,\\n    scoring=scorer,\\n    cv=5,\\n    random_state=42,\\n)\\n\\n# Fitting parameters in RandomizedSearchCV\\nrandomized_cv.fit(X_train, y_train)\\n\\nprint(\\n    \\\"Best parameters are {} with CV score={}:\\\".format(\\n        randomized_cv.best_params_, randomized_cv.best_score_\\n    )\\n)\\n\\n# Chime notification when cell successfully executes\\nchime.success()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Defining model\n",
    "Model = XGBRegressor(random_state=42, booster='gbtree')\n",
    "\n",
    "# Parameter grid to pass in RandomizedSearchCV\n",
    "param_grid={\n",
    "    'n_estimators': np.arange(100, 500),\n",
    "    \"learning_rate\": uniform(0.1, 0.3), # aka eta\n",
    "    'gamma': expon(), # aka min_split_loss\n",
    "    'subsample': uniform(loc=0.6, scale=0.2), # proportion of train set to randomly sample prior to growing trees\n",
    "    'max_depth': np.arange(3, 8).tolist(),\n",
    "    'colsample_bytree': uniform(loc=0.3, scale=0.5)\n",
    "}\n",
    "\n",
    "# Calling RandomizedSearchCV\n",
    "randomized_cv = RandomizedSearchCV(\n",
    "    estimator=Model,\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=100,\n",
    "    n_jobs=-1,\n",
    "    scoring=scorer,\n",
    "    cv=5,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "# Fitting parameters in RandomizedSearchCV\n",
    "randomized_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\n",
    "    \"Best parameters are {} with CV score={}:\".format(\n",
    "        randomized_cv.best_params_, randomized_cv.best_score_\n",
    "    )\n",
    ")\n",
    "\n",
    "# Chime notification when cell successfully executes\n",
    "chime.success()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9472522b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', callbacks=None,\n",
       "             colsample_bylevel=1, colsample_bynode=1,\n",
       "             colsample_bytree=0.42649508399462055, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None,\n",
       "             gamma=1.188792356281234, gpu_id=-1, grow_policy='depthwise',\n",
       "             importance_type=None, interaction_constraints='',\n",
       "             learning_rate=0.12263036412693079, max_bin=256,\n",
       "             max_cat_to_onehot=4, max_delta_step=0, max_depth=3, max_leaves=0,\n",
       "             min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "             n_estimators=404, n_jobs=0, num_parallel_tree=1, predictor='auto',\n",
       "             random_state=42, reg_alpha=0, reg_lambda=1, ...)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 26;\n",
       "                var nbb_unformatted_code = \"# Building model with best parameters\\nXGB_gbtree_tuned = XGBRegressor(\\n    booster=\\\"gbtree\\\",\\n    random_state=42,\\n    colsample_bytree=0.42649508399462055,\\n    gamma=1.188792356281234,\\n    learning_rate=0.12263036412693079,\\n    max_depth=3,\\n    n_estimators=404,\\n    subsample=0.7391497377969234,\\n)\\n\\n# Fit the model on training data\\nXGB_gbtree_tuned.fit(X_train, y_train)\";\n",
       "                var nbb_formatted_code = \"# Building model with best parameters\\nXGB_gbtree_tuned = XGBRegressor(\\n    booster=\\\"gbtree\\\",\\n    random_state=42,\\n    colsample_bytree=0.42649508399462055,\\n    gamma=1.188792356281234,\\n    learning_rate=0.12263036412693079,\\n    max_depth=3,\\n    n_estimators=404,\\n    subsample=0.7391497377969234,\\n)\\n\\n# Fit the model on training data\\nXGB_gbtree_tuned.fit(X_train, y_train)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Building model with best parameters\n",
    "XGB_gbtree_tuned = XGBRegressor(\n",
    "    booster=\"gbtree\",\n",
    "    random_state=42,\n",
    "    colsample_bytree=0.42649508399462055,\n",
    "    gamma=1.188792356281234,\n",
    "    learning_rate=0.12263036412693079,\n",
    "    max_depth=3,\n",
    "    n_estimators=404,\n",
    "    subsample=0.7391497377969234,\n",
    ")\n",
    "\n",
    "# Fit the model on training data\n",
    "XGB_gbtree_tuned.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a6101083",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training performance:\n",
      "         RMSE       MAE  R-squared  Adj. R-squared       MAPE\n",
      "0  14.813429  11.50438   0.127496         0.12695  18.953973\n",
      "\n",
      "Validation performance:\n",
      "         RMSE        MAE  R-squared  Adj. R-squared       MAPE\n",
      "0  14.882834  11.546377   0.108255        0.106951  18.931955\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 27;\n",
       "                var nbb_unformatted_code = \"# Calculating different metrics\\nXGB_gbtree_tuned_train_perf = model_performance_regression(\\n    XGB_gbtree_tuned, X_train, y_train\\n)\\nprint(\\\"Training performance:\\\\n\\\", XGB_gbtree_tuned_train_perf)\\nXGB_gbtree_tuned_val_perf = model_performance_regression(XGB_gbtree_tuned, X_val, y_val)\\nprint(\\\"\\\\nValidation performance:\\\\n\\\", XGB_gbtree_tuned_val_perf)\\n\\n# Adding model to model comparison dataframes\\nmodels_train_comp_df[\\\"XGB_gbtree Tuned\\\"] = XGB_gbtree_tuned_train_perf.T\\nmodels_val_comp_df[\\\"XGB_gbtree Tuned\\\"] = XGB_gbtree_tuned_val_perf.T\";\n",
       "                var nbb_formatted_code = \"# Calculating different metrics\\nXGB_gbtree_tuned_train_perf = model_performance_regression(\\n    XGB_gbtree_tuned, X_train, y_train\\n)\\nprint(\\\"Training performance:\\\\n\\\", XGB_gbtree_tuned_train_perf)\\nXGB_gbtree_tuned_val_perf = model_performance_regression(XGB_gbtree_tuned, X_val, y_val)\\nprint(\\\"\\\\nValidation performance:\\\\n\\\", XGB_gbtree_tuned_val_perf)\\n\\n# Adding model to model comparison dataframes\\nmodels_train_comp_df[\\\"XGB_gbtree Tuned\\\"] = XGB_gbtree_tuned_train_perf.T\\nmodels_val_comp_df[\\\"XGB_gbtree Tuned\\\"] = XGB_gbtree_tuned_val_perf.T\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculating different metrics\n",
    "XGB_gbtree_tuned_train_perf = model_performance_regression(\n",
    "    XGB_gbtree_tuned, X_train, y_train\n",
    ")\n",
    "print(\"Training performance:\\n\", XGB_gbtree_tuned_train_perf)\n",
    "XGB_gbtree_tuned_val_perf = model_performance_regression(XGB_gbtree_tuned, X_val, y_val)\n",
    "print(\"\\nValidation performance:\\n\", XGB_gbtree_tuned_val_perf)\n",
    "\n",
    "# Adding model to model comparison dataframes\n",
    "models_train_comp_df[\"XGB_gbtree Tuned\"] = XGB_gbtree_tuned_train_perf.T\n",
    "models_val_comp_df[\"XGB_gbtree Tuned\"] = XGB_gbtree_tuned_val_perf.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "589bde06",
   "metadata": {},
   "source": [
    "#### Observations:\n",
    "- The performance for *XGB_gbtree* is improved with hyperparameter tuning.  \n",
    "- There is a slight increase in overfitting, but the validation metrics are better."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc9bc9d",
   "metadata": {},
   "source": [
    "### *XGB_gblinear Tuned*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5bded9fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gblinear', callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, gamma=None, gpu_id=-1,\n",
       "             grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.5, max_bin=None,\n",
       "             max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "             max_leaves=None, min_child_weight=None, missing=nan,\n",
       "             monotone_constraints=None, n_estimators=100, n_jobs=0,\n",
       "             num_parallel_tree=None, predictor=None, random_state=42,\n",
       "             reg_alpha=0, reg_lambda=0, ...)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 28;\n",
       "                var nbb_unformatted_code = \"# Confirming the model\\nmodels_to_tune[\\\"XGB_gblinear\\\"]\";\n",
       "                var nbb_formatted_code = \"# Confirming the model\\nmodels_to_tune[\\\"XGB_gblinear\\\"]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Confirming the model\n",
    "models_to_tune[\"XGB_gblinear\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b6f73eb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters are {'n_estimators': 439, 'reg_lambda': 0.0009206654892274761} with CV score=0.09196572057161607:\n",
      "CPU times: total: 1min\n",
      "Wall time: 6min 3s\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 29;\n",
       "                var nbb_unformatted_code = \"%%time\\n\\n# Defining model\\nModel = XGBRegressor(random_state=42, booster='gblinear')\\n\\n# Parameter grid to pass in RandomizedSearchCV\\nparam_grid={\\n    'n_estimators': np.arange(100, 500),\\n    'reg_lambda': loguniform(.0001, 1)\\n}\\n\\n# Calling RandomizedSearchCV\\nrandomized_cv = RandomizedSearchCV(\\n    estimator=Model,\\n    param_distributions=param_grid,\\n    n_iter=100,\\n    n_jobs=-1,\\n    scoring=scorer,\\n    cv=5,\\n    random_state=42,\\n)\\n\\n# Fitting parameters in RandomizedSearchCV\\nrandomized_cv.fit(X_train, y_train)\\n\\nprint(\\n    \\\"Best parameters are {} with CV score={}:\\\".format(\\n        randomized_cv.best_params_, randomized_cv.best_score_\\n    )\\n)\\n\\n# Chime notification when cell successfully executes\\nchime.success()\";\n",
       "                var nbb_formatted_code = \"%%time\\n\\n# Defining model\\nModel = XGBRegressor(random_state=42, booster='gblinear')\\n\\n# Parameter grid to pass in RandomizedSearchCV\\nparam_grid={\\n    'n_estimators': np.arange(100, 500),\\n    'reg_lambda': loguniform(.0001, 1)\\n}\\n\\n# Calling RandomizedSearchCV\\nrandomized_cv = RandomizedSearchCV(\\n    estimator=Model,\\n    param_distributions=param_grid,\\n    n_iter=100,\\n    n_jobs=-1,\\n    scoring=scorer,\\n    cv=5,\\n    random_state=42,\\n)\\n\\n# Fitting parameters in RandomizedSearchCV\\nrandomized_cv.fit(X_train, y_train)\\n\\nprint(\\n    \\\"Best parameters are {} with CV score={}:\\\".format(\\n        randomized_cv.best_params_, randomized_cv.best_score_\\n    )\\n)\\n\\n# Chime notification when cell successfully executes\\nchime.success()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Defining model\n",
    "Model = XGBRegressor(random_state=42, booster='gblinear')\n",
    "\n",
    "# Parameter grid to pass in RandomizedSearchCV\n",
    "param_grid={\n",
    "    'n_estimators': np.arange(100, 500),\n",
    "    'reg_lambda': loguniform(.0001, 1)\n",
    "}\n",
    "\n",
    "# Calling RandomizedSearchCV\n",
    "randomized_cv = RandomizedSearchCV(\n",
    "    estimator=Model,\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=100,\n",
    "    n_jobs=-1,\n",
    "    scoring=scorer,\n",
    "    cv=5,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "# Fitting parameters in RandomizedSearchCV\n",
    "randomized_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\n",
    "    \"Best parameters are {} with CV score={}:\".format(\n",
    "        randomized_cv.best_params_, randomized_cv.best_score_\n",
    "    )\n",
    ")\n",
    "\n",
    "# Chime notification when cell successfully executes\n",
    "chime.success()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c5f6c963",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gblinear', callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, gamma=None, gpu_id=-1,\n",
       "             grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.5, max_bin=None,\n",
       "             max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "             max_leaves=None, min_child_weight=None, missing=nan,\n",
       "             monotone_constraints=None, n_estimators=439, n_jobs=0,\n",
       "             num_parallel_tree=None, predictor=None, random_state=42,\n",
       "             reg_alpha=0, reg_lambda=0.0009206654892274761, ...)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 30;\n",
       "                var nbb_unformatted_code = \"# Building model with best parameters\\nXGB_gblinear_tuned = XGBRegressor(\\n    booster=\\\"gblinear\\\",\\n    random_state=42,\\n    n_estimators=439,\\n    reg_lambda=0.0009206654892274761,\\n)\\n\\n# Fit the model on training data\\nXGB_gblinear_tuned.fit(X_train, y_train)\";\n",
       "                var nbb_formatted_code = \"# Building model with best parameters\\nXGB_gblinear_tuned = XGBRegressor(\\n    booster=\\\"gblinear\\\",\\n    random_state=42,\\n    n_estimators=439,\\n    reg_lambda=0.0009206654892274761,\\n)\\n\\n# Fit the model on training data\\nXGB_gblinear_tuned.fit(X_train, y_train)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Building model with best parameters\n",
    "XGB_gblinear_tuned = XGBRegressor(\n",
    "    booster=\"gblinear\",\n",
    "    random_state=42,\n",
    "    n_estimators=439,\n",
    "    reg_lambda=0.0009206654892274761,\n",
    ")\n",
    "\n",
    "# Fit the model on training data\n",
    "XGB_gblinear_tuned.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c03abdd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training performance:\n",
      "         RMSE        MAE  R-squared  Adj. R-squared       MAPE\n",
      "0  15.103509  11.729318    0.09299        0.092423  19.393524\n",
      "\n",
      "Validation performance:\n",
      "         RMSE        MAE  R-squared  Adj. R-squared       MAPE\n",
      "0  14.995503  11.640214   0.094702        0.093378  19.152201\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 31;\n",
       "                var nbb_unformatted_code = \"# Calculating different metrics\\nXGB_gblinear_tuned_train_perf = model_performance_regression(\\n    XGB_gblinear_tuned, X_train, y_train\\n)\\nprint(\\\"Training performance:\\\\n\\\", XGB_gblinear_tuned_train_perf)\\nXGB_gblinear_tuned_val_perf = model_performance_regression(\\n    XGB_gblinear_tuned, X_val, y_val\\n)\\nprint(\\\"\\\\nValidation performance:\\\\n\\\", XGB_gblinear_tuned_val_perf)\\n\\n# Adding model to model comparison dataframes\\nmodels_train_comp_df[\\\"XGB_gblinear Tuned\\\"] = XGB_gblinear_tuned_train_perf.T\\nmodels_val_comp_df[\\\"XGB_gblinear Tuned\\\"] = XGB_gblinear_tuned_val_perf.T\";\n",
       "                var nbb_formatted_code = \"# Calculating different metrics\\nXGB_gblinear_tuned_train_perf = model_performance_regression(\\n    XGB_gblinear_tuned, X_train, y_train\\n)\\nprint(\\\"Training performance:\\\\n\\\", XGB_gblinear_tuned_train_perf)\\nXGB_gblinear_tuned_val_perf = model_performance_regression(\\n    XGB_gblinear_tuned, X_val, y_val\\n)\\nprint(\\\"\\\\nValidation performance:\\\\n\\\", XGB_gblinear_tuned_val_perf)\\n\\n# Adding model to model comparison dataframes\\nmodels_train_comp_df[\\\"XGB_gblinear Tuned\\\"] = XGB_gblinear_tuned_train_perf.T\\nmodels_val_comp_df[\\\"XGB_gblinear Tuned\\\"] = XGB_gblinear_tuned_val_perf.T\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculating different metrics\n",
    "XGB_gblinear_tuned_train_perf = model_performance_regression(\n",
    "    XGB_gblinear_tuned, X_train, y_train\n",
    ")\n",
    "print(\"Training performance:\\n\", XGB_gblinear_tuned_train_perf)\n",
    "XGB_gblinear_tuned_val_perf = model_performance_regression(\n",
    "    XGB_gblinear_tuned, X_val, y_val\n",
    ")\n",
    "print(\"\\nValidation performance:\\n\", XGB_gblinear_tuned_val_perf)\n",
    "\n",
    "# Adding model to model comparison dataframes\n",
    "models_train_comp_df[\"XGB_gblinear Tuned\"] = XGB_gblinear_tuned_train_perf.T\n",
    "models_val_comp_df[\"XGB_gblinear Tuned\"] = XGB_gblinear_tuned_val_perf.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "627e4098",
   "metadata": {},
   "source": [
    "#### Observations:\n",
    "- *XGB_gblinear* also has improved performance with hyperparameter tuning.\n",
    "- Let us compare the models, before and after hyperparameter tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27ff942",
   "metadata": {},
   "source": [
    "## Model Performance Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1dcb341",
   "metadata": {},
   "source": [
    "### Performance of Various Models Tuned and Untuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "eafdbe24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Performance Comparison:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GBM</th>\n",
       "      <th>GBM Tuned</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>Random Forest Tuned</th>\n",
       "      <th>XGB_gblinear</th>\n",
       "      <th>XGB_gblinear Tuned</th>\n",
       "      <th>XGB_gbtree</th>\n",
       "      <th>XGB_gbtree Tuned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>14.971421</td>\n",
       "      <td>14.835035</td>\n",
       "      <td>11.686697</td>\n",
       "      <td>14.562659</td>\n",
       "      <td>15.175572</td>\n",
       "      <td>15.103509</td>\n",
       "      <td>14.237993</td>\n",
       "      <td>14.813429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>11.627512</td>\n",
       "      <td>11.521845</td>\n",
       "      <td>8.736482</td>\n",
       "      <td>11.314155</td>\n",
       "      <td>11.784714</td>\n",
       "      <td>11.729318</td>\n",
       "      <td>11.034927</td>\n",
       "      <td>11.504380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-squared</th>\n",
       "      <td>0.108786</td>\n",
       "      <td>0.124949</td>\n",
       "      <td>0.456950</td>\n",
       "      <td>0.156787</td>\n",
       "      <td>0.084315</td>\n",
       "      <td>0.092990</td>\n",
       "      <td>0.193965</td>\n",
       "      <td>0.127496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Adj. R-squared</th>\n",
       "      <td>0.108228</td>\n",
       "      <td>0.124401</td>\n",
       "      <td>0.456610</td>\n",
       "      <td>0.156259</td>\n",
       "      <td>0.083741</td>\n",
       "      <td>0.092423</td>\n",
       "      <td>0.193461</td>\n",
       "      <td>0.126950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAPE</th>\n",
       "      <td>19.221156</td>\n",
       "      <td>18.989296</td>\n",
       "      <td>13.944396</td>\n",
       "      <td>18.707850</td>\n",
       "      <td>19.426149</td>\n",
       "      <td>19.393524</td>\n",
       "      <td>18.032207</td>\n",
       "      <td>18.953973</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      GBM  GBM Tuned  Random Forest  Random Forest Tuned  \\\n",
       "RMSE            14.971421  14.835035      11.686697            14.562659   \n",
       "MAE             11.627512  11.521845       8.736482            11.314155   \n",
       "R-squared        0.108786   0.124949       0.456950             0.156787   \n",
       "Adj. R-squared   0.108228   0.124401       0.456610             0.156259   \n",
       "MAPE            19.221156  18.989296      13.944396            18.707850   \n",
       "\n",
       "                XGB_gblinear  XGB_gblinear Tuned  XGB_gbtree  XGB_gbtree Tuned  \n",
       "RMSE               15.175572           15.103509   14.237993         14.813429  \n",
       "MAE                11.784714           11.729318   11.034927         11.504380  \n",
       "R-squared           0.084315            0.092990    0.193965          0.127496  \n",
       "Adj. R-squared      0.083741            0.092423    0.193461          0.126950  \n",
       "MAPE               19.426149           19.393524   18.032207         18.953973  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 32;\n",
       "                var nbb_unformatted_code = \"# Displaying train performance of all models\\nprint(\\\"Train Performance Comparison:\\\")\\nmodels_train_comp_df.sort_index(axis=1)\";\n",
       "                var nbb_formatted_code = \"# Displaying train performance of all models\\nprint(\\\"Train Performance Comparison:\\\")\\nmodels_train_comp_df.sort_index(axis=1)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Displaying train performance of all models\n",
    "print(\"Train Performance Comparison:\")\n",
    "models_train_comp_df.sort_index(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ed958b1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Performance Comparison:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GBM</th>\n",
       "      <th>GBM Tuned</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>Random Forest Tuned</th>\n",
       "      <th>XGB_gblinear</th>\n",
       "      <th>XGB_gblinear Tuned</th>\n",
       "      <th>XGB_gbtree</th>\n",
       "      <th>XGB_gbtree Tuned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>14.922006</td>\n",
       "      <td>14.877704</td>\n",
       "      <td>16.271584</td>\n",
       "      <td>14.952845</td>\n",
       "      <td>15.057793</td>\n",
       "      <td>14.995503</td>\n",
       "      <td>15.022284</td>\n",
       "      <td>14.882834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>11.580272</td>\n",
       "      <td>11.542386</td>\n",
       "      <td>12.558769</td>\n",
       "      <td>11.602043</td>\n",
       "      <td>11.696734</td>\n",
       "      <td>11.640214</td>\n",
       "      <td>11.632590</td>\n",
       "      <td>11.546377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-squared</th>\n",
       "      <td>0.103555</td>\n",
       "      <td>0.108870</td>\n",
       "      <td>-0.065931</td>\n",
       "      <td>0.099846</td>\n",
       "      <td>0.087166</td>\n",
       "      <td>0.094702</td>\n",
       "      <td>0.091466</td>\n",
       "      <td>0.108255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Adj. R-squared</th>\n",
       "      <td>0.102244</td>\n",
       "      <td>0.107567</td>\n",
       "      <td>-0.067489</td>\n",
       "      <td>0.098529</td>\n",
       "      <td>0.085831</td>\n",
       "      <td>0.093378</td>\n",
       "      <td>0.090137</td>\n",
       "      <td>0.106951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAPE</th>\n",
       "      <td>19.051063</td>\n",
       "      <td>18.937928</td>\n",
       "      <td>20.193462</td>\n",
       "      <td>19.093536</td>\n",
       "      <td>19.182297</td>\n",
       "      <td>19.152201</td>\n",
       "      <td>19.008358</td>\n",
       "      <td>18.931955</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      GBM  GBM Tuned  Random Forest  Random Forest Tuned  \\\n",
       "RMSE            14.922006  14.877704      16.271584            14.952845   \n",
       "MAE             11.580272  11.542386      12.558769            11.602043   \n",
       "R-squared        0.103555   0.108870      -0.065931             0.099846   \n",
       "Adj. R-squared   0.102244   0.107567      -0.067489             0.098529   \n",
       "MAPE            19.051063  18.937928      20.193462            19.093536   \n",
       "\n",
       "                XGB_gblinear  XGB_gblinear Tuned  XGB_gbtree  XGB_gbtree Tuned  \n",
       "RMSE               15.057793           14.995503   15.022284         14.882834  \n",
       "MAE                11.696734           11.640214   11.632590         11.546377  \n",
       "R-squared           0.087166            0.094702    0.091466          0.108255  \n",
       "Adj. R-squared      0.085831            0.093378    0.090137          0.106951  \n",
       "MAPE               19.182297           19.152201   19.008358         18.931955  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 33;\n",
       "                var nbb_unformatted_code = \"# Displaying validation performance of all models\\nprint(\\\"Validation Performance Comparison:\\\")\\nmodels_val_comp_df.sort_index(axis=1)\";\n",
       "                var nbb_formatted_code = \"# Displaying validation performance of all models\\nprint(\\\"Validation Performance Comparison:\\\")\\nmodels_val_comp_df.sort_index(axis=1)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Displaying validation performance of all models\n",
    "print(\"Validation Performance Comparison:\")\n",
    "models_val_comp_df.sort_index(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db377c5d",
   "metadata": {},
   "source": [
    "#### Observations:\n",
    "- *GBM Tuned* has the highest R$^2$ (0.109) on the validation set, followed by *XGB_gbtree Tuned*, then *GBM*.\n",
    "- As we did not include the Decision Tree here, we can ignore Adjusted R$^2$, and just compare R$^2$.\n",
    "- Of the three models with R$^2$ scores over 10, there is some variation in overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9676dad",
   "metadata": {},
   "source": [
    "#### Comparison of Percentage of Overfitting for R$^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "233dce94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of R-square overfitting:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGB_gblinear            -3.381345\n",
       "XGB_gblinear Tuned      -1.840783\n",
       "GBM                      4.808487\n",
       "GBM Tuned               12.868707\n",
       "XGB_gbtree Tuned        15.091493\n",
       "Random Forest Tuned     36.317546\n",
       "XGB_gbtree              52.844295\n",
       "Random Forest          114.428464\n",
       "Name: R-squared, dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 34;\n",
       "                var nbb_unformatted_code = \"# Subtracting the ratio of validation R-square/train R-square from 1\\noverfit_perc = (\\n    1\\n    - (\\n        models_val_comp_df.loc[\\\"R-squared\\\", :]\\n        / models_train_comp_df.loc[\\\"R-squared\\\", :]\\n    )\\n) * 100\\n\\nprint(f\\\"Percentage of R-square overfitting:\\\")\\noverfit_perc.sort_values()\";\n",
       "                var nbb_formatted_code = \"# Subtracting the ratio of validation R-square/train R-square from 1\\noverfit_perc = (\\n    1\\n    - (\\n        models_val_comp_df.loc[\\\"R-squared\\\", :]\\n        / models_train_comp_df.loc[\\\"R-squared\\\", :]\\n    )\\n) * 100\\n\\nprint(f\\\"Percentage of R-square overfitting:\\\")\\noverfit_perc.sort_values()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Subtracting the ratio of validation R-square/train R-square from 1\n",
    "overfit_perc = (\n",
    "    1\n",
    "    - (\n",
    "        models_val_comp_df.loc[\"R-squared\", :]\n",
    "        / models_train_comp_df.loc[\"R-squared\", :]\n",
    "    )\n",
    ") * 100\n",
    "\n",
    "print(f\"Percentage of R-square overfitting:\")\n",
    "overfit_perc.sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b074931e",
   "metadata": {},
   "source": [
    "#### Observations:\n",
    "- *XGB_gblinear* and *XGB_gblinear Tuned* both performed better on the validation set, than the training set, which is interesting.\n",
    "- Of the top 3 models for R$^2$ score, *GBM* generalized considerably better than *GBM Tuned* and *XGB_gtree Tuned*.  \n",
    "- That said, *GBM Tuned* has the highest R$^2$ score on the validation set.\n",
    "- Next we will try another modeling iteration, replacing the one hot encoded `known_for` predictor with the original `known for` category columns.  For linear regression, we had to drop categorical columns to address multicollinearity, so entries with multiple `known for` categories were grouped in the `known_for` feature, into `two` and `three_to_five` classes.  We retained that approach for the above modeling iteration, but for this iteration we will allow entries to have their original multiple categories.  We will also include the `num_categories` feature in this iteration."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31317d01",
   "metadata": {},
   "source": [
    "## 2nd Modeling Iteration with Original `known for` Category Columns and `num_features`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3bec29e",
   "metadata": {},
   "source": [
    "### Defining Independent and Dependent Variables for Train and Validation Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "13c39fb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 54336 rows and 34 columns in the train set.\n",
      "\n",
      "There are 23288 rows and 34 columns in the validation set.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_references</th>\n",
       "      <th>years</th>\n",
       "      <th>sciences</th>\n",
       "      <th>social</th>\n",
       "      <th>spiritual</th>\n",
       "      <th>academia_humanities</th>\n",
       "      <th>business_farming</th>\n",
       "      <th>arts</th>\n",
       "      <th>sports</th>\n",
       "      <th>law_enf_military_operator</th>\n",
       "      <th>politics_govt_law</th>\n",
       "      <th>crime</th>\n",
       "      <th>num_categories</th>\n",
       "      <th>region_Asia</th>\n",
       "      <th>region_Central Asia</th>\n",
       "      <th>region_Europe</th>\n",
       "      <th>region_Mid-Cent America/Caribbean</th>\n",
       "      <th>region_Middle East</th>\n",
       "      <th>region_North America</th>\n",
       "      <th>region_Oceania</th>\n",
       "      <th>region_Russian Federation</th>\n",
       "      <th>region_South America</th>\n",
       "      <th>region_South East Asia</th>\n",
       "      <th>prior_region_Asia</th>\n",
       "      <th>prior_region_Central Asia</th>\n",
       "      <th>prior_region_Europe</th>\n",
       "      <th>prior_region_Mid-Cent America/Caribbean</th>\n",
       "      <th>prior_region_Middle East</th>\n",
       "      <th>prior_region_No Prior Region</th>\n",
       "      <th>prior_region_North America</th>\n",
       "      <th>prior_region_Oceania</th>\n",
       "      <th>prior_region_Russian Federation</th>\n",
       "      <th>prior_region_South America</th>\n",
       "      <th>prior_region_South East Asia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5302</th>\n",
       "      <td>5.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      num_references  years  sciences  social  spiritual  academia_humanities  \\\n",
       "5302             5.0   20.0       0.0     0.0        0.0                  0.0   \n",
       "\n",
       "      business_farming  arts  sports  law_enf_military_operator  \\\n",
       "5302               0.0   1.0     1.0                        0.0   \n",
       "\n",
       "      politics_govt_law  crime  num_categories  region_Asia  \\\n",
       "5302                0.0    0.0             2.0          0.0   \n",
       "\n",
       "      region_Central Asia  region_Europe  region_Mid-Cent America/Caribbean  \\\n",
       "5302                  0.0            0.0                                0.0   \n",
       "\n",
       "      region_Middle East  region_North America  region_Oceania  \\\n",
       "5302                 0.0                   1.0             0.0   \n",
       "\n",
       "      region_Russian Federation  region_South America  region_South East Asia  \\\n",
       "5302                        0.0                   0.0                     0.0   \n",
       "\n",
       "      prior_region_Asia  prior_region_Central Asia  prior_region_Europe  \\\n",
       "5302                0.0                        0.0                  0.0   \n",
       "\n",
       "      prior_region_Mid-Cent America/Caribbean  prior_region_Middle East  \\\n",
       "5302                                      0.0                       0.0   \n",
       "\n",
       "      prior_region_No Prior Region  prior_region_North America  \\\n",
       "5302                           1.0                         0.0   \n",
       "\n",
       "      prior_region_Oceania  prior_region_Russian Federation  \\\n",
       "5302                   0.0                              0.0   \n",
       "\n",
       "      prior_region_South America  prior_region_South East Asia  \n",
       "5302                         0.0                           0.0  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 35;\n",
       "                var nbb_unformatted_code = \"# Creating list of predictor columns\\npredictor_cols = [\\n    \\\"num_references\\\",\\n    \\\"years\\\",\\n    \\\"region\\\",\\n    \\\"prior_region\\\",\\n    \\\"sciences\\\",\\n    \\\"social\\\",\\n    \\\"spiritual\\\",\\n    \\\"academia_humanities\\\",\\n    \\\"business_farming\\\",\\n    \\\"arts\\\",\\n    \\\"sports\\\",\\n    \\\"law_enf_military_operator\\\",\\n    \\\"politics_govt_law\\\",\\n    \\\"crime\\\",\\n    \\\"num_categories\\\",\\n]\\n\\n# Defining target column\\ntarget = \\\"age\\\"\\n\\n# Defining independent and dependent variables\\nX = df[predictor_cols]\\ny = df[target]\\n\\n# One hot encoding of categorical predictors and typecasting all predictors as float\\nX = pd.get_dummies(X, drop_first=True).astype(\\\"float64\\\")\\n\\n# Splitting into 70:30 train and validation sets\\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=42)\\n\\n# Checking shape of train and validation sets\\nprint(\\n    f\\\"There are {X_train.shape[0]} rows and {X_train.shape[1]} columns in the train set.\\\\n\\\"\\n)\\nprint(\\n    f\\\"There are {X_val.shape[0]} rows and {X_val.shape[1]} columns in the validation set.\\\\n\\\"\\n)\\n\\n# Checking a sample\\nX_train.sample()\";\n",
       "                var nbb_formatted_code = \"# Creating list of predictor columns\\npredictor_cols = [\\n    \\\"num_references\\\",\\n    \\\"years\\\",\\n    \\\"region\\\",\\n    \\\"prior_region\\\",\\n    \\\"sciences\\\",\\n    \\\"social\\\",\\n    \\\"spiritual\\\",\\n    \\\"academia_humanities\\\",\\n    \\\"business_farming\\\",\\n    \\\"arts\\\",\\n    \\\"sports\\\",\\n    \\\"law_enf_military_operator\\\",\\n    \\\"politics_govt_law\\\",\\n    \\\"crime\\\",\\n    \\\"num_categories\\\",\\n]\\n\\n# Defining target column\\ntarget = \\\"age\\\"\\n\\n# Defining independent and dependent variables\\nX = df[predictor_cols]\\ny = df[target]\\n\\n# One hot encoding of categorical predictors and typecasting all predictors as float\\nX = pd.get_dummies(X, drop_first=True).astype(\\\"float64\\\")\\n\\n# Splitting into 70:30 train and validation sets\\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=42)\\n\\n# Checking shape of train and validation sets\\nprint(\\n    f\\\"There are {X_train.shape[0]} rows and {X_train.shape[1]} columns in the train set.\\\\n\\\"\\n)\\nprint(\\n    f\\\"There are {X_val.shape[0]} rows and {X_val.shape[1]} columns in the validation set.\\\\n\\\"\\n)\\n\\n# Checking a sample\\nX_train.sample()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Creating list of predictor columns\n",
    "predictor_cols = [\n",
    "    \"num_references\",\n",
    "    \"years\",\n",
    "    \"region\",\n",
    "    \"prior_region\",\n",
    "    \"sciences\",\n",
    "    \"social\",\n",
    "    \"spiritual\",\n",
    "    \"academia_humanities\",\n",
    "    \"business_farming\",\n",
    "    \"arts\",\n",
    "    \"sports\",\n",
    "    \"law_enf_military_operator\",\n",
    "    \"politics_govt_law\",\n",
    "    \"crime\",\n",
    "    \"num_categories\",\n",
    "]\n",
    "\n",
    "# Defining target column\n",
    "target = \"age\"\n",
    "\n",
    "# Defining independent and dependent variables\n",
    "X = df[predictor_cols]\n",
    "y = df[target]\n",
    "\n",
    "# One hot encoding of categorical predictors and typecasting all predictors as float\n",
    "X = pd.get_dummies(X, drop_first=True).astype(\"float64\")\n",
    "\n",
    "# Splitting into 70:30 train and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Checking shape of train and validation sets\n",
    "print(\n",
    "    f\"There are {X_train.shape[0]} rows and {X_train.shape[1]} columns in the train set.\\n\"\n",
    ")\n",
    "print(\n",
    "    f\"There are {X_val.shape[0]} rows and {X_val.shape[1]} columns in the validation set.\\n\"\n",
    ")\n",
    "\n",
    "# Checking a sample\n",
    "X_train.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f2d0b7",
   "metadata": {},
   "source": [
    "#### Defining Scorer for Cross-validation and Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "091141e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 36;\n",
       "                var nbb_unformatted_code = \"# Type of scoring used to compare parameter combinations--maximizing Adj R-squared\\nscorer = \\\"r2\\\"\";\n",
       "                var nbb_formatted_code = \"# Type of scoring used to compare parameter combinations--maximizing Adj R-squared\\nscorer = \\\"r2\\\"\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Type of scoring used to compare parameter combinations--maximizing Adj R-squared\n",
    "scorer = \"r2\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1737ee02",
   "metadata": {},
   "source": [
    "### Building the Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c72709d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cross-Validation:\n",
      "\n",
      "Dtree2: -0.39988031150791087\n",
      "Random Forest2: -0.055391943965687626\n",
      "Bagging Dtree2: -0.09151226074998306\n",
      "GBM2: 0.10458496917399238\n",
      "AdaBoost Dtree2: -0.04659101299906472\n",
      "XGB_gbtree2: 0.09199892946363704\n",
      "XGB_gblinear2: 0.08876867683811089\n",
      "\n",
      "Validation Performance:\n",
      "\n",
      "Dtree2: -0.3874580410488391\n",
      "Random Forest2: -0.05737130520636269\n",
      "Bagging Dtree2: -0.09428953449035293\n",
      "GBM2: 0.10690165941428653\n",
      "AdaBoost Dtree2: -0.08047644155074885\n",
      "XGB_gbtree2: 0.09741681484821774\n",
      "XGB_gblinear2: 0.09098718429881647\n",
      "CPU times: total: 3min 42s\n",
      "Wall time: 1min 18s\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 37;\n",
       "                var nbb_unformatted_code = \"%%time\\n\\n# Creating list to store the models\\nmodels = []\\n\\n# Appending models to the list\\nmodels.append(('Dtree2', DecisionTreeRegressor(random_state=42)))\\n\\nmodels.append(('Random Forest2', RandomForestRegressor(random_state=42)))\\n\\nmodels.append(('Bagging Dtree2', BaggingRegressor(random_state=42)))\\n\\nmodels.append(('GBM2', GradientBoostingRegressor(random_state=42)))\\n\\nmodels.append(('AdaBoost Dtree2', AdaBoostRegressor(random_state=42)))\\n\\nmodels.append(('XGB_gbtree2', XGBRegressor(random_state=42)))\\n\\nmodels.append(('XGB_gblinear2', XGBRegressor(random_state=42, booster='gblinear')))\\n\\n# Create empty list to store all model's names and CV scores\\nnames = []\\nresults = []\\n\\n# Loop through all models to get the mean cross validated score\\nprint(\\\"\\\\n\\\" \\\"Cross-Validation:\\\" \\\"\\\\n\\\")\\n\\nfor name, model in models:\\n    cv_result = cross_val_score(\\n        estimator=model, X=X_train, y=y_train, scoring=scorer, cv=5\\n    )\\n    results.append(cv_result)\\n    names.append(name)\\n    print(f\\\"{name}: {cv_result.mean()}\\\")\\n    \\nprint(\\\"\\\\n\\\" \\\"Validation Performance:\\\" \\\"\\\\n\\\")\\n\\nfor name, model in models:\\n    model.fit(X_train, y_train)\\n    scores = r2_score(y_val, model.predict(X_val))\\n    print(\\\"{}: {}\\\".format(name, scores))\";\n",
       "                var nbb_formatted_code = \"%%time\\n\\n# Creating list to store the models\\nmodels = []\\n\\n# Appending models to the list\\nmodels.append(('Dtree2', DecisionTreeRegressor(random_state=42)))\\n\\nmodels.append(('Random Forest2', RandomForestRegressor(random_state=42)))\\n\\nmodels.append(('Bagging Dtree2', BaggingRegressor(random_state=42)))\\n\\nmodels.append(('GBM2', GradientBoostingRegressor(random_state=42)))\\n\\nmodels.append(('AdaBoost Dtree2', AdaBoostRegressor(random_state=42)))\\n\\nmodels.append(('XGB_gbtree2', XGBRegressor(random_state=42)))\\n\\nmodels.append(('XGB_gblinear2', XGBRegressor(random_state=42, booster='gblinear')))\\n\\n# Create empty list to store all model's names and CV scores\\nnames = []\\nresults = []\\n\\n# Loop through all models to get the mean cross validated score\\nprint(\\\"\\\\n\\\" \\\"Cross-Validation:\\\" \\\"\\\\n\\\")\\n\\nfor name, model in models:\\n    cv_result = cross_val_score(\\n        estimator=model, X=X_train, y=y_train, scoring=scorer, cv=5\\n    )\\n    results.append(cv_result)\\n    names.append(name)\\n    print(f\\\"{name}: {cv_result.mean()}\\\")\\n    \\nprint(\\\"\\\\n\\\" \\\"Validation Performance:\\\" \\\"\\\\n\\\")\\n\\nfor name, model in models:\\n    model.fit(X_train, y_train)\\n    scores = r2_score(y_val, model.predict(X_val))\\n    print(\\\"{}: {}\\\".format(name, scores))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Creating list to store the models\n",
    "models = []\n",
    "\n",
    "# Appending models to the list\n",
    "models.append(('Dtree2', DecisionTreeRegressor(random_state=42)))\n",
    "\n",
    "models.append(('Random Forest2', RandomForestRegressor(random_state=42)))\n",
    "\n",
    "models.append(('Bagging Dtree2', BaggingRegressor(random_state=42)))\n",
    "\n",
    "models.append(('GBM2', GradientBoostingRegressor(random_state=42)))\n",
    "\n",
    "models.append(('AdaBoost Dtree2', AdaBoostRegressor(random_state=42)))\n",
    "\n",
    "models.append(('XGB_gbtree2', XGBRegressor(random_state=42)))\n",
    "\n",
    "models.append(('XGB_gblinear2', XGBRegressor(random_state=42, booster='gblinear')))\n",
    "\n",
    "# Create empty list to store all model's names and CV scores\n",
    "names = []\n",
    "results = []\n",
    "\n",
    "# Loop through all models to get the mean cross validated score\n",
    "print(\"\\n\" \"Cross-Validation:\" \"\\n\")\n",
    "\n",
    "for name, model in models:\n",
    "    cv_result = cross_val_score(\n",
    "        estimator=model, X=X_train, y=y_train, scoring=scorer, cv=5\n",
    "    )\n",
    "    results.append(cv_result)\n",
    "    names.append(name)\n",
    "    print(f\"{name}: {cv_result.mean()}\")\n",
    "    \n",
    "print(\"\\n\" \"Validation Performance:\" \"\\n\")\n",
    "\n",
    "for name, model in models:\n",
    "    model.fit(X_train, y_train)\n",
    "    scores = r2_score(y_val, model.predict(X_val))\n",
    "    print(\"{}: {}\".format(name, scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8c8051d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x504 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 38;\n",
       "                var nbb_unformatted_code = \"# Plotting boxplots for CV scores of all models defined above\\nfig = plt.figure(figsize=(20, 7))\\n\\nfig.suptitle(\\\"Algorithm Comparison for Cross-validation R-squared Score\\\")\\nax = fig.add_subplot(111)\\n\\nplt.boxplot(results)\\nax.set_xticklabels(names)\\nplt.xticks(rotation=30)\\n\\nplt.show()\";\n",
       "                var nbb_formatted_code = \"# Plotting boxplots for CV scores of all models defined above\\nfig = plt.figure(figsize=(20, 7))\\n\\nfig.suptitle(\\\"Algorithm Comparison for Cross-validation R-squared Score\\\")\\nax = fig.add_subplot(111)\\n\\nplt.boxplot(results)\\nax.set_xticklabels(names)\\nplt.xticks(rotation=30)\\n\\nplt.show()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting boxplots for CV scores of all models defined above\n",
    "fig = plt.figure(figsize=(20, 7))\n",
    "\n",
    "fig.suptitle(\"Algorithm Comparison for Cross-validation R-squared Score\")\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "plt.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "plt.xticks(rotation=30)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad83c51d",
   "metadata": {},
   "source": [
    "#### Observations:\n",
    "- So far, the performances are similar to the first modeling iteration above.\n",
    "- We will perform hyperparameter tuning on the top 3 models and again keep *Random Forest2* in the mix, also."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17777769",
   "metadata": {},
   "source": [
    "#### Collecting Models with Best Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "31644f82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 39;\n",
       "                var nbb_unformatted_code = \"# List of top models so far\\ntop_models = [models[1]] + [models[3]] + models[-2:]\";\n",
       "                var nbb_formatted_code = \"# List of top models so far\\ntop_models = [models[1]] + [models[3]] + models[-2:]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# List of top models so far\n",
    "top_models = [models[1]] + [models[3]] + models[-2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf8ed15",
   "metadata": {},
   "source": [
    "#### Creating Dataframes to Compare Training and Validation Performance of Best Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "eac3f2e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 40;\n",
       "                var nbb_unformatted_code = \"# Creating empty dictionary to hold the models\\nmodels_to_tune = {}\\n\\n# For loop to add models to dictionary\\nfor model in top_models:\\n    key = model[0]\\n    value = model[1]\\n    models_to_tune[key] = value\\n\\n# For loop to add performance results of each top model\\nfor name, model in models_to_tune.items():\\n    models_train_comp_df[name] = model_performance_regression(model, X_train, y_train).T\\n    models_val_comp_df[name] = model_performance_regression(model, X_val, y_val).T\";\n",
       "                var nbb_formatted_code = \"# Creating empty dictionary to hold the models\\nmodels_to_tune = {}\\n\\n# For loop to add models to dictionary\\nfor model in top_models:\\n    key = model[0]\\n    value = model[1]\\n    models_to_tune[key] = value\\n\\n# For loop to add performance results of each top model\\nfor name, model in models_to_tune.items():\\n    models_train_comp_df[name] = model_performance_regression(model, X_train, y_train).T\\n    models_val_comp_df[name] = model_performance_regression(model, X_val, y_val).T\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Creating empty dictionary to hold the models\n",
    "models_to_tune = {}\n",
    "\n",
    "# For loop to add models to dictionary\n",
    "for model in top_models:\n",
    "    key = model[0]\n",
    "    value = model[1]\n",
    "    models_to_tune[key] = value\n",
    "\n",
    "# For loop to add performance results of each top model\n",
    "for name, model in models_to_tune.items():\n",
    "    models_train_comp_df[name] = model_performance_regression(model, X_train, y_train).T\n",
    "    models_val_comp_df[name] = model_performance_regression(model, X_val, y_val).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17466a60",
   "metadata": {},
   "source": [
    "#### Comparing Top Models Before Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d7a2bc20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Performance:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Random Forest2</th>\n",
       "      <th>GBM2</th>\n",
       "      <th>XGB_gbtree2</th>\n",
       "      <th>XGB_gblinear2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>11.328976</td>\n",
       "      <td>14.937480</td>\n",
       "      <td>14.196740</td>\n",
       "      <td>15.129788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>8.362030</td>\n",
       "      <td>11.599899</td>\n",
       "      <td>10.984573</td>\n",
       "      <td>11.741532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-squared</th>\n",
       "      <td>0.489686</td>\n",
       "      <td>0.112822</td>\n",
       "      <td>0.198629</td>\n",
       "      <td>0.089831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Adj. R-squared</th>\n",
       "      <td>0.489367</td>\n",
       "      <td>0.112266</td>\n",
       "      <td>0.198128</td>\n",
       "      <td>0.089262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAPE</th>\n",
       "      <td>13.404005</td>\n",
       "      <td>19.178492</td>\n",
       "      <td>17.982195</td>\n",
       "      <td>19.384426</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Random Forest2       GBM2  XGB_gbtree2  XGB_gblinear2\n",
       "RMSE                 11.328976  14.937480    14.196740      15.129788\n",
       "MAE                   8.362030  11.599899    10.984573      11.741532\n",
       "R-squared             0.489686   0.112822     0.198629       0.089831\n",
       "Adj. R-squared        0.489367   0.112266     0.198128       0.089262\n",
       "MAPE                 13.404005  19.178492    17.982195      19.384426"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 41;\n",
       "                var nbb_unformatted_code = \"# Comparing train performance\\nprint(f\\\"Training Performance:\\\")\\nmodels_train_comp_df[[key for key in models_to_tune.keys()]]\";\n",
       "                var nbb_formatted_code = \"# Comparing train performance\\nprint(f\\\"Training Performance:\\\")\\nmodels_train_comp_df[[key for key in models_to_tune.keys()]]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Comparing train performance\n",
    "print(f\"Training Performance:\")\n",
    "models_train_comp_df[[key for key in models_to_tune.keys()]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2afc9145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Performance:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Random Forest2</th>\n",
       "      <th>GBM2</th>\n",
       "      <th>XGB_gbtree2</th>\n",
       "      <th>XGB_gblinear2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>16.206121</td>\n",
       "      <td>14.894124</td>\n",
       "      <td>14.973004</td>\n",
       "      <td>15.026240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>12.476262</td>\n",
       "      <td>11.552854</td>\n",
       "      <td>11.582826</td>\n",
       "      <td>11.654621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-squared</th>\n",
       "      <td>-0.057371</td>\n",
       "      <td>0.106902</td>\n",
       "      <td>0.097417</td>\n",
       "      <td>0.090987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Adj. R-squared</th>\n",
       "      <td>-0.058917</td>\n",
       "      <td>0.105596</td>\n",
       "      <td>0.096097</td>\n",
       "      <td>0.089658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAPE</th>\n",
       "      <td>20.071146</td>\n",
       "      <td>19.011210</td>\n",
       "      <td>18.941080</td>\n",
       "      <td>19.158441</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Random Forest2       GBM2  XGB_gbtree2  XGB_gblinear2\n",
       "RMSE                 16.206121  14.894124    14.973004      15.026240\n",
       "MAE                  12.476262  11.552854    11.582826      11.654621\n",
       "R-squared            -0.057371   0.106902     0.097417       0.090987\n",
       "Adj. R-squared       -0.058917   0.105596     0.096097       0.089658\n",
       "MAPE                 20.071146  19.011210    18.941080      19.158441"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 42;\n",
       "                var nbb_unformatted_code = \"# Comparing validation performance\\nprint(f\\\"Validation Performance:\\\")\\nmodels_val_comp_df[[key for key in models_to_tune.keys()]]\";\n",
       "                var nbb_formatted_code = \"# Comparing validation performance\\nprint(f\\\"Validation Performance:\\\")\\nmodels_val_comp_df[[key for key in models_to_tune.keys()]]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Comparing validation performance\n",
    "print(f\"Validation Performance:\")\n",
    "models_val_comp_df[[key for key in models_to_tune.keys()]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e812ca",
   "metadata": {},
   "source": [
    "#### Observations:\n",
    "- Here, we compare the performance on the whole train set to the validation set.\n",
    "- As with the first iteration above, only *GBM2* and *XGB_gblinear2* are giving generalized performances on the two sets.\n",
    "- We will proceed with hyperparameter tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59aace1",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c9645e8",
   "metadata": {},
   "source": [
    "### *Random Forest2 Tuned*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fdc0fd0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(random_state=42)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 43;\n",
       "                var nbb_unformatted_code = \"# Confirming the model\\nmodels_to_tune[\\\"Random Forest2\\\"]\";\n",
       "                var nbb_formatted_code = \"# Confirming the model\\nmodels_to_tune[\\\"Random Forest2\\\"]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Confirming the model\n",
    "models_to_tune[\"Random Forest2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c0c1d615",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Teres\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "5 fits failed out of a total of 50.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Teres\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Teres\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 450, in fit\n",
      "    trees = Parallel(\n",
      "  File \"C:\\Users\\Teres\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Teres\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Teres\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Teres\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Teres\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Teres\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Teres\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Teres\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 216, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\Teres\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 185, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Teres\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1315, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\Teres\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 241, in fit\n",
      "    if not 0.0 < self.min_samples_leaf <= 0.5:\n",
      "TypeError: '<' not supported between instances of 'float' and 'NoneType'\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\Teres\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.10342598 0.10211994 0.10160088 0.10362196 0.05381091 0.10627175\n",
      " 0.10560085 0.10495005        nan 0.09923682]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters are {'criterion': 'squared_error', 'max_depth': None, 'max_features': 'sqrt', 'max_samples': 0.7162213204002108, 'min_samples_leaf': 5, 'n_estimators': 485} with CV score=0.10627175102316326:\n",
      "CPU times: total: 7.92 s\n",
      "Wall time: 1min 15s\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 44;\n",
       "                var nbb_unformatted_code = \"%%time\\n\\n# Defining model\\nModel = RandomForestRegressor(random_state=42)\\n\\n# Parameter grid to pass in RandomizedSearchCV\\nparam_grid = { \\n    \\\"n_estimators\\\": np.arange(100, 500), \\n    \\\"min_samples_leaf\\\": [None] + np.arange(1, 10).tolist(),\\n    \\\"max_features\\\": ['sqrt'], \\n    \\\"max_samples\\\": uniform(loc=0.3, scale=0.5),\\n    'criterion': ['squared_error'],\\n    \\\"max_depth\\\": [None]\\n}\\n\\n# Calling RandomizedSearchCV\\nrandomized_cv = RandomizedSearchCV(\\n    estimator=Model,\\n    param_distributions=param_grid,\\n    n_iter=10,\\n    n_jobs=-1,\\n    scoring=scorer,\\n    cv=5,\\n    random_state=42,\\n)\\n\\n# Fitting parameters in RandomizedSearchCV\\nrandomized_cv.fit(X_train, y_train)\\n\\nprint(\\n    \\\"Best parameters are {} with CV score={}:\\\".format(\\n        randomized_cv.best_params_, randomized_cv.best_score_\\n    )\\n)\\n\\n# Chime notification when cell successfully executes\\nchime.success()\";\n",
       "                var nbb_formatted_code = \"%%time\\n\\n# Defining model\\nModel = RandomForestRegressor(random_state=42)\\n\\n# Parameter grid to pass in RandomizedSearchCV\\nparam_grid = { \\n    \\\"n_estimators\\\": np.arange(100, 500), \\n    \\\"min_samples_leaf\\\": [None] + np.arange(1, 10).tolist(),\\n    \\\"max_features\\\": ['sqrt'], \\n    \\\"max_samples\\\": uniform(loc=0.3, scale=0.5),\\n    'criterion': ['squared_error'],\\n    \\\"max_depth\\\": [None]\\n}\\n\\n# Calling RandomizedSearchCV\\nrandomized_cv = RandomizedSearchCV(\\n    estimator=Model,\\n    param_distributions=param_grid,\\n    n_iter=10,\\n    n_jobs=-1,\\n    scoring=scorer,\\n    cv=5,\\n    random_state=42,\\n)\\n\\n# Fitting parameters in RandomizedSearchCV\\nrandomized_cv.fit(X_train, y_train)\\n\\nprint(\\n    \\\"Best parameters are {} with CV score={}:\\\".format(\\n        randomized_cv.best_params_, randomized_cv.best_score_\\n    )\\n)\\n\\n# Chime notification when cell successfully executes\\nchime.success()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Defining model\n",
    "Model = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Parameter grid to pass in RandomizedSearchCV\n",
    "param_grid = { \n",
    "    \"n_estimators\": np.arange(100, 500), \n",
    "    \"min_samples_leaf\": [None] + np.arange(1, 10).tolist(),\n",
    "    \"max_features\": ['sqrt'], \n",
    "    \"max_samples\": uniform(loc=0.3, scale=0.5),\n",
    "    'criterion': ['squared_error'],\n",
    "    \"max_depth\": [None]\n",
    "}\n",
    "\n",
    "# Calling RandomizedSearchCV\n",
    "randomized_cv = RandomizedSearchCV(\n",
    "    estimator=Model,\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=10,\n",
    "    n_jobs=-1,\n",
    "    scoring=scorer,\n",
    "    cv=5,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "# Fitting parameters in RandomizedSearchCV\n",
    "randomized_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\n",
    "    \"Best parameters are {} with CV score={}:\".format(\n",
    "        randomized_cv.best_params_, randomized_cv.best_score_\n",
    "    )\n",
    ")\n",
    "\n",
    "# Chime notification when cell successfully executes\n",
    "chime.success()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ff8ed9c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(max_features='sqrt', max_samples=0.7162213204002108,\n",
       "                      min_samples_leaf=5, n_estimators=485)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 45;\n",
       "                var nbb_unformatted_code = \"# Building model with best parameters\\nRandom_Forest2_tuned = RandomForestRegressor(\\n    criterion=\\\"squared_error\\\",\\n    max_depth=None,\\n    max_features=\\\"sqrt\\\",\\n    max_samples=0.7162213204002108,\\n    min_samples_leaf=5,\\n    n_estimators=485,\\n)\\n\\n# Fit the model on training data\\nRandom_Forest2_tuned.fit(X_train, y_train)\";\n",
       "                var nbb_formatted_code = \"# Building model with best parameters\\nRandom_Forest2_tuned = RandomForestRegressor(\\n    criterion=\\\"squared_error\\\",\\n    max_depth=None,\\n    max_features=\\\"sqrt\\\",\\n    max_samples=0.7162213204002108,\\n    min_samples_leaf=5,\\n    n_estimators=485,\\n)\\n\\n# Fit the model on training data\\nRandom_Forest2_tuned.fit(X_train, y_train)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Building model with best parameters\n",
    "Random_Forest2_tuned = RandomForestRegressor(\n",
    "    criterion=\"squared_error\",\n",
    "    max_depth=None,\n",
    "    max_features=\"sqrt\",\n",
    "    max_samples=0.7162213204002108,\n",
    "    min_samples_leaf=5,\n",
    "    n_estimators=485,\n",
    ")\n",
    "\n",
    "# Fit the model on training data\n",
    "Random_Forest2_tuned.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7bb844d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training performance:\n",
      "         RMSE        MAE  R-squared  Adj. R-squared       MAPE\n",
      "0  14.496677  11.259928    0.16441        0.163887  18.615087\n",
      "\n",
      "Validation performance:\n",
      "         RMSE        MAE  R-squared  Adj. R-squared       MAPE\n",
      "0  14.901352  11.555613   0.106035        0.104727  19.015297\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 46;\n",
       "                var nbb_unformatted_code = \"# Calculating different metrics\\nRandom_Forest2_tuned_train_perf = model_performance_regression(\\n    Random_Forest2_tuned, X_train, y_train\\n)\\nprint(\\\"Training performance:\\\\n\\\", Random_Forest2_tuned_train_perf)\\nRandom_Forest2_tuned_val_perf = model_performance_regression(\\n    Random_Forest2_tuned, X_val, y_val\\n)\\nprint(\\\"\\\\nValidation performance:\\\\n\\\", Random_Forest2_tuned_val_perf)\\n\\n# Adding model to model comparison dataframes\\nmodels_train_comp_df[\\\"Random Forest2 Tuned\\\"] = Random_Forest2_tuned_train_perf.T\\nmodels_val_comp_df[\\\"Random Forest2 Tuned\\\"] = Random_Forest2_tuned_val_perf.T\";\n",
       "                var nbb_formatted_code = \"# Calculating different metrics\\nRandom_Forest2_tuned_train_perf = model_performance_regression(\\n    Random_Forest2_tuned, X_train, y_train\\n)\\nprint(\\\"Training performance:\\\\n\\\", Random_Forest2_tuned_train_perf)\\nRandom_Forest2_tuned_val_perf = model_performance_regression(\\n    Random_Forest2_tuned, X_val, y_val\\n)\\nprint(\\\"\\\\nValidation performance:\\\\n\\\", Random_Forest2_tuned_val_perf)\\n\\n# Adding model to model comparison dataframes\\nmodels_train_comp_df[\\\"Random Forest2 Tuned\\\"] = Random_Forest2_tuned_train_perf.T\\nmodels_val_comp_df[\\\"Random Forest2 Tuned\\\"] = Random_Forest2_tuned_val_perf.T\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculating different metrics\n",
    "Random_Forest2_tuned_train_perf = model_performance_regression(\n",
    "    Random_Forest2_tuned, X_train, y_train\n",
    ")\n",
    "print(\"Training performance:\\n\", Random_Forest2_tuned_train_perf)\n",
    "Random_Forest2_tuned_val_perf = model_performance_regression(\n",
    "    Random_Forest2_tuned, X_val, y_val\n",
    ")\n",
    "print(\"\\nValidation performance:\\n\", Random_Forest2_tuned_val_perf)\n",
    "\n",
    "# Adding model to model comparison dataframes\n",
    "models_train_comp_df[\"Random Forest2 Tuned\"] = Random_Forest2_tuned_train_perf.T\n",
    "models_val_comp_df[\"Random Forest2 Tuned\"] = Random_Forest2_tuned_val_perf.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd5517f3",
   "metadata": {},
   "source": [
    "#### Observations:\n",
    "- Hyperparameter tuning improved performance for *Random Forest2*.\n",
    "- The algorithm is still overfitting the train set, compared to the validation set.\n",
    "- Note that we again had a 10% fit fail during cross-validation (\"UserWarning: One or more of the test scores are non-finite..\") indicating cross-validation had some folds for which hyperparameter combinations led to Nan values.  We are going to allow it here, and go with the results of the successful iterations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3bbffed",
   "metadata": {},
   "source": [
    "### *GBM2 Tuned*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5a7278d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(random_state=42)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 47;\n",
       "                var nbb_unformatted_code = \"# Confirming the model\\nmodels_to_tune[\\\"GBM2\\\"]\";\n",
       "                var nbb_formatted_code = \"# Confirming the model\\nmodels_to_tune[\\\"GBM2\\\"]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Confirming the model\n",
    "models_to_tune[\"GBM2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "164a6ac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters are {'learning_rate': 0.08171272700715591, 'max_features': 0.6630456668613307, 'n_estimators': 368, 'subsample': 0.7847684335570795} with CV score=0.11041556668246581:\n",
      "CPU times: total: 14.2 s\n",
      "Wall time: 8min\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 48;\n",
       "                var nbb_unformatted_code = \"%%time\\n\\n# Defining model\\nModel = GradientBoostingRegressor(random_state=42)\\n\\n# Parameter grid to pass in RandomizedSearchCV\\nparam_grid = {\\n    \\\"n_estimators\\\": np.arange(100, 500),\\n    \\\"learning_rate\\\": loguniform(0.001, 1),\\n    \\\"subsample\\\": uniform(loc=0.3, scale=0.5),\\n    \\\"max_features\\\": uniform(loc=0.3, scale=0.5),\\n}\\n\\n# Calling RandomizedSearchCV\\nrandomized_cv = RandomizedSearchCV(\\n    estimator=Model,\\n    param_distributions=param_grid,\\n    n_iter=100,\\n    n_jobs=-1,\\n    scoring=scorer,\\n    cv=5,\\n    random_state=42,\\n)\\n\\n# Fitting parameters in RandomizedSearchCV\\nrandomized_cv.fit(X_train, y_train)\\n\\nprint(\\n    \\\"Best parameters are {} with CV score={}:\\\".format(\\n        randomized_cv.best_params_, randomized_cv.best_score_\\n    )\\n)\\n\\n# Chime notification when cell successfully executes\\nchime.success()\";\n",
       "                var nbb_formatted_code = \"%%time\\n\\n# Defining model\\nModel = GradientBoostingRegressor(random_state=42)\\n\\n# Parameter grid to pass in RandomizedSearchCV\\nparam_grid = {\\n    \\\"n_estimators\\\": np.arange(100, 500),\\n    \\\"learning_rate\\\": loguniform(0.001, 1),\\n    \\\"subsample\\\": uniform(loc=0.3, scale=0.5),\\n    \\\"max_features\\\": uniform(loc=0.3, scale=0.5),\\n}\\n\\n# Calling RandomizedSearchCV\\nrandomized_cv = RandomizedSearchCV(\\n    estimator=Model,\\n    param_distributions=param_grid,\\n    n_iter=100,\\n    n_jobs=-1,\\n    scoring=scorer,\\n    cv=5,\\n    random_state=42,\\n)\\n\\n# Fitting parameters in RandomizedSearchCV\\nrandomized_cv.fit(X_train, y_train)\\n\\nprint(\\n    \\\"Best parameters are {} with CV score={}:\\\".format(\\n        randomized_cv.best_params_, randomized_cv.best_score_\\n    )\\n)\\n\\n# Chime notification when cell successfully executes\\nchime.success()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Defining model\n",
    "Model = GradientBoostingRegressor(random_state=42)\n",
    "\n",
    "# Parameter grid to pass in RandomizedSearchCV\n",
    "param_grid = {\n",
    "    \"n_estimators\": np.arange(100, 500),\n",
    "    \"learning_rate\": loguniform(0.001, 1),\n",
    "    \"subsample\": uniform(loc=0.3, scale=0.5),\n",
    "    \"max_features\": uniform(loc=0.3, scale=0.5),\n",
    "}\n",
    "\n",
    "# Calling RandomizedSearchCV\n",
    "randomized_cv = RandomizedSearchCV(\n",
    "    estimator=Model,\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=100,\n",
    "    n_jobs=-1,\n",
    "    scoring=scorer,\n",
    "    cv=5,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "# Fitting parameters in RandomizedSearchCV\n",
    "randomized_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\n",
    "    \"Best parameters are {} with CV score={}:\".format(\n",
    "        randomized_cv.best_params_, randomized_cv.best_score_\n",
    "    )\n",
    ")\n",
    "\n",
    "# Chime notification when cell successfully executes\n",
    "chime.success()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "83072624",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(learning_rate=0.08171272700715591,\n",
       "                          max_features=0.6630456668613307, n_estimators=368,\n",
       "                          random_state=42, subsample=0.7847684335570795)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 49;\n",
       "                var nbb_unformatted_code = \"# Building model with best parameters\\nGBM2_tuned = GradientBoostingRegressor(\\n    random_state=42,\\n    learning_rate=0.08171272700715591,\\n    max_features=0.6630456668613307,\\n    n_estimators=368,\\n    subsample=0.7847684335570795,\\n)\\n\\n# Fit the model on training data\\nGBM2_tuned.fit(X_train, y_train)\";\n",
       "                var nbb_formatted_code = \"# Building model with best parameters\\nGBM2_tuned = GradientBoostingRegressor(\\n    random_state=42,\\n    learning_rate=0.08171272700715591,\\n    max_features=0.6630456668613307,\\n    n_estimators=368,\\n    subsample=0.7847684335570795,\\n)\\n\\n# Fit the model on training data\\nGBM2_tuned.fit(X_train, y_train)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Building model with best parameters\n",
    "GBM2_tuned = GradientBoostingRegressor(\n",
    "    random_state=42,\n",
    "    learning_rate=0.08171272700715591,\n",
    "    max_features=0.6630456668613307,\n",
    "    n_estimators=368,\n",
    "    subsample=0.7847684335570795,\n",
    ")\n",
    "\n",
    "# Fit the model on training data\n",
    "GBM2_tuned.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "41f9f376",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training performance:\n",
      "         RMSE       MAE  R-squared  Adj. R-squared      MAPE\n",
      "0  14.803396  11.49037   0.128678        0.128132  18.95094\n",
      "\n",
      "Validation performance:\n",
      "         RMSE        MAE  R-squared  Adj. R-squared       MAPE\n",
      "0  14.853802  11.512155   0.111731        0.110432  18.898856\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 50;\n",
       "                var nbb_unformatted_code = \"# Calculating different metrics\\nGBM2_tuned_train_perf = model_performance_regression(GBM2_tuned, X_train, y_train)\\nprint(\\\"Training performance:\\\\n\\\", GBM2_tuned_train_perf)\\nGBM2_tuned_val_perf = model_performance_regression(GBM2_tuned, X_val, y_val)\\nprint(\\\"\\\\nValidation performance:\\\\n\\\", GBM2_tuned_val_perf)\\n\\n# Adding model to model comparison dataframes\\nmodels_train_comp_df[\\\"GBM2 Tuned\\\"] = GBM2_tuned_train_perf.T\\nmodels_val_comp_df[\\\"GBM2 Tuned\\\"] = GBM2_tuned_val_perf.T\";\n",
       "                var nbb_formatted_code = \"# Calculating different metrics\\nGBM2_tuned_train_perf = model_performance_regression(GBM2_tuned, X_train, y_train)\\nprint(\\\"Training performance:\\\\n\\\", GBM2_tuned_train_perf)\\nGBM2_tuned_val_perf = model_performance_regression(GBM2_tuned, X_val, y_val)\\nprint(\\\"\\\\nValidation performance:\\\\n\\\", GBM2_tuned_val_perf)\\n\\n# Adding model to model comparison dataframes\\nmodels_train_comp_df[\\\"GBM2 Tuned\\\"] = GBM2_tuned_train_perf.T\\nmodels_val_comp_df[\\\"GBM2 Tuned\\\"] = GBM2_tuned_val_perf.T\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculating different metrics\n",
    "GBM2_tuned_train_perf = model_performance_regression(GBM2_tuned, X_train, y_train)\n",
    "print(\"Training performance:\\n\", GBM2_tuned_train_perf)\n",
    "GBM2_tuned_val_perf = model_performance_regression(GBM2_tuned, X_val, y_val)\n",
    "print(\"\\nValidation performance:\\n\", GBM2_tuned_val_perf)\n",
    "\n",
    "# Adding model to model comparison dataframes\n",
    "models_train_comp_df[\"GBM2 Tuned\"] = GBM2_tuned_train_perf.T\n",
    "models_val_comp_df[\"GBM2 Tuned\"] = GBM2_tuned_val_perf.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d33085",
   "metadata": {},
   "source": [
    "#### Observations:\n",
    "- The performance for *GBM2* is improved with hyperparameter tuning.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ea9612",
   "metadata": {},
   "source": [
    "### *XGB_gbtree2 Tuned*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "629f0ae4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', callbacks=None,\n",
       "             colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "             early_stopping_rounds=None, enable_categorical=False,\n",
       "             eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n",
       "             importance_type=None, interaction_constraints='',\n",
       "             learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n",
       "             max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,\n",
       "             missing=nan, monotone_constraints='()', n_estimators=100, n_jobs=0,\n",
       "             num_parallel_tree=1, predictor='auto', random_state=42,\n",
       "             reg_alpha=0, reg_lambda=1, ...)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 51;\n",
       "                var nbb_unformatted_code = \"# Confirming the model\\nmodels_to_tune[\\\"XGB_gbtree2\\\"]\";\n",
       "                var nbb_formatted_code = \"# Confirming the model\\nmodels_to_tune[\\\"XGB_gbtree2\\\"]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Confirming the model\n",
    "models_to_tune[\"XGB_gbtree2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "567e4678",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters are {'colsample_bytree': 0.6861223846483286, 'gamma': 0.22153944050588595, 'learning_rate': 0.10165663513708073, 'max_depth': 5, 'n_estimators': 180, 'subsample': 0.74226839054973} with CV score=0.11086998659519617:\n",
      "CPU times: total: 47.5 s\n",
      "Wall time: 21min 10s\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 52;\n",
       "                var nbb_unformatted_code = \"%%time\\n\\n# Defining model\\nModel = XGBRegressor(random_state=42, booster='gbtree')\\n\\n# Parameter grid to pass in RandomizedSearchCV\\nparam_grid={\\n    'n_estimators': np.arange(100, 500),\\n    \\\"learning_rate\\\": uniform(0.1, 0.3), # aka eta\\n    'gamma': expon(), # aka min_split_loss\\n    'subsample': uniform(loc=0.6, scale=0.2), # proportion of train set to randomly sample prior to growing trees\\n    'max_depth': np.arange(3, 8).tolist(),\\n    'colsample_bytree': uniform(loc=0.3, scale=0.5)\\n}\\n\\n# Calling RandomizedSearchCV\\nrandomized_cv = RandomizedSearchCV(\\n    estimator=Model,\\n    param_distributions=param_grid,\\n    n_iter=100,\\n    n_jobs=-1,\\n    scoring=scorer,\\n    cv=5,\\n    random_state=42,\\n)\\n\\n# Fitting parameters in RandomizedSearchCV\\nrandomized_cv.fit(X_train, y_train)\\n\\nprint(\\n    \\\"Best parameters are {} with CV score={}:\\\".format(\\n        randomized_cv.best_params_, randomized_cv.best_score_\\n    )\\n)\\n\\n# Chime notification when cell successfully executes\\nchime.success()\";\n",
       "                var nbb_formatted_code = \"%%time\\n\\n# Defining model\\nModel = XGBRegressor(random_state=42, booster='gbtree')\\n\\n# Parameter grid to pass in RandomizedSearchCV\\nparam_grid={\\n    'n_estimators': np.arange(100, 500),\\n    \\\"learning_rate\\\": uniform(0.1, 0.3), # aka eta\\n    'gamma': expon(), # aka min_split_loss\\n    'subsample': uniform(loc=0.6, scale=0.2), # proportion of train set to randomly sample prior to growing trees\\n    'max_depth': np.arange(3, 8).tolist(),\\n    'colsample_bytree': uniform(loc=0.3, scale=0.5)\\n}\\n\\n# Calling RandomizedSearchCV\\nrandomized_cv = RandomizedSearchCV(\\n    estimator=Model,\\n    param_distributions=param_grid,\\n    n_iter=100,\\n    n_jobs=-1,\\n    scoring=scorer,\\n    cv=5,\\n    random_state=42,\\n)\\n\\n# Fitting parameters in RandomizedSearchCV\\nrandomized_cv.fit(X_train, y_train)\\n\\nprint(\\n    \\\"Best parameters are {} with CV score={}:\\\".format(\\n        randomized_cv.best_params_, randomized_cv.best_score_\\n    )\\n)\\n\\n# Chime notification when cell successfully executes\\nchime.success()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Defining model\n",
    "Model = XGBRegressor(random_state=42, booster='gbtree')\n",
    "\n",
    "# Parameter grid to pass in RandomizedSearchCV\n",
    "param_grid={\n",
    "    'n_estimators': np.arange(100, 500),\n",
    "    \"learning_rate\": uniform(0.1, 0.3), # aka eta\n",
    "    'gamma': expon(), # aka min_split_loss\n",
    "    'subsample': uniform(loc=0.6, scale=0.2), # proportion of train set to randomly sample prior to growing trees\n",
    "    'max_depth': np.arange(3, 8).tolist(),\n",
    "    'colsample_bytree': uniform(loc=0.3, scale=0.5)\n",
    "}\n",
    "\n",
    "# Calling RandomizedSearchCV\n",
    "randomized_cv = RandomizedSearchCV(\n",
    "    estimator=Model,\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=100,\n",
    "    n_jobs=-1,\n",
    "    scoring=scorer,\n",
    "    cv=5,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "# Fitting parameters in RandomizedSearchCV\n",
    "randomized_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\n",
    "    \"Best parameters are {} with CV score={}:\".format(\n",
    "        randomized_cv.best_params_, randomized_cv.best_score_\n",
    "    )\n",
    ")\n",
    "\n",
    "# Chime notification when cell successfully executes\n",
    "chime.success()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ff25695c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', callbacks=None,\n",
       "             colsample_bylevel=1, colsample_bynode=1,\n",
       "             colsample_bytree=0.6861223846483286, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None,\n",
       "             gamma=0.22153944050588595, gpu_id=-1, grow_policy='depthwise',\n",
       "             importance_type=None, interaction_constraints='',\n",
       "             learning_rate=0.10165663513708073, max_bin=256,\n",
       "             max_cat_to_onehot=4, max_delta_step=0, max_depth=5, max_leaves=0,\n",
       "             min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "             n_estimators=180, n_jobs=0, num_parallel_tree=1, predictor='auto',\n",
       "             random_state=42, reg_alpha=0, reg_lambda=1, ...)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 59;\n",
       "                var nbb_unformatted_code = \"# Building model with best parameters\\nXGB_gbtree2_tuned = XGBRegressor(\\n    booster=\\\"gbtree\\\",\\n    random_state=42,\\n    colsample_bytree=0.6861223846483286,\\n    gamma=0.22153944050588595,\\n    learning_rate=0.10165663513708073,\\n    max_depth=5,\\n    n_estimators=180,\\n    subsample=0.74226839054973,\\n)\\n\\n# Fit the model on training data\\nXGB_gbtree2_tuned.fit(X_train, y_train)\";\n",
       "                var nbb_formatted_code = \"# Building model with best parameters\\nXGB_gbtree2_tuned = XGBRegressor(\\n    booster=\\\"gbtree\\\",\\n    random_state=42,\\n    colsample_bytree=0.6861223846483286,\\n    gamma=0.22153944050588595,\\n    learning_rate=0.10165663513708073,\\n    max_depth=5,\\n    n_estimators=180,\\n    subsample=0.74226839054973,\\n)\\n\\n# Fit the model on training data\\nXGB_gbtree2_tuned.fit(X_train, y_train)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Building model with best parameters\n",
    "XGB_gbtree2_tuned = XGBRegressor(\n",
    "    booster=\"gbtree\",\n",
    "    random_state=42,\n",
    "    colsample_bytree=0.6861223846483286,\n",
    "    gamma=0.22153944050588595,\n",
    "    learning_rate=0.10165663513708073,\n",
    "    max_depth=5,\n",
    "    n_estimators=180,\n",
    "    subsample=0.74226839054973,\n",
    ")\n",
    "\n",
    "# Fit the model on training data\n",
    "XGB_gbtree2_tuned.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3c4bbcb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training performance:\n",
      "         RMSE        MAE  R-squared  Adj. R-squared       MAPE\n",
      "0  14.596533  11.326033   0.152859        0.152329  18.630614\n",
      "\n",
      "Validation performance:\n",
      "         RMSE        MAE  R-squared  Adj. R-squared       MAPE\n",
      "0  14.867475  11.517005   0.110095        0.108794  18.881056\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 60;\n",
       "                var nbb_unformatted_code = \"# Calculating different metrics\\nXGB_gbtree2_tuned_train_perf = model_performance_regression(\\n    XGB_gbtree2_tuned, X_train, y_train\\n)\\nprint(\\\"Training performance:\\\\n\\\", XGB_gbtree2_tuned_train_perf)\\nXGB_gbtree2_tuned_val_perf = model_performance_regression(\\n    XGB_gbtree2_tuned, X_val, y_val\\n)\\nprint(\\\"\\\\nValidation performance:\\\\n\\\", XGB_gbtree2_tuned_val_perf)\\n\\n# Adding model to model comparison dataframes\\nmodels_train_comp_df[\\\"XGB_gbtree2 Tuned\\\"] = XGB_gbtree2_tuned_train_perf.T\\nmodels_val_comp_df[\\\"XGB_gbtree2 Tuned\\\"] = XGB_gbtree2_tuned_val_perf.T\";\n",
       "                var nbb_formatted_code = \"# Calculating different metrics\\nXGB_gbtree2_tuned_train_perf = model_performance_regression(\\n    XGB_gbtree2_tuned, X_train, y_train\\n)\\nprint(\\\"Training performance:\\\\n\\\", XGB_gbtree2_tuned_train_perf)\\nXGB_gbtree2_tuned_val_perf = model_performance_regression(\\n    XGB_gbtree2_tuned, X_val, y_val\\n)\\nprint(\\\"\\\\nValidation performance:\\\\n\\\", XGB_gbtree2_tuned_val_perf)\\n\\n# Adding model to model comparison dataframes\\nmodels_train_comp_df[\\\"XGB_gbtree2 Tuned\\\"] = XGB_gbtree2_tuned_train_perf.T\\nmodels_val_comp_df[\\\"XGB_gbtree2 Tuned\\\"] = XGB_gbtree2_tuned_val_perf.T\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculating different metrics\n",
    "XGB_gbtree2_tuned_train_perf = model_performance_regression(\n",
    "    XGB_gbtree2_tuned, X_train, y_train\n",
    ")\n",
    "print(\"Training performance:\\n\", XGB_gbtree2_tuned_train_perf)\n",
    "XGB_gbtree2_tuned_val_perf = model_performance_regression(\n",
    "    XGB_gbtree2_tuned, X_val, y_val\n",
    ")\n",
    "print(\"\\nValidation performance:\\n\", XGB_gbtree2_tuned_val_perf)\n",
    "\n",
    "# Adding model to model comparison dataframes\n",
    "models_train_comp_df[\"XGB_gbtree2 Tuned\"] = XGB_gbtree2_tuned_train_perf.T\n",
    "models_val_comp_df[\"XGB_gbtree2 Tuned\"] = XGB_gbtree2_tuned_val_perf.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b65f6e3",
   "metadata": {},
   "source": [
    "#### Observations:\n",
    "- The performance for *XGB_gbtree2* is improved with hyperparameter tuning.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150d6c55",
   "metadata": {},
   "source": [
    "### *XGB_gblinear2 Tuned*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "283c6ebe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gblinear', callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, gamma=None, gpu_id=-1,\n",
       "             grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.5, max_bin=None,\n",
       "             max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "             max_leaves=None, min_child_weight=None, missing=nan,\n",
       "             monotone_constraints=None, n_estimators=100, n_jobs=0,\n",
       "             num_parallel_tree=None, predictor=None, random_state=42,\n",
       "             reg_alpha=0, reg_lambda=0, ...)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 55;\n",
       "                var nbb_unformatted_code = \"# Confirming the model\\nmodels_to_tune[\\\"XGB_gblinear2\\\"]\";\n",
       "                var nbb_formatted_code = \"# Confirming the model\\nmodels_to_tune[\\\"XGB_gblinear2\\\"]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Confirming the model\n",
    "models_to_tune[\"XGB_gblinear2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8ceb7df9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters are {'n_estimators': 439, 'reg_lambda': 0.0009206654892274761} with CV score=0.09239924785728368:\n",
      "CPU times: total: 38.5 s\n",
      "Wall time: 5min 52s\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 56;\n",
       "                var nbb_unformatted_code = \"%%time\\n\\n# Defining model\\nModel = XGBRegressor(random_state=42, booster='gblinear')\\n\\n# Parameter grid to pass in RandomizedSearchCV\\nparam_grid={\\n    'n_estimators': np.arange(100, 500),\\n    'reg_lambda': loguniform(.0001, 1)\\n}\\n\\n# Calling RandomizedSearchCV\\nrandomized_cv = RandomizedSearchCV(\\n    estimator=Model,\\n    param_distributions=param_grid,\\n    n_iter=100,\\n    n_jobs=-1,\\n    scoring=scorer,\\n    cv=5,\\n    random_state=42,\\n)\\n\\n# Fitting parameters in RandomizedSearchCV\\nrandomized_cv.fit(X_train, y_train)\\n\\nprint(\\n    \\\"Best parameters are {} with CV score={}:\\\".format(\\n        randomized_cv.best_params_, randomized_cv.best_score_\\n    )\\n)\\n\\n# Chime notification when cell successfully executes\\nchime.success()\";\n",
       "                var nbb_formatted_code = \"%%time\\n\\n# Defining model\\nModel = XGBRegressor(random_state=42, booster='gblinear')\\n\\n# Parameter grid to pass in RandomizedSearchCV\\nparam_grid={\\n    'n_estimators': np.arange(100, 500),\\n    'reg_lambda': loguniform(.0001, 1)\\n}\\n\\n# Calling RandomizedSearchCV\\nrandomized_cv = RandomizedSearchCV(\\n    estimator=Model,\\n    param_distributions=param_grid,\\n    n_iter=100,\\n    n_jobs=-1,\\n    scoring=scorer,\\n    cv=5,\\n    random_state=42,\\n)\\n\\n# Fitting parameters in RandomizedSearchCV\\nrandomized_cv.fit(X_train, y_train)\\n\\nprint(\\n    \\\"Best parameters are {} with CV score={}:\\\".format(\\n        randomized_cv.best_params_, randomized_cv.best_score_\\n    )\\n)\\n\\n# Chime notification when cell successfully executes\\nchime.success()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Defining model\n",
    "Model = XGBRegressor(random_state=42, booster='gblinear')\n",
    "\n",
    "# Parameter grid to pass in RandomizedSearchCV\n",
    "param_grid={\n",
    "    'n_estimators': np.arange(100, 500),\n",
    "    'reg_lambda': loguniform(.0001, 1)\n",
    "}\n",
    "\n",
    "# Calling RandomizedSearchCV\n",
    "randomized_cv = RandomizedSearchCV(\n",
    "    estimator=Model,\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=100,\n",
    "    n_jobs=-1,\n",
    "    scoring=scorer,\n",
    "    cv=5,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "# Fitting parameters in RandomizedSearchCV\n",
    "randomized_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\n",
    "    \"Best parameters are {} with CV score={}:\".format(\n",
    "        randomized_cv.best_params_, randomized_cv.best_score_\n",
    "    )\n",
    ")\n",
    "\n",
    "# Chime notification when cell successfully executes\n",
    "chime.success()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "19ae25e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gblinear', callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, gamma=None, gpu_id=-1,\n",
       "             grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.5, max_bin=None,\n",
       "             max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "             max_leaves=None, min_child_weight=None, missing=nan,\n",
       "             monotone_constraints=None, n_estimators=439, n_jobs=0,\n",
       "             num_parallel_tree=None, predictor=None, random_state=42,\n",
       "             reg_alpha=0, reg_lambda=0.0009206654892274761, ...)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 57;\n",
       "                var nbb_unformatted_code = \"# Building model with best parameters\\nXGB_gblinear2_tuned = XGBRegressor(\\n    booster=\\\"gblinear\\\",\\n    random_state=42,\\n    n_estimators=439,\\n    reg_lambda=0.0009206654892274761,\\n)\\n\\n# Fit the model on training data\\nXGB_gblinear2_tuned.fit(X_train, y_train)\";\n",
       "                var nbb_formatted_code = \"# Building model with best parameters\\nXGB_gblinear2_tuned = XGBRegressor(\\n    booster=\\\"gblinear\\\",\\n    random_state=42,\\n    n_estimators=439,\\n    reg_lambda=0.0009206654892274761,\\n)\\n\\n# Fit the model on training data\\nXGB_gblinear2_tuned.fit(X_train, y_train)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Building model with best parameters\n",
    "XGB_gblinear2_tuned = XGBRegressor(\n",
    "    booster=\"gblinear\",\n",
    "    random_state=42,\n",
    "    n_estimators=439,\n",
    "    reg_lambda=0.0009206654892274761,\n",
    ")\n",
    "\n",
    "# Fit the model on training data\n",
    "XGB_gblinear2_tuned.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "45ab8538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training performance:\n",
      "         RMSE        MAE  R-squared  Adj. R-squared       MAPE\n",
      "0  15.100237  11.725048   0.093383        0.092816  19.392028\n",
      "\n",
      "Validation performance:\n",
      "         RMSE        MAE  R-squared  Adj. R-squared       MAPE\n",
      "0  15.007769  11.640587   0.093221        0.091895  19.169206\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 58;\n",
       "                var nbb_unformatted_code = \"# Calculating different metrics\\nXGB_gblinear2_tuned_train_perf = model_performance_regression(\\n    XGB_gblinear2_tuned, X_train, y_train\\n)\\nprint(\\\"Training performance:\\\\n\\\", XGB_gblinear2_tuned_train_perf)\\nXGB_gblinear2_tuned_val_perf = model_performance_regression(\\n    XGB_gblinear2_tuned, X_val, y_val\\n)\\nprint(\\\"\\\\nValidation performance:\\\\n\\\", XGB_gblinear2_tuned_val_perf)\\n\\n# Adding model to model comparison dataframes\\nmodels_train_comp_df[\\\"XGB_gblinear2 Tuned\\\"] = XGB_gblinear2_tuned_train_perf.T\\nmodels_val_comp_df[\\\"XGB_gblinear2 Tuned\\\"] = XGB_gblinear2_tuned_val_perf.T\";\n",
       "                var nbb_formatted_code = \"# Calculating different metrics\\nXGB_gblinear2_tuned_train_perf = model_performance_regression(\\n    XGB_gblinear2_tuned, X_train, y_train\\n)\\nprint(\\\"Training performance:\\\\n\\\", XGB_gblinear2_tuned_train_perf)\\nXGB_gblinear2_tuned_val_perf = model_performance_regression(\\n    XGB_gblinear2_tuned, X_val, y_val\\n)\\nprint(\\\"\\\\nValidation performance:\\\\n\\\", XGB_gblinear2_tuned_val_perf)\\n\\n# Adding model to model comparison dataframes\\nmodels_train_comp_df[\\\"XGB_gblinear2 Tuned\\\"] = XGB_gblinear2_tuned_train_perf.T\\nmodels_val_comp_df[\\\"XGB_gblinear2 Tuned\\\"] = XGB_gblinear2_tuned_val_perf.T\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculating different metrics\n",
    "XGB_gblinear2_tuned_train_perf = model_performance_regression(\n",
    "    XGB_gblinear2_tuned, X_train, y_train\n",
    ")\n",
    "print(\"Training performance:\\n\", XGB_gblinear2_tuned_train_perf)\n",
    "XGB_gblinear2_tuned_val_perf = model_performance_regression(\n",
    "    XGB_gblinear2_tuned, X_val, y_val\n",
    ")\n",
    "print(\"\\nValidation performance:\\n\", XGB_gblinear2_tuned_val_perf)\n",
    "\n",
    "# Adding model to model comparison dataframes\n",
    "models_train_comp_df[\"XGB_gblinear2 Tuned\"] = XGB_gblinear2_tuned_train_perf.T\n",
    "models_val_comp_df[\"XGB_gblinear2 Tuned\"] = XGB_gblinear2_tuned_val_perf.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef992f89",
   "metadata": {},
   "source": [
    "#### Observations:\n",
    "- The performance of *XGB_gblinear1* is improved with hyperparameter tuning.\n",
    "- Let us compare the performance of this iteration's models before and after hyperparameter tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce915567",
   "metadata": {},
   "source": [
    "## Model Performance Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd758c1",
   "metadata": {},
   "source": [
    "### Performance of Various Models Tuned and Untuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "53f2ff81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Performance Comparison:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GBM2</th>\n",
       "      <th>GBM2 Tuned</th>\n",
       "      <th>Random Forest2</th>\n",
       "      <th>Random Forest2 Tuned</th>\n",
       "      <th>XGB_gblinear2</th>\n",
       "      <th>XGB_gblinear2 Tuned</th>\n",
       "      <th>XGB_gbtree2</th>\n",
       "      <th>XGB_gbtree2 Tuned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>14.937480</td>\n",
       "      <td>14.803396</td>\n",
       "      <td>11.328976</td>\n",
       "      <td>14.496677</td>\n",
       "      <td>15.129788</td>\n",
       "      <td>15.100237</td>\n",
       "      <td>14.196740</td>\n",
       "      <td>14.596533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>11.599899</td>\n",
       "      <td>11.490370</td>\n",
       "      <td>8.362030</td>\n",
       "      <td>11.259928</td>\n",
       "      <td>11.741532</td>\n",
       "      <td>11.725048</td>\n",
       "      <td>10.984573</td>\n",
       "      <td>11.326033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-squared</th>\n",
       "      <td>0.112822</td>\n",
       "      <td>0.128678</td>\n",
       "      <td>0.489686</td>\n",
       "      <td>0.164410</td>\n",
       "      <td>0.089831</td>\n",
       "      <td>0.093383</td>\n",
       "      <td>0.198629</td>\n",
       "      <td>0.152859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Adj. R-squared</th>\n",
       "      <td>0.112266</td>\n",
       "      <td>0.128132</td>\n",
       "      <td>0.489367</td>\n",
       "      <td>0.163887</td>\n",
       "      <td>0.089262</td>\n",
       "      <td>0.092816</td>\n",
       "      <td>0.198128</td>\n",
       "      <td>0.152329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAPE</th>\n",
       "      <td>19.178492</td>\n",
       "      <td>18.950940</td>\n",
       "      <td>13.404005</td>\n",
       "      <td>18.615087</td>\n",
       "      <td>19.384426</td>\n",
       "      <td>19.392028</td>\n",
       "      <td>17.982195</td>\n",
       "      <td>18.630614</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     GBM2  GBM2 Tuned  Random Forest2  Random Forest2 Tuned  \\\n",
       "RMSE            14.937480   14.803396       11.328976             14.496677   \n",
       "MAE             11.599899   11.490370        8.362030             11.259928   \n",
       "R-squared        0.112822    0.128678        0.489686              0.164410   \n",
       "Adj. R-squared   0.112266    0.128132        0.489367              0.163887   \n",
       "MAPE            19.178492   18.950940       13.404005             18.615087   \n",
       "\n",
       "                XGB_gblinear2  XGB_gblinear2 Tuned  XGB_gbtree2  \\\n",
       "RMSE                15.129788            15.100237    14.196740   \n",
       "MAE                 11.741532            11.725048    10.984573   \n",
       "R-squared            0.089831             0.093383     0.198629   \n",
       "Adj. R-squared       0.089262             0.092816     0.198128   \n",
       "MAPE                19.384426            19.392028    17.982195   \n",
       "\n",
       "                XGB_gbtree2 Tuned  \n",
       "RMSE                    14.596533  \n",
       "MAE                     11.326033  \n",
       "R-squared                0.152859  \n",
       "Adj. R-squared           0.152329  \n",
       "MAPE                    18.630614  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 63;\n",
       "                var nbb_unformatted_code = \"# Displaying train performance of all models\\nprint(\\\"Train Performance Comparison:\\\")\\ncols = [column for column in models_train_comp_df.columns if \\\"2\\\" in column]\\nmodels_train_comp_df[cols].sort_index(axis=1)\";\n",
       "                var nbb_formatted_code = \"# Displaying train performance of all models\\nprint(\\\"Train Performance Comparison:\\\")\\ncols = [column for column in models_train_comp_df.columns if \\\"2\\\" in column]\\nmodels_train_comp_df[cols].sort_index(axis=1)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Displaying train performance of all models\n",
    "print(\"Train Performance Comparison:\")\n",
    "cols = [column for column in models_train_comp_df.columns if \"2\" in column]\n",
    "models_train_comp_df[cols].sort_index(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ad87ba49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Performance Comparison:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GBM2</th>\n",
       "      <th>GBM2 Tuned</th>\n",
       "      <th>Random Forest2</th>\n",
       "      <th>Random Forest2 Tuned</th>\n",
       "      <th>XGB_gblinear2</th>\n",
       "      <th>XGB_gblinear2 Tuned</th>\n",
       "      <th>XGB_gbtree2</th>\n",
       "      <th>XGB_gbtree2 Tuned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>14.894124</td>\n",
       "      <td>14.853802</td>\n",
       "      <td>16.206121</td>\n",
       "      <td>14.901352</td>\n",
       "      <td>15.026240</td>\n",
       "      <td>15.007769</td>\n",
       "      <td>14.973004</td>\n",
       "      <td>14.867475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>11.552854</td>\n",
       "      <td>11.512155</td>\n",
       "      <td>12.476262</td>\n",
       "      <td>11.555613</td>\n",
       "      <td>11.654621</td>\n",
       "      <td>11.640587</td>\n",
       "      <td>11.582826</td>\n",
       "      <td>11.517005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-squared</th>\n",
       "      <td>0.106902</td>\n",
       "      <td>0.111731</td>\n",
       "      <td>-0.057371</td>\n",
       "      <td>0.106035</td>\n",
       "      <td>0.090987</td>\n",
       "      <td>0.093221</td>\n",
       "      <td>0.097417</td>\n",
       "      <td>0.110095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Adj. R-squared</th>\n",
       "      <td>0.105596</td>\n",
       "      <td>0.110432</td>\n",
       "      <td>-0.058917</td>\n",
       "      <td>0.104727</td>\n",
       "      <td>0.089658</td>\n",
       "      <td>0.091895</td>\n",
       "      <td>0.096097</td>\n",
       "      <td>0.108794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAPE</th>\n",
       "      <td>19.011210</td>\n",
       "      <td>18.898856</td>\n",
       "      <td>20.071146</td>\n",
       "      <td>19.015297</td>\n",
       "      <td>19.158441</td>\n",
       "      <td>19.169206</td>\n",
       "      <td>18.941080</td>\n",
       "      <td>18.881056</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     GBM2  GBM2 Tuned  Random Forest2  Random Forest2 Tuned  \\\n",
       "RMSE            14.894124   14.853802       16.206121             14.901352   \n",
       "MAE             11.552854   11.512155       12.476262             11.555613   \n",
       "R-squared        0.106902    0.111731       -0.057371              0.106035   \n",
       "Adj. R-squared   0.105596    0.110432       -0.058917              0.104727   \n",
       "MAPE            19.011210   18.898856       20.071146             19.015297   \n",
       "\n",
       "                XGB_gblinear2  XGB_gblinear2 Tuned  XGB_gbtree2  \\\n",
       "RMSE                15.026240            15.007769    14.973004   \n",
       "MAE                 11.654621            11.640587    11.582826   \n",
       "R-squared            0.090987             0.093221     0.097417   \n",
       "Adj. R-squared       0.089658             0.091895     0.096097   \n",
       "MAPE                19.158441            19.169206    18.941080   \n",
       "\n",
       "                XGB_gbtree2 Tuned  \n",
       "RMSE                    14.867475  \n",
       "MAE                     11.517005  \n",
       "R-squared                0.110095  \n",
       "Adj. R-squared           0.108794  \n",
       "MAPE                    18.881056  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 64;\n",
       "                var nbb_unformatted_code = \"# Displaying validation performance of all models\\nprint(\\\"Validation Performance Comparison:\\\")\\nmodels_val_comp_df[cols].sort_index(axis=1)\";\n",
       "                var nbb_formatted_code = \"# Displaying validation performance of all models\\nprint(\\\"Validation Performance Comparison:\\\")\\nmodels_val_comp_df[cols].sort_index(axis=1)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Displaying validation performance of all models\n",
    "print(\"Validation Performance Comparison:\")\n",
    "models_val_comp_df[cols].sort_index(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff0499f5",
   "metadata": {},
   "source": [
    "#### Observations:\n",
    "- We see improvement across the board with hyperparameter tuning.  Even *Random Forest2** improved enough to be a contender.\n",
    "- Let us narrow down the model contenders to those with validation R$^2$ scores of at least 0.10, from both modeling iterations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "099b7c64",
   "metadata": {},
   "source": [
    "### Performance of Contender Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b8aa7622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Performance Comparison:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GBM</th>\n",
       "      <th>GBM Tuned</th>\n",
       "      <th>GBM2</th>\n",
       "      <th>GBM2 Tuned</th>\n",
       "      <th>Random Forest2 Tuned</th>\n",
       "      <th>XGB_gbtree Tuned</th>\n",
       "      <th>XGB_gbtree2 Tuned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>14.971421</td>\n",
       "      <td>14.835035</td>\n",
       "      <td>14.937480</td>\n",
       "      <td>14.803396</td>\n",
       "      <td>14.496677</td>\n",
       "      <td>14.813429</td>\n",
       "      <td>14.596533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>11.627512</td>\n",
       "      <td>11.521845</td>\n",
       "      <td>11.599899</td>\n",
       "      <td>11.490370</td>\n",
       "      <td>11.259928</td>\n",
       "      <td>11.504380</td>\n",
       "      <td>11.326033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-squared</th>\n",
       "      <td>0.108786</td>\n",
       "      <td>0.124949</td>\n",
       "      <td>0.112822</td>\n",
       "      <td>0.128678</td>\n",
       "      <td>0.164410</td>\n",
       "      <td>0.127496</td>\n",
       "      <td>0.152859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Adj. R-squared</th>\n",
       "      <td>0.108228</td>\n",
       "      <td>0.124401</td>\n",
       "      <td>0.112266</td>\n",
       "      <td>0.128132</td>\n",
       "      <td>0.163887</td>\n",
       "      <td>0.126950</td>\n",
       "      <td>0.152329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAPE</th>\n",
       "      <td>19.221156</td>\n",
       "      <td>18.989296</td>\n",
       "      <td>19.178492</td>\n",
       "      <td>18.950940</td>\n",
       "      <td>18.615087</td>\n",
       "      <td>18.953973</td>\n",
       "      <td>18.630614</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      GBM  GBM Tuned       GBM2  GBM2 Tuned  \\\n",
       "RMSE            14.971421  14.835035  14.937480   14.803396   \n",
       "MAE             11.627512  11.521845  11.599899   11.490370   \n",
       "R-squared        0.108786   0.124949   0.112822    0.128678   \n",
       "Adj. R-squared   0.108228   0.124401   0.112266    0.128132   \n",
       "MAPE            19.221156  18.989296  19.178492   18.950940   \n",
       "\n",
       "                Random Forest2 Tuned  XGB_gbtree Tuned  XGB_gbtree2 Tuned  \n",
       "RMSE                       14.496677         14.813429          14.596533  \n",
       "MAE                        11.259928         11.504380          11.326033  \n",
       "R-squared                   0.164410          0.127496           0.152859  \n",
       "Adj. R-squared              0.163887          0.126950           0.152329  \n",
       "MAPE                       18.615087         18.953973          18.630614  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 65;\n",
       "                var nbb_unformatted_code = \"# Displaying train performance of all models\\nprint(\\\"Train Performance Comparison:\\\")\\ncols = [column for column in models_train_comp_df.columns if models_val_comp_df.loc['R-squared', column]>=0.10]\\nmodels_train_comp_df[cols].sort_index(axis=1)\";\n",
       "                var nbb_formatted_code = \"# Displaying train performance of all models\\nprint(\\\"Train Performance Comparison:\\\")\\ncols = [\\n    column\\n    for column in models_train_comp_df.columns\\n    if models_val_comp_df.loc[\\\"R-squared\\\", column] >= 0.10\\n]\\nmodels_train_comp_df[cols].sort_index(axis=1)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Displaying train performance of all models\n",
    "print(\"Train Performance Comparison:\")\n",
    "cols = [\n",
    "    column\n",
    "    for column in models_train_comp_df.columns\n",
    "    if models_val_comp_df.loc[\"R-squared\", column] >= 0.10\n",
    "]\n",
    "models_train_comp_df[cols].sort_index(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7767a6b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Performance Comparison:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GBM</th>\n",
       "      <th>GBM Tuned</th>\n",
       "      <th>GBM2</th>\n",
       "      <th>GBM2 Tuned</th>\n",
       "      <th>Random Forest2 Tuned</th>\n",
       "      <th>XGB_gbtree Tuned</th>\n",
       "      <th>XGB_gbtree2 Tuned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>14.922006</td>\n",
       "      <td>14.877704</td>\n",
       "      <td>14.894124</td>\n",
       "      <td>14.853802</td>\n",
       "      <td>14.901352</td>\n",
       "      <td>14.882834</td>\n",
       "      <td>14.867475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>11.580272</td>\n",
       "      <td>11.542386</td>\n",
       "      <td>11.552854</td>\n",
       "      <td>11.512155</td>\n",
       "      <td>11.555613</td>\n",
       "      <td>11.546377</td>\n",
       "      <td>11.517005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-squared</th>\n",
       "      <td>0.103555</td>\n",
       "      <td>0.108870</td>\n",
       "      <td>0.106902</td>\n",
       "      <td>0.111731</td>\n",
       "      <td>0.106035</td>\n",
       "      <td>0.108255</td>\n",
       "      <td>0.110095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Adj. R-squared</th>\n",
       "      <td>0.102244</td>\n",
       "      <td>0.107567</td>\n",
       "      <td>0.105596</td>\n",
       "      <td>0.110432</td>\n",
       "      <td>0.104727</td>\n",
       "      <td>0.106951</td>\n",
       "      <td>0.108794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAPE</th>\n",
       "      <td>19.051063</td>\n",
       "      <td>18.937928</td>\n",
       "      <td>19.011210</td>\n",
       "      <td>18.898856</td>\n",
       "      <td>19.015297</td>\n",
       "      <td>18.931955</td>\n",
       "      <td>18.881056</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      GBM  GBM Tuned       GBM2  GBM2 Tuned  \\\n",
       "RMSE            14.922006  14.877704  14.894124   14.853802   \n",
       "MAE             11.580272  11.542386  11.552854   11.512155   \n",
       "R-squared        0.103555   0.108870   0.106902    0.111731   \n",
       "Adj. R-squared   0.102244   0.107567   0.105596    0.110432   \n",
       "MAPE            19.051063  18.937928  19.011210   18.898856   \n",
       "\n",
       "                Random Forest2 Tuned  XGB_gbtree Tuned  XGB_gbtree2 Tuned  \n",
       "RMSE                       14.901352         14.882834          14.867475  \n",
       "MAE                        11.555613         11.546377          11.517005  \n",
       "R-squared                   0.106035          0.108255           0.110095  \n",
       "Adj. R-squared              0.104727          0.106951           0.108794  \n",
       "MAPE                       19.015297         18.931955          18.881056  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 66;\n",
       "                var nbb_unformatted_code = \"# Displaying validation performance of all models\\nprint(\\\"Validation Performance Comparison:\\\")\\nmodels_val_comp_df[cols].sort_index(axis=1)\";\n",
       "                var nbb_formatted_code = \"# Displaying validation performance of all models\\nprint(\\\"Validation Performance Comparison:\\\")\\nmodels_val_comp_df[cols].sort_index(axis=1)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Displaying validation performance of all models\n",
    "print(\"Validation Performance Comparison:\")\n",
    "models_val_comp_df[cols].sort_index(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c27f686",
   "metadata": {},
   "source": [
    "#### Observations:\n",
    "- *GBM* and *GBM Tuned* has one additional feature than the other models, after one hot encoding.  Therefore Ajusted $R^2$ is more relevant here comparing those two models with the others, than previously.\n",
    "- Regardless, the top models are the same for R$^2$ and Adjusted R$^2$, *GBM2 Tuned*, followed by *XGB_gtree2 Tuned*, then *GBM Tuned*.\n",
    "- Using the original `known for` category columns instead of `known_for`, with the inclusion of `num_categories`, brought the validation R$^2$ scores over 0.11 for two of the models.\n",
    "- There is some variation in overfitting between the contender models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff59cc71",
   "metadata": {},
   "source": [
    "#### Comparison of Percentage of Overfit for R$^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8c576bcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of R-square overfit:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GBM                      4.808487\n",
       "GBM2                     5.247422\n",
       "GBM Tuned               12.868707\n",
       "GBM2 Tuned              13.170000\n",
       "XGB_gbtree Tuned        15.091493\n",
       "XGB_gbtree2 Tuned       27.976393\n",
       "Random Forest2 Tuned    35.506112\n",
       "Name: R-squared, dtype: float64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 69;\n",
       "                var nbb_unformatted_code = \"# Subtracting the ratio of validation R-square/train R-square from 1\\noverfit_perc = (\\n    1\\n    - (\\n        models_val_comp_df[cols].loc[\\\"R-squared\\\", :]\\n        / models_train_comp_df[cols].loc[\\\"R-squared\\\", :]\\n    )\\n) * 100\\n\\nprint(f\\\"Percentage of R-square overfit:\\\")\\noverfit_perc.sort_values()\";\n",
       "                var nbb_formatted_code = \"# Subtracting the ratio of validation R-square/train R-square from 1\\noverfit_perc = (\\n    1\\n    - (\\n        models_val_comp_df[cols].loc[\\\"R-squared\\\", :]\\n        / models_train_comp_df[cols].loc[\\\"R-squared\\\", :]\\n    )\\n) * 100\\n\\nprint(f\\\"Percentage of R-square overfit:\\\")\\noverfit_perc.sort_values()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Subtracting the ratio of validation R-square/train R-square from 1\n",
    "overfit_perc = (\n",
    "    1\n",
    "    - (\n",
    "        models_val_comp_df[cols].loc[\"R-squared\", :]\n",
    "        / models_train_comp_df[cols].loc[\"R-squared\", :]\n",
    "    )\n",
    ") * 100\n",
    "\n",
    "print(f\"Percentage of R-square overfit:\")\n",
    "overfit_perc.sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c347e38b",
   "metadata": {},
   "source": [
    "#### Observations:\n",
    "- Of the top 3 models for R$^2$ score, *GBM2* generalized considerably better than *GBM2 Tuned* and *XGB_gtree Tuned*.  \n",
    "- That said, *GBM2 Tuned* has the highest R$^2$ score on the validation set.\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3195e171",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67fac016",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1cd0c82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26fd544",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42adfacf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b825f7ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c14ccbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85f8094",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a09adf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78a38ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b176c9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb43ad2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff1c6f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29cd878",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1a1fd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de521a9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d950457d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd237ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6a9b5162",
   "metadata": {},
   "source": [
    "### *GBM2 Tuned* Performance on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8e3bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking performance of champion model on test set\n",
    "GBM2_tuned_test_perf = model_performance_regression(GBM2_tuned, X_test, y_test)\n",
    "print(\"Test performance:\\n\", GBM2_tuned_test_perf)\n",
    "\n",
    "# Creating test and train performance df\n",
    "champion_df = pd.DataFrame()\n",
    "champion_df[\"GBM2 Tuned Train\"] = GBM2_tuned_train_perf.T\n",
    "champion_df[\"GBM2 Tuned Test\"] = GBM2_tuned_test_perf.T\n",
    "champion_df[\"Overfit Percentage\"] = (\n",
    "    1 - (champion_df[\"GBM2 Tuned Test\"] / champion_df[\"GBM2 Tuned Train\"])\n",
    ") * 100\n",
    "champion_df.drop(\"Adj. R-squared\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8496606",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance on train and test sets\n",
    "print(\n",
    "    f'Average overfit of the 4 metrics is {np.round(champion_df[\"Overfit Percentage\"].sum()/4, 2)}%.'\n",
    ")\n",
    "champion_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32efcd3",
   "metadata": {},
   "source": [
    "#### Observations:\n",
    "- *GBM Tuned*'s performance is holding up on the unseen test data.\n",
    "- We have a model that explains 10.7% of the variation in life span of notable Wikipedia individuals, who meet inclusion criteria.\n",
    "- The model predicts life expectancy within average errors of 11.5 years and 18.8%.\n",
    "- Let us check the most important predictive features of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9154ab0",
   "metadata": {},
   "source": [
    "### Feature Importance of *GBM Tuned*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3873454",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting feature importances of final model\n",
    "feature_names = X_train.columns\n",
    "importances = GBM_tuned.feature_importances_\n",
    "indices = np.argsort(importances)\n",
    "\n",
    "plt.figure(figsize=(12, 12))\n",
    "plt.title(\"Feature Importances\")\n",
    "plt.barh(range(len(indices)), importances[indices], color=\"violet\", align=\"center\")\n",
    "plt.yticks(range(len(indices)), [feature_names[i] for i in indices])\n",
    "plt.xlabel(\"Relative Importance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24bdf4d7",
   "metadata": {},
   "source": [
    "#### Observations:\n",
    "- Before deciding on a champion model, we will try another very similar approach.\n",
    "- Instead of using the extracted feature `known_for`, that grouped entries with multiple `known for` categories, we will let the original features stand.  This approach would not have worked for the basic linear regression model, because we had to drop columns to avoid multicollinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36c0663",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Complete\")\n",
    "\n",
    "# Chime notification when cell executes\n",
    "chime.success()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11aacfcc",
   "metadata": {},
   "source": [
    "# [Proceed to Data Cleaning Part ]()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
