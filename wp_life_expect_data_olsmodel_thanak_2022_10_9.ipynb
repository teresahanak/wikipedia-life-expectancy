{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "316a0779",
   "metadata": {},
   "source": [
    "# Wikipedia Notable Life Expectancies\n",
    "# [Notebook 11: Basic Linear Regression Model ](https://github.com/teresahanak/wikipedia-life-expectancy/blob/main/wp_life_expect_data_modeling_thanak_2022_10_9.ipynb)\n",
    "### Context\n",
    "\n",
    "The\n",
    "### Objective\n",
    "\n",
    "The\n",
    "### Data Dictionary\n",
    "- Feature: Description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99245d51",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "453bba83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1;\n",
       "                var nbb_unformatted_code = \"# To structure code automatically\\n%load_ext nb_black\\n\\n# To import/export sqlite databases\\n# import sqlite3 as sql\\n\\n# To save/open python objects in pickle file\\nimport pickle\\n\\n# To help with reading, cleaning, and manipulating data\\nimport pandas as pd\\nimport numpy as np\\n\\n# To help with data visualization\\nimport matplotlib.pyplot as plt\\nimport seaborn as sns\\n\\n# randomized data splitting\\nfrom sklearn.model_selection import train_test_split\\n\\n# building regression model\\nimport statsmodels.api as sm\\n\\n# check model performance\\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\\n\\n# check linear regression assumptions\\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\\nimport pylab\\nimport scipy.stats as stats\\nimport statsmodels.stats.api as sms\\nfrom statsmodels.compat import lzip\\n\\n# to compare fit between models\\nfrom scipy.stats.distributions import chi2\\n\\n# To define maximum number of columns to be displayed in a dataframe\\npd.set_option(\\\"display.max_columns\\\", None)\\n# To define the maximum number of rows to be displayed in a dataframe\\npd.set_option(\\\"display.max_rows\\\", 211)\\n\\n# To set some dataframe visualization attributes\\npd.set_option(\\\"max_colwidth\\\", 150)\\n\\n# To supress scientific notations for a dataframe\\n# pd.set_option(\\\"display.float_format\\\", lambda x: \\\"%.3f\\\" % x)\\n\\n# To supress warnings\\n# import warnings\\n\\n# warnings.filterwarnings(\\\"ignore\\\")\\n\\n# To set some plot visualization attributes\\nsns.set_theme()\\nsns.set(font_scale=1.4)\\nsns.set_palette(\\n    (\\n        \\\"midnightblue\\\",\\n        \\\"goldenrod\\\",\\n        \\\"maroon\\\",\\n        \\\"darkolivegreen\\\",\\n        \\\"cadetblue\\\",\\n        \\\"tab:purple\\\",\\n        \\\"yellowgreen\\\",\\n    )\\n)\\n# plt.rc(\\\"font\\\", size=12)\\n# plt.rc(\\\"axes\\\", titlesize=15)\\n# plt.rc(\\\"axes\\\", labelsize=14)\\n# plt.rc(\\\"xtick\\\", labelsize=13)\\n# plt.rc(\\\"ytick\\\", labelsize=13)\\n# plt.rc(\\\"legend\\\", fontsize=13)\\n# plt.rc(\\\"legend\\\", fontsize=14)\\n# plt.rc(\\\"figure\\\", titlesize=16)\\n\\n# To play auditory cue when cell has executed, has warning, or has error and set chime theme\\nimport chime\\n\\nchime.theme(\\\"zelda\\\")\";\n",
       "                var nbb_formatted_code = \"# To structure code automatically\\n%load_ext nb_black\\n\\n# To import/export sqlite databases\\n# import sqlite3 as sql\\n\\n# To save/open python objects in pickle file\\nimport pickle\\n\\n# To help with reading, cleaning, and manipulating data\\nimport pandas as pd\\nimport numpy as np\\n\\n# To help with data visualization\\nimport matplotlib.pyplot as plt\\nimport seaborn as sns\\n\\n# randomized data splitting\\nfrom sklearn.model_selection import train_test_split\\n\\n# building regression model\\nimport statsmodels.api as sm\\n\\n# check model performance\\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\\n\\n# check linear regression assumptions\\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\\nimport pylab\\nimport scipy.stats as stats\\nimport statsmodels.stats.api as sms\\nfrom statsmodels.compat import lzip\\n\\n# to compare fit between models\\nfrom scipy.stats.distributions import chi2\\n\\n# To define maximum number of columns to be displayed in a dataframe\\npd.set_option(\\\"display.max_columns\\\", None)\\n# To define the maximum number of rows to be displayed in a dataframe\\npd.set_option(\\\"display.max_rows\\\", 211)\\n\\n# To set some dataframe visualization attributes\\npd.set_option(\\\"max_colwidth\\\", 150)\\n\\n# To supress scientific notations for a dataframe\\n# pd.set_option(\\\"display.float_format\\\", lambda x: \\\"%.3f\\\" % x)\\n\\n# To supress warnings\\n# import warnings\\n\\n# warnings.filterwarnings(\\\"ignore\\\")\\n\\n# To set some plot visualization attributes\\nsns.set_theme()\\nsns.set(font_scale=1.4)\\nsns.set_palette(\\n    (\\n        \\\"midnightblue\\\",\\n        \\\"goldenrod\\\",\\n        \\\"maroon\\\",\\n        \\\"darkolivegreen\\\",\\n        \\\"cadetblue\\\",\\n        \\\"tab:purple\\\",\\n        \\\"yellowgreen\\\",\\n    )\\n)\\n# plt.rc(\\\"font\\\", size=12)\\n# plt.rc(\\\"axes\\\", titlesize=15)\\n# plt.rc(\\\"axes\\\", labelsize=14)\\n# plt.rc(\\\"xtick\\\", labelsize=13)\\n# plt.rc(\\\"ytick\\\", labelsize=13)\\n# plt.rc(\\\"legend\\\", fontsize=13)\\n# plt.rc(\\\"legend\\\", fontsize=14)\\n# plt.rc(\\\"figure\\\", titlesize=16)\\n\\n# To play auditory cue when cell has executed, has warning, or has error and set chime theme\\nimport chime\\n\\nchime.theme(\\\"zelda\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# To structure code automatically\n",
    "%load_ext nb_black\n",
    "\n",
    "# To import/export sqlite databases\n",
    "# import sqlite3 as sql\n",
    "\n",
    "# To save/open python objects in pickle file\n",
    "import pickle\n",
    "\n",
    "# To help with reading, cleaning, and manipulating data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# To help with data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# randomized data splitting\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# building regression model\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# check model performance\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# check linear regression assumptions\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "import pylab\n",
    "import scipy.stats as stats\n",
    "import statsmodels.stats.api as sms\n",
    "from statsmodels.compat import lzip\n",
    "\n",
    "# to compare fit between models\n",
    "from scipy.stats.distributions import chi2\n",
    "\n",
    "# To define maximum number of columns to be displayed in a dataframe\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "# To define the maximum number of rows to be displayed in a dataframe\n",
    "pd.set_option(\"display.max_rows\", 211)\n",
    "\n",
    "# To set some dataframe visualization attributes\n",
    "pd.set_option(\"max_colwidth\", 150)\n",
    "\n",
    "# To supress scientific notations for a dataframe\n",
    "# pd.set_option(\"display.float_format\", lambda x: \"%.3f\" % x)\n",
    "\n",
    "# To supress warnings\n",
    "# import warnings\n",
    "\n",
    "# warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# To set some plot visualization attributes\n",
    "sns.set_theme()\n",
    "sns.set(font_scale=1.4)\n",
    "sns.set_palette(\n",
    "    (\n",
    "        \"midnightblue\",\n",
    "        \"goldenrod\",\n",
    "        \"maroon\",\n",
    "        \"darkolivegreen\",\n",
    "        \"cadetblue\",\n",
    "        \"tab:purple\",\n",
    "        \"yellowgreen\",\n",
    "    )\n",
    ")\n",
    "# plt.rc(\"font\", size=12)\n",
    "# plt.rc(\"axes\", titlesize=15)\n",
    "# plt.rc(\"axes\", labelsize=14)\n",
    "# plt.rc(\"xtick\", labelsize=13)\n",
    "# plt.rc(\"ytick\", labelsize=13)\n",
    "# plt.rc(\"legend\", fontsize=13)\n",
    "# plt.rc(\"legend\", fontsize=14)\n",
    "# plt.rc(\"figure\", titlesize=16)\n",
    "\n",
    "# To play auditory cue when cell has executed, has warning, or has error and set chime theme\n",
    "import chime\n",
    "\n",
    "chime.theme(\"zelda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc818a82",
   "metadata": {},
   "source": [
    "## Data Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed005f6",
   "metadata": {},
   "source": [
    "### [Reading](https://github.com/teresahanak/wikipedia-life-expectancy/blob/main/wp_life_expect_preproc.csv), Sampling, and Checking Data Shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ca58a95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 77624 rows and 20 columns.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_references</th>\n",
       "      <th>year</th>\n",
       "      <th>age</th>\n",
       "      <th>sciences</th>\n",
       "      <th>social</th>\n",
       "      <th>spiritual</th>\n",
       "      <th>academia_humanities</th>\n",
       "      <th>business_farming</th>\n",
       "      <th>arts</th>\n",
       "      <th>sports</th>\n",
       "      <th>law_enf_military_operator</th>\n",
       "      <th>politics_govt_law</th>\n",
       "      <th>crime</th>\n",
       "      <th>num_categories</th>\n",
       "      <th>age_sqrd</th>\n",
       "      <th>recip_num_references</th>\n",
       "      <th>years_sqrd</th>\n",
       "      <th>region</th>\n",
       "      <th>prior_region</th>\n",
       "      <th>known_for</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>2002</td>\n",
       "      <td>73.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5329.0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>64</td>\n",
       "      <td>Europe</td>\n",
       "      <td>No Prior Region</td>\n",
       "      <td>spiritual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>2007</td>\n",
       "      <td>90.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>8100.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>169</td>\n",
       "      <td>North America</td>\n",
       "      <td>No Prior Region</td>\n",
       "      <td>two</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_references  year   age  sciences  social  spiritual  \\\n",
       "0               4  2002  73.0         0       0          1   \n",
       "1               3  2007  90.0         1       0          0   \n",
       "\n",
       "   academia_humanities  business_farming  arts  sports  \\\n",
       "0                    0                 0     0       0   \n",
       "1                    1                 0     0       0   \n",
       "\n",
       "   law_enf_military_operator  politics_govt_law  crime  num_categories  \\\n",
       "0                          0                  0      0               1   \n",
       "1                          0                  0      0               2   \n",
       "\n",
       "   age_sqrd  recip_num_references  years_sqrd         region     prior_region  \\\n",
       "0    5329.0              0.250000          64         Europe  No Prior Region   \n",
       "1    8100.0              0.333333         169  North America  No Prior Region   \n",
       "\n",
       "   known_for  \n",
       "0  spiritual  \n",
       "1        two  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2;\n",
       "                var nbb_unformatted_code = \"# Reading the train set\\ndata = pd.read_csv(\\\"wp_life_expect_preproc.csv\\\")\\n\\n# Making a working copy\\ndf = data.copy()\\n\\n# Checking the shape\\nprint(f\\\"There are {df.shape[0]} rows and {df.shape[1]} columns.\\\")\\n\\n# Checking first 2 rows of the data\\ndf.head(2)\";\n",
       "                var nbb_formatted_code = \"# Reading the train set\\ndata = pd.read_csv(\\\"wp_life_expect_preproc.csv\\\")\\n\\n# Making a working copy\\ndf = data.copy()\\n\\n# Checking the shape\\nprint(f\\\"There are {df.shape[0]} rows and {df.shape[1]} columns.\\\")\\n\\n# Checking first 2 rows of the data\\ndf.head(2)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Reading the train set\n",
    "data = pd.read_csv(\"wp_life_expect_preproc.csv\")\n",
    "\n",
    "# Making a working copy\n",
    "df = data.copy()\n",
    "\n",
    "# Checking the shape\n",
    "print(f\"There are {df.shape[0]} rows and {df.shape[1]} columns.\")\n",
    "\n",
    "# Checking first 2 rows of the data\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6cca416f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_references</th>\n",
       "      <th>year</th>\n",
       "      <th>age</th>\n",
       "      <th>sciences</th>\n",
       "      <th>social</th>\n",
       "      <th>spiritual</th>\n",
       "      <th>academia_humanities</th>\n",
       "      <th>business_farming</th>\n",
       "      <th>arts</th>\n",
       "      <th>sports</th>\n",
       "      <th>law_enf_military_operator</th>\n",
       "      <th>politics_govt_law</th>\n",
       "      <th>crime</th>\n",
       "      <th>num_categories</th>\n",
       "      <th>age_sqrd</th>\n",
       "      <th>recip_num_references</th>\n",
       "      <th>years_sqrd</th>\n",
       "      <th>region</th>\n",
       "      <th>prior_region</th>\n",
       "      <th>known_for</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>77622</th>\n",
       "      <td>7</td>\n",
       "      <td>1994</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5476.0</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0</td>\n",
       "      <td>North America</td>\n",
       "      <td>No Prior Region</td>\n",
       "      <td>arts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77623</th>\n",
       "      <td>5</td>\n",
       "      <td>2002</td>\n",
       "      <td>92.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8464.0</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>64</td>\n",
       "      <td>Europe</td>\n",
       "      <td>No Prior Region</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       num_references  year   age  sciences  social  spiritual  \\\n",
       "77622               7  1994  74.0         0       0          0   \n",
       "77623               5  2002  92.0         0       0          0   \n",
       "\n",
       "       academia_humanities  business_farming  arts  sports  \\\n",
       "77622                    0                 0     1       0   \n",
       "77623                    0                 0     0       1   \n",
       "\n",
       "       law_enf_military_operator  politics_govt_law  crime  num_categories  \\\n",
       "77622                          0                  0      0               1   \n",
       "77623                          0                  0      0               1   \n",
       "\n",
       "       age_sqrd  recip_num_references  years_sqrd         region  \\\n",
       "77622    5476.0              0.142857           0  North America   \n",
       "77623    8464.0              0.200000          64         Europe   \n",
       "\n",
       "          prior_region known_for  \n",
       "77622  No Prior Region      arts  \n",
       "77623  No Prior Region    sports  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 3;\n",
       "                var nbb_unformatted_code = \"# Checking last 2 rows of the data\\ndf.tail(2)\";\n",
       "                var nbb_formatted_code = \"# Checking last 2 rows of the data\\ndf.tail(2)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Checking last 2 rows of the data\n",
    "df.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de6e8ee5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_references</th>\n",
       "      <th>year</th>\n",
       "      <th>age</th>\n",
       "      <th>sciences</th>\n",
       "      <th>social</th>\n",
       "      <th>spiritual</th>\n",
       "      <th>academia_humanities</th>\n",
       "      <th>business_farming</th>\n",
       "      <th>arts</th>\n",
       "      <th>sports</th>\n",
       "      <th>law_enf_military_operator</th>\n",
       "      <th>politics_govt_law</th>\n",
       "      <th>crime</th>\n",
       "      <th>num_categories</th>\n",
       "      <th>age_sqrd</th>\n",
       "      <th>recip_num_references</th>\n",
       "      <th>years_sqrd</th>\n",
       "      <th>region</th>\n",
       "      <th>prior_region</th>\n",
       "      <th>known_for</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28593</th>\n",
       "      <td>7</td>\n",
       "      <td>2006</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4096.0</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>144</td>\n",
       "      <td>Europe</td>\n",
       "      <td>No Prior Region</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42108</th>\n",
       "      <td>7</td>\n",
       "      <td>2000</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2209.0</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>36</td>\n",
       "      <td>North America</td>\n",
       "      <td>No Prior Region</td>\n",
       "      <td>three_to_five</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21712</th>\n",
       "      <td>9</td>\n",
       "      <td>2022</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2304.0</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>784</td>\n",
       "      <td>Africa</td>\n",
       "      <td>No Prior Region</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58236</th>\n",
       "      <td>3</td>\n",
       "      <td>2007</td>\n",
       "      <td>53.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2809.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>169</td>\n",
       "      <td>Europe</td>\n",
       "      <td>No Prior Region</td>\n",
       "      <td>arts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24300</th>\n",
       "      <td>136</td>\n",
       "      <td>2006</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>9409.0</td>\n",
       "      <td>0.007353</td>\n",
       "      <td>144</td>\n",
       "      <td>North America</td>\n",
       "      <td>No Prior Region</td>\n",
       "      <td>two</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       num_references  year   age  sciences  social  spiritual  \\\n",
       "28593               7  2006  64.0         0       0          0   \n",
       "42108               7  2000  47.0         0       0          0   \n",
       "21712               9  2022  48.0         0       0          0   \n",
       "58236               3  2007  53.0         0       0          0   \n",
       "24300             136  2006  97.0         0       0          0   \n",
       "\n",
       "       academia_humanities  business_farming  arts  sports  \\\n",
       "28593                    0                 0     0       1   \n",
       "42108                    0                 0     1       1   \n",
       "21712                    0                 0     0       1   \n",
       "58236                    0                 0     1       0   \n",
       "24300                    0                 0     1       0   \n",
       "\n",
       "       law_enf_military_operator  politics_govt_law  crime  num_categories  \\\n",
       "28593                          0                  0      0               1   \n",
       "42108                          0                  0      1               3   \n",
       "21712                          0                  0      0               1   \n",
       "58236                          0                  0      0               1   \n",
       "24300                          0                  1      0               2   \n",
       "\n",
       "       age_sqrd  recip_num_references  years_sqrd         region  \\\n",
       "28593    4096.0              0.142857         144         Europe   \n",
       "42108    2209.0              0.142857          36  North America   \n",
       "21712    2304.0              0.111111         784         Africa   \n",
       "58236    2809.0              0.333333         169         Europe   \n",
       "24300    9409.0              0.007353         144  North America   \n",
       "\n",
       "          prior_region      known_for  \n",
       "28593  No Prior Region         sports  \n",
       "42108  No Prior Region  three_to_five  \n",
       "21712  No Prior Region         sports  \n",
       "58236  No Prior Region           arts  \n",
       "24300  No Prior Region            two  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 4;\n",
       "                var nbb_unformatted_code = \"# Checking a sample of the data\\ndf.sample(5)\";\n",
       "                var nbb_formatted_code = \"# Checking a sample of the data\\ndf.sample(5)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Checking a sample of the data\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d5f29da",
   "metadata": {},
   "source": [
    "### Checking Data Types and Null Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf505f87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 77624 entries, 0 to 77623\n",
      "Data columns (total 20 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   num_references             77624 non-null  int64  \n",
      " 1   year                       77624 non-null  int64  \n",
      " 2   age                        77624 non-null  float64\n",
      " 3   sciences                   77624 non-null  int64  \n",
      " 4   social                     77624 non-null  int64  \n",
      " 5   spiritual                  77624 non-null  int64  \n",
      " 6   academia_humanities        77624 non-null  int64  \n",
      " 7   business_farming           77624 non-null  int64  \n",
      " 8   arts                       77624 non-null  int64  \n",
      " 9   sports                     77624 non-null  int64  \n",
      " 10  law_enf_military_operator  77624 non-null  int64  \n",
      " 11  politics_govt_law          77624 non-null  int64  \n",
      " 12  crime                      77624 non-null  int64  \n",
      " 13  num_categories             77624 non-null  int64  \n",
      " 14  age_sqrd                   77624 non-null  float64\n",
      " 15  recip_num_references       77624 non-null  float64\n",
      " 16  years_sqrd                 77624 non-null  int64  \n",
      " 17  region                     77624 non-null  object \n",
      " 18  prior_region               77624 non-null  object \n",
      " 19  known_for                  77624 non-null  object \n",
      "dtypes: float64(3), int64(14), object(3)\n",
      "memory usage: 11.8+ MB\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 5;\n",
       "                var nbb_unformatted_code = \"# Checking data types and null values\\ndf.info()\";\n",
       "                var nbb_formatted_code = \"# Checking data types and null values\\ndf.info()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Checking data types and null values\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c459d7f8",
   "metadata": {},
   "source": [
    "#### Observations:\n",
    "- With our dataset loaded, we are ready for modeling.\n",
    "- We have three variables that need typcasting from object to category, then one hot encoding."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c542ec1",
   "metadata": {},
   "source": [
    "#### Typecasting `region`, `prior_region`, and `known_for` as Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "87fccaff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 77624 entries, 0 to 77623\n",
      "Data columns (total 20 columns):\n",
      " #   Column                     Non-Null Count  Dtype   \n",
      "---  ------                     --------------  -----   \n",
      " 0   num_references             77624 non-null  int64   \n",
      " 1   year                       77624 non-null  int64   \n",
      " 2   age                        77624 non-null  float64 \n",
      " 3   sciences                   77624 non-null  int64   \n",
      " 4   social                     77624 non-null  int64   \n",
      " 5   spiritual                  77624 non-null  int64   \n",
      " 6   academia_humanities        77624 non-null  int64   \n",
      " 7   business_farming           77624 non-null  int64   \n",
      " 8   arts                       77624 non-null  int64   \n",
      " 9   sports                     77624 non-null  int64   \n",
      " 10  law_enf_military_operator  77624 non-null  int64   \n",
      " 11  politics_govt_law          77624 non-null  int64   \n",
      " 12  crime                      77624 non-null  int64   \n",
      " 13  num_categories             77624 non-null  int64   \n",
      " 14  age_sqrd                   77624 non-null  float64 \n",
      " 15  recip_num_references       77624 non-null  float64 \n",
      " 16  years_sqrd                 77624 non-null  int64   \n",
      " 17  region                     77624 non-null  category\n",
      " 18  prior_region               77624 non-null  category\n",
      " 19  known_for                  77624 non-null  category\n",
      "dtypes: category(3), float64(3), int64(14)\n",
      "memory usage: 10.3 MB\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 7;\n",
       "                var nbb_unformatted_code = \"# Typcasting prior_region and region as categorical\\ndf[[\\\"prior_region\\\", \\\"region\\\", 'known_for']] = df[[\\\"prior_region\\\", \\\"region\\\", 'known_for']].astype(\\\"category\\\")\\n\\n# Re-check info\\ndf.info()\";\n",
       "                var nbb_formatted_code = \"# Typcasting prior_region and region as categorical\\ndf[[\\\"prior_region\\\", \\\"region\\\", \\\"known_for\\\"]] = df[\\n    [\\\"prior_region\\\", \\\"region\\\", \\\"known_for\\\"]\\n].astype(\\\"category\\\")\\n\\n# Re-check info\\ndf.info()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Typcasting prior_region and region as categorical\n",
    "df[[\"prior_region\", \"region\", \"known_for\"]] = df[\n",
    "    [\"prior_region\", \"region\", \"known_for\"]\n",
    "].astype(\"category\")\n",
    "\n",
    "# Re-check info\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4804e77f",
   "metadata": {},
   "source": [
    "## Building a Linear Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176c405c",
   "metadata": {},
   "source": [
    "### Data Preparation for Modeling\n",
    "As there is no model tuning in this basic ordinary least squares model, we can train directly with the `train` set and check performance directly on the `test` set.  We will need to do the necessary treatments on the `test` set first."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c14b3ab",
   "metadata": {},
   "source": [
    "### Test Set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9e1840",
   "metadata": {},
   "source": [
    "#### Loading [Test Set](https://github.com/teresahanak/wikipedia-life-expectancy/blob/main/wp_life_expect_test.csv) and [region_place_dict](https://github.com/teresahanak/wikipedia-life-expectancy/blob/main/region_place_dict.pkl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a0214f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 19608 rows and 25 columns.\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 8;\n",
       "                var nbb_unformatted_code = \"# Reading test.csv\\ntest = pd.read_csv(\\\"wp_life_expect_test.csv\\\")\\n\\n# Checking shape\\nprint(f\\\"There are {test.shape[0]} rows and {test.shape[1]} columns.\\\")\\n\\n# Loading region_place_dict\\nwith open(\\\"region_place_dict.pkl\\\", \\\"rb\\\") as f:\\n    region_place_dict = pickle.load(f)\";\n",
       "                var nbb_formatted_code = \"# Reading test.csv\\ntest = pd.read_csv(\\\"wp_life_expect_test.csv\\\")\\n\\n# Checking shape\\nprint(f\\\"There are {test.shape[0]} rows and {test.shape[1]} columns.\\\")\\n\\n# Loading region_place_dict\\nwith open(\\\"region_place_dict.pkl\\\", \\\"rb\\\") as f:\\n    region_place_dict = pickle.load(f)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Reading test.csv\n",
    "test = pd.read_csv(\"wp_life_expect_test.csv\")\n",
    "\n",
    "# Checking shape\n",
    "print(f\"There are {test.shape[0]} rows and {test.shape[1]} columns.\")\n",
    "\n",
    "# Loading region_place_dict\n",
    "with open(\"region_place_dict.pkl\", \"rb\") as f:\n",
    "    region_place_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eba2f22f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 19608 entries, 0 to 19607\n",
      "Data columns (total 25 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   day                        19608 non-null  int64  \n",
      " 1   name                       19608 non-null  object \n",
      " 2   info                       19608 non-null  object \n",
      " 3   link                       19608 non-null  object \n",
      " 4   num_references             19608 non-null  int64  \n",
      " 5   year                       19608 non-null  int64  \n",
      " 6   month                      19608 non-null  object \n",
      " 7   info_parenth               6832 non-null   object \n",
      " 8   age                        19608 non-null  float64\n",
      " 9   cause_of_death             6641 non-null   object \n",
      " 10  place_1                    19580 non-null  object \n",
      " 11  place_2                    1193 non-null   object \n",
      " 12  sciences                   19608 non-null  int64  \n",
      " 13  social                     19608 non-null  int64  \n",
      " 14  spiritual                  19608 non-null  int64  \n",
      " 15  academia_humanities        19608 non-null  int64  \n",
      " 16  business_farming           19608 non-null  int64  \n",
      " 17  arts                       19608 non-null  int64  \n",
      " 18  sports                     19608 non-null  int64  \n",
      " 19  law_enf_military_operator  19608 non-null  int64  \n",
      " 20  politics_govt_law          19608 non-null  int64  \n",
      " 21  crime                      19608 non-null  int64  \n",
      " 22  event_record_other         19608 non-null  int64  \n",
      " 23  other_species              19608 non-null  int64  \n",
      " 24  num_categories             19608 non-null  int64  \n",
      "dtypes: float64(1), int64(16), object(8)\n",
      "memory usage: 3.7+ MB\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 9;\n",
       "                var nbb_unformatted_code = \"# Checking info\\ntest.info()\";\n",
       "                var nbb_formatted_code = \"# Checking info\\ntest.info()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Checking info\n",
    "test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d04b53",
   "metadata": {},
   "source": [
    "#### Pre-processing Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd1344e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# 1. Dropping non-human entries\n",
    "rows_to_drop = test[test[\"other_species\"] == 1].index\n",
    "test.drop(rows_to_drop, inplace=True)\n",
    "test.reset_index(inplace=True, drop=True)\n",
    "\n",
    "# 2. Dropping entries with event_record_other as sole category\n",
    "rows_to_drop = test[(test['event_record_other']==1) & (test['num_categories']==1)].index\n",
    "test.drop(rows_to_drop, inplace=True)\n",
    "test.reset_index(inplace=True, drop=True)\n",
    "\n",
    "# 3. Creating recip_num_references column\n",
    "test[\"recip_num_references\"] = test[\"num_references\"].apply(lambda x: 1 / x)\n",
    "\n",
    "# 4. Creating region column\n",
    "# Dropping place_2 values that are duplicates of place_1\n",
    "index = [\n",
    "    index\n",
    "    for index in test.index\n",
    "    if test.loc[index, \"place_2\"] == test.loc[index, \"place_1\"]\n",
    "]\n",
    "test.loc[index, \"place_2\"] = None\n",
    "\n",
    "# For loop to create region column\n",
    "test[\"region\"] = None\n",
    "for region, places in region_place_dict.items():\n",
    "    for place in places:\n",
    "        for index in test[(test[\"region\"].isna()) & (test[\"place_2\"].notna())].index:\n",
    "            item = test.loc[index, \"place_2\"]\n",
    "            if item:\n",
    "                if item == place:\n",
    "                    test.loc[index, \"region\"] = region\n",
    "        for index in test[(test[\"region\"].isna()) & (test[\"place_2\"].isna())].index:\n",
    "            item = test.loc[index, \"place_1\"]\n",
    "            if item:\n",
    "                if item == place:\n",
    "                    test.loc[index, \"region\"] = region\n",
    "\n",
    "# 5. Creating prior_region column\n",
    "# For loop to create prior_region column\n",
    "test[\"prior_region\"] = None\n",
    "for region, places in region_place_dict.items():\n",
    "    for place in places:\n",
    "        for index in test[\n",
    "            (test[\"place_2\"].notna()) & (test[\"prior_region\"].isna())\n",
    "        ].index:\n",
    "            item = test.loc[index, \"place_1\"]\n",
    "            if item:\n",
    "                if item == place:\n",
    "                    test.loc[index, \"prior_region\"] = region\n",
    "# Adding No Prior Region category\n",
    "test[\"prior_region\"].fillna(\"No Prior Region\", inplace=True)\n",
    "\n",
    "# 6. Creating known_for column\n",
    "# Initializing known_for\n",
    "test['known_for']=None\n",
    "# List of known for columns\n",
    "cols = ['sciences', 'social', 'spiritual', 'academia_humanities',\n",
    "       'business_farming', 'arts', 'sports', 'law_enf_military_operator',\n",
    "       'politics_govt_law', 'crime', 'event_record_other', 'other_species']\n",
    "# For loop to assign known_for\n",
    "for index in test[test['known_for'].isna()].index:\n",
    "    if test.loc[index, 'num_categories']==2:\n",
    "        test.loc[index, 'known_for'] = 'two'\n",
    "    elif test.loc[index, 'num_categories'] > 2:\n",
    "        test.loc[index, 'known_for'] = 'three_to_five'\n",
    "    else: \n",
    "        for column in cols:\n",
    "            if test.loc[index, column]==1:\n",
    "                test.loc[index, 'known_for'] = column\n",
    "\n",
    "# 7. Creating years column\n",
    "test[\"years\"] = test[\"year\"].apply(lambda x: x - 1994)\n",
    "\n",
    "# 8. Typecasting object columns as category\n",
    "test[['region', 'prior_region', 'known_for']] = test[['region', 'prior_region', 'known_for']].astype('category')\n",
    "\n",
    "# 9. Dropping Unnecessary Columns\n",
    "cols_to_drop = [\n",
    "   'day', 'name', 'info', 'link', 'num_references', 'year', 'month',\n",
    "       'info_parenth', 'cause_of_death', 'place_1', 'place_2',\n",
    "       'sciences', 'social', 'spiritual', 'academia_humanities',\n",
    "       'business_farming', 'arts', 'sports', 'law_enf_military_operator',\n",
    "       'politics_govt_law', 'crime', 'event_record_other', 'other_species',\n",
    "       'num_categories', \n",
    "]\n",
    "test.drop(cols_to_drop, axis=1, inplace=True)\n",
    "\n",
    "# Rechecking columns\n",
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3cf0c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking a sample of rows\n",
    "test.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8168b5",
   "metadata": {},
   "source": [
    "#### Observations:\n",
    "- Treatment of `test` missing values is the only remaining step.\n",
    "- We will use the modes for the `known_for` groups from `train` to fill missing values for `test` to avoid data leakage.  `region` is the only column with missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221f578f",
   "metadata": {},
   "source": [
    "#### Treating Missing Values for `region` in Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf531d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the starting missing values\n",
    "print(f'There are {test[\"region\"].isna().sum()} missing values.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5092b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For loop to impute test missing values with mode of train rows with matching sole known for category\n",
    "for index in test[test[\"region\"].isna()].index:\n",
    "    value = test.loc[index, \"known_for\"]\n",
    "    group_mode = df[df[\"known_for\"] == value][\"region\"].mode().iloc[0]\n",
    "    test.loc[index, \"region\"] = group_mode\n",
    "\n",
    "# Checking the starting missing values\n",
    "print(f'There are {test[\"region\"].isna().sum()} missing values.')\n",
    "\n",
    "# Checking region value_counts\n",
    "test[\"region\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf4e183",
   "metadata": {},
   "source": [
    "#### Observations:\n",
    "- `train` and `test` are both ready for modeling.\n",
    "- We will perform one hot encoding when defining our independent variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23403783",
   "metadata": {},
   "source": [
    "#### Defining Independent and Dependent Variables for Train and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2216c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining independent and dependent variables\n",
    "X_train, X_test = df.drop(\"age\", axis=1), test.drop(\"age\", axis=1)\n",
    "y_train, y_test = df[\"age\"], test[\"age\"]\n",
    "\n",
    "\n",
    "# One hot encoding independent categorical features\n",
    "X_train = pd.get_dummies(X_train, drop_first=True)\n",
    "X_test = pd.get_dummies(X_test, drop_first=True)\n",
    "\n",
    "# Adding the intercept\n",
    "X_train = sm.add_constant(X_train)\n",
    "X_test = sm.add_constant(X_test)\n",
    "\n",
    "# Typecasting independent variables as float\n",
    "X_train = X_train.astype(\"float64\")\n",
    "X_test = X_test.astype(\"float64\")\n",
    "\n",
    "# Checking shape of train and test sets\n",
    "print(f\"There are {X_train.shape[0]} rows and {X_train.shape[1]} columns in X_train.\")\n",
    "print(f\"There are {X_test.shape[0]} rows and {X_test.shape[1]} columns in X_test.\\n\")\n",
    "\n",
    "# Checking a sample of train set\n",
    "X_train.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e144120",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking a sample of test set\n",
    "X_test.sample(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "598a53f2",
   "metadata": {},
   "source": [
    "#### Observations:\n",
    "- We are ready to build our model.\n",
    "- The references levels for the categorical features are as follows:\n",
    "    - `region`: Africa\n",
    "    - `prior_region`: Africa\n",
    "    - `known_for` academia_humanities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e86a0713",
   "metadata": {},
   "source": [
    "### Fitting a Linear Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa7c7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting a linear model and displaying model summary\n",
    "olsmodel = sm.OLS(y_train, X_train).fit()\n",
    "print(olsmodel.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ef7379",
   "metadata": {},
   "source": [
    "### Model Performance Check"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be442673",
   "metadata": {},
   "source": [
    "#### Functions to check model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815c33f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to compute adjusted R-squared\n",
    "def adj_r2_score(predictors, targets, predictions):\n",
    "    r2 = r2_score(targets, predictions)\n",
    "    n = predictors.shape[0]\n",
    "    k = predictors.shape[1]\n",
    "    return 1 - ((1 - r2) * (n - 1) / (n - k - 1))\n",
    "\n",
    "\n",
    "# function to compute MAPE\n",
    "def mape_score(targets, predictions):\n",
    "    return np.mean(np.abs((targets - predictions) / targets)) * 100\n",
    "\n",
    "\n",
    "# function to compute and display different metrics to check performance of a regression model\n",
    "# with conversion back to original scale for RMSE, MAE, and MAPE for ease of explainability\n",
    "def model_performance_regression(model, predictors, target):\n",
    "    \"\"\"\n",
    "    Function to compute and return a dataframe of different metrics to check\n",
    "    regression model performance\n",
    "    \n",
    "    model: regressor\n",
    "    predictors: independent variables\n",
    "    target: dependent variable\n",
    "    \"\"\"\n",
    "    # predictions\n",
    "    pred = model.predict(predictors)\n",
    "\n",
    "    r2 = r2_score(target, pred)  # to compute R-squared\n",
    "    adjr2 = adj_r2_score(predictors, target, pred)  # to compute adjusted R-squared\n",
    "    rmse = np.sqrt(mean_squared_error(target, pred))  # to compute RMSE\n",
    "    mae = mean_absolute_error(target, pred)  # to compute MAE\n",
    "    mape = mape_score(target, pred)  # to compute MAPE\n",
    "\n",
    "    # creating a dataframe of metrics\n",
    "    df_perf = pd.DataFrame(\n",
    "        {\n",
    "            \"RMSE\": rmse,\n",
    "            \"MAE\": mae,\n",
    "            \"R-squared\": r2,\n",
    "            \"Adj. R-squared\": adjr2,\n",
    "            \"MAPE\": mape,\n",
    "        },\n",
    "        index=[0],\n",
    "    )\n",
    "\n",
    "    return df_perf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "738385af",
   "metadata": {},
   "source": [
    "#### Model Performance on Train Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c19a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking model performance on train set\n",
    "print(\"Training Performance\\n\")\n",
    "olsmodel_train_perf = model_performance_regression(olsmodel, X_train, y_train)\n",
    "olsmodel_train_perf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46dbdf32",
   "metadata": {},
   "source": [
    "### Model Performance on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d45f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking model performance on validation set\n",
    "print(\"Test Peformance\\n\")\n",
    "olsmodel_test_perf = model_performance_regression(olsmodel, X_test, y_test)\n",
    "olsmodel_test_perf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a15e44",
   "metadata": {},
   "source": [
    "#### Observations:\n",
    "- The train and test $R^2$ are 0.096 and 0.093, respectively, indicating that the model explains 9.6% of total variation in the train set and 9.3% of variation in the test set, so a very small amount.\n",
    "- RMSE values for the two sets are also comparable.\n",
    "- The comparable results between the two sets show that the model is not overfitting.\n",
    "- MAE indicates that our current model is able to predict age of reported deceased notable Wikipedia individuals within a mean error of 11.6 years on the test set.\n",
    "- MAPE of 19.2% on the test set means that we are able to predict within 19.2% of the reported age, in years."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e498339",
   "metadata": {},
   "source": [
    "### Checking Linear Regression Assumptions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0dd4c8f",
   "metadata": {},
   "source": [
    "### Test for Multicollinearity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5caeb86",
   "metadata": {},
   "source": [
    "#### Function to check VIF of Each Independent Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45eb9177",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to check and display VIF of each independent variable\n",
    "def checking_vif(predictors):\n",
    "    \"\"\"\n",
    "    Takes input dependent variables predictors and returns\n",
    "    a dataframe of variable name and VIF\n",
    "    \"\"\"\n",
    "    vif = pd.DataFrame()\n",
    "    vif[\"feature\"] = predictors.columns\n",
    "\n",
    "    # calculating VIF for each feature\n",
    "    vif[\"VIF\"] = [\n",
    "        variance_inflation_factor(predictors.values, i)\n",
    "        for i in range(len(predictors.columns))\n",
    "    ]\n",
    "    return vif"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f6e35b",
   "metadata": {},
   "source": [
    "#### VIF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5591c46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking vif\n",
    "vif = checking_vif(X_train).sort_values(by=\"VIF\", ascending=False)\n",
    "vif"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f188c5",
   "metadata": {},
   "source": [
    "#### Observations:\n",
    "- The majority of predictors have low VIF (< 5), which is good.\n",
    "- We will accept the higher VIF value belonging to the constant as the constant is necessary for the residuals to have zero mean, avoiding bias.\n",
    "- We will proceed by checking the impact on performance of dropping each of the high VIF columns, and drop the column with the least impact on performance, then re-evaluate VIF.  \n",
    "- This process is iterative until we have all low VIF columns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a3ca177",
   "metadata": {},
   "source": [
    "#### Function to Treat Multicollinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b38a46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def treating_multicollinearity(predictors, target, high_vif_columns):\n",
    "    \"\"\"\n",
    "    Checking the effect of dropping the columns showing high multicollinearity\n",
    "    on model performance (adj. R-squared and RMSE)\n",
    "\n",
    "    predictors: independent variables\n",
    "    target: dependent variable\n",
    "    high_vif_columns: columns having high VIF\n",
    "    \"\"\"\n",
    "    # empty lists to store adj. R-squared and RMSE values\n",
    "    adj_r2 = []\n",
    "    rmse = []\n",
    "\n",
    "    # build ols models by dropping one of the high VIF columns at a time\n",
    "    # store the adjusted R-squared and RMSE in the lists defined previously\n",
    "    for cols in high_vif_columns:\n",
    "        # defining the new train set\n",
    "        train = predictors.loc[:, ~predictors.columns.str.startswith(cols)]\n",
    "\n",
    "        # create the model\n",
    "        olsmodel = sm.OLS(target, train).fit()\n",
    "\n",
    "        # adding adj. R-squared and RMSE to the lists\n",
    "        adj_r2.append(olsmodel.rsquared_adj)\n",
    "        rmse.append(np.sqrt(olsmodel.mse_resid))\n",
    "\n",
    "    # creating a dataframe for the results\n",
    "    temp = pd.DataFrame(\n",
    "        {\n",
    "            \"col\": high_vif_columns,\n",
    "            \"Adj. R-squared after_dropping col\": adj_r2,\n",
    "            \"RMSE after dropping col\": rmse,\n",
    "        }\n",
    "    ).sort_values(by=\"Adj. R-squared after_dropping col\", ascending=False)\n",
    "    temp.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe878568",
   "metadata": {},
   "source": [
    "#### Checking Impact of Dropping Columns on Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9147ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking impact of dropping columns\n",
    "col_list = vif[vif[\"VIF\"] >= 5][\"feature\"].tolist()\n",
    "col_list.remove(\"const\")\n",
    "\n",
    "results = treating_multicollinearity(X_train, y_train, col_list)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb376b60",
   "metadata": {},
   "source": [
    "#### Observations:\n",
    "- Of the high VIF columns, `prior_region_No Prior Region` has the least impact on performance when dropped, so we will drop it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a9595fb",
   "metadata": {},
   "source": [
    "#### Dropping `prior_region_No Prior Region`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eecac674",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping prior_region_No Prior Region column\n",
    "col_to_drop = \"prior_region_No Prior Region\"\n",
    "X_train = X_train.drop(col_to_drop, axis=1)\n",
    "X_test = X_test.drop(col_to_drop, axis=1)\n",
    "\n",
    "# Recheck VIF\n",
    "vif = checking_vif(X_train).sort_values(by=\"VIF\", ascending=False)\n",
    "vif"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fffa51dd",
   "metadata": {},
   "source": [
    "#### Checking Impact of Dropping Columns on Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a64dda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking impact of dropping columns\n",
    "col_list = vif[vif[\"VIF\"] >= 5][\"feature\"].tolist()\n",
    "col_list.remove(\"const\")\n",
    "\n",
    "results = treating_multicollinearity(X_train, y_train, col_list)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c688bba7",
   "metadata": {},
   "source": [
    "#### Observations:\n",
    "- Of the remaining high VIF columns, `known_for_politics_govt_law` has the least impact on performance when dropped, so we will drop it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50e79ee",
   "metadata": {},
   "source": [
    "#### Dropping `known_for_politics_govt_law`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764cafcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping known_for_politics_govt_law column\n",
    "col_to_drop = \"known_for_politics_govt_law\"\n",
    "X_train = X_train.drop(col_to_drop, axis=1)\n",
    "X_test = X_test.drop(col_to_drop, axis=1)\n",
    "\n",
    "# Recheck VIF\n",
    "vif = checking_vif(X_train).sort_values(by=\"VIF\", ascending=False)\n",
    "vif"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42ca4f4",
   "metadata": {},
   "source": [
    "#### Checking Impact of Dropping Columns on Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b7c34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking impact of dropping columns\n",
    "col_list = vif[vif[\"VIF\"] >= 5][\"feature\"].tolist()\n",
    "col_list.remove(\"const\")\n",
    "\n",
    "results = treating_multicollinearity(X_train, y_train, col_list)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dfc9a3d",
   "metadata": {},
   "source": [
    "#### Observations:\n",
    "- That iteration got us down to two remaining high VIF columns.\n",
    "- Of the remaining high VIF columns, `region_Europe` has the least impact on performance when dropped, so we will drop it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824eaeb6",
   "metadata": {},
   "source": [
    "#### Dropping `region_Europe`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe25943a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping region_Europe column\n",
    "col_to_drop = \"region_Europe\"\n",
    "X_train = X_train.drop(col_to_drop, axis=1)\n",
    "X_test = X_test.drop(col_to_drop, axis=1)\n",
    "\n",
    "# Recheck VIF\n",
    "vif = checking_vif(X_train).sort_values(by=\"VIF\", ascending=False)\n",
    "vif"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9145a7ab",
   "metadata": {},
   "source": [
    "#### Observations:\n",
    "- `prior_region_No Prior Region`, `known_for_politics_govt_law`, and `region_Europe` columns were dropped and there are no remaining high VIF columns,excluding the constant, which we will retain.\n",
    "- **So, the assumption of independence of predictor variables (absence of multicollinearity) is satisfied.**\n",
    "- The updated reference levels for each feature are as follows:\n",
    "    - `region`: Africa OR Europe\n",
    "    - `prior_region`: Africa OR No Prior Region\n",
    "    - `known_for`: academia_humanities OR politics_govt_law\n",
    "- Next, we will fit our second model, then drop columns with high p-values for their coefficients."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a014e23",
   "metadata": {},
   "source": [
    "#### Fitting Second Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b9787e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting a linear model and displaying model summary\n",
    "olsmodel2 = sm.OLS(y_train, X_train).fit()\n",
    "print(olsmodel2.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1ce68e",
   "metadata": {},
   "source": [
    "#### Checking Features with High Coefficient p-values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db60a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loop for Dropping variables with high coefficient p-values one at a time excluding constant and dummy variables\n",
    "# Current model predictors\n",
    "train_predictors = X_train\n",
    "\n",
    "# initial list of all independent variable columns including constant\n",
    "cols = train_predictors.columns.to_list()\n",
    "\n",
    "# initial empty list of independent variables to exclude\n",
    "excluded_features = []\n",
    "\n",
    "# setting an initial max p_value\n",
    "max_p_value = 1\n",
    "\n",
    "for i in range(len(cols)):\n",
    "    # defining the train set\n",
    "    x_train_aux = train_predictors[cols]\n",
    "\n",
    "    # fitting the model\n",
    "    model = sm.OLS(y_train, x_train_aux).fit()\n",
    "\n",
    "    # getting the p-values and the maximum p-value\n",
    "    p_values = model.pvalues[cols]\n",
    "    max_p_value = max(p_values)\n",
    "\n",
    "    # name of the variable with maximum p-value\n",
    "    feature_with_p_max = p_values.idxmax()\n",
    "\n",
    "    if max_p_value > 0.05:\n",
    "        cols.remove(feature_with_p_max)\n",
    "        excluded_features.append(feature_with_p_max)\n",
    "    else:\n",
    "        break\n",
    "\n",
    "print(f\"Features with high p-values to exclude: {excluded_features}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd86680d",
   "metadata": {},
   "source": [
    "#### Dropping `excluded_features` with High p-values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf36614",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping excluded_features\n",
    "X_train.drop(excluded_features, axis=1, inplace=True)\n",
    "X_test.drop(excluded_features, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90468b3",
   "metadata": {},
   "source": [
    "#### Observations:\n",
    "- We dropped several columns with high p-values.\n",
    "- The updated reference levels for each feature are as follows:\n",
    "    - `region`: Africa, Europe, OR Oceania\n",
    "    - `prior_region`: Africa, No Prior Region, Central Asia, South America, Mid-Cent America/Caribbean, Oceania, North America, OR Asia\n",
    "    - `known_for`: academia_humanities, politics_govt_law, social "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a384648",
   "metadata": {},
   "source": [
    "#### Fitting Third Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a669c67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fitting third model and printing summary\n",
    "olsmodel3 = sm.OLS(y_train, X_train).fit()\n",
    "print(olsmodel3.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee8bf22",
   "metadata": {},
   "source": [
    "#### Observations:\n",
    "- Adjusted $R^2$ has held at 0.082 after dropping the high p-value columns, indicating that the dropped variables were not affecting the model much at all.\n",
    "- **Now, no other feature, including the constant, has a p-value greater than 0.05, so we will consider these features as the final set of predictor variables and *olsmodel3* as the final model.**\n",
    "- *olsmodel3* has 22 predictors plut the constant term.\n",
    "- We will now check the remaining assumptions for linear regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cca321e",
   "metadata": {},
   "source": [
    "### Test for Linearity and Independence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ddda70b",
   "metadata": {},
   "source": [
    "#### Dataframe of Actual, Fitted, and Residual Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297c2f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe of actual, fitted, and residual values\n",
    "df_pred = pd.DataFrame()\n",
    "\n",
    "df_pred[\"Actual Values\"] = y_train  # actual values\n",
    "df_pred[\"Fitted Values\"] = olsmodel3.fittedvalues  # predicted values\n",
    "df_pred[\"Residuals\"] = olsmodel3.resid  # residuals\n",
    "\n",
    "df_pred.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e1f0fe9",
   "metadata": {},
   "source": [
    "#### Plot of Fitted Values vs Residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83e48ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot of fitted values vs residuals\n",
    "sns.residplot(\n",
    "    data=df_pred, x=\"Fitted Values\", y=\"Residuals\", color=\"purple\", lowess=True\n",
    ")\n",
    "plt.xlabel(\"Fitted Values\")\n",
    "plt.ylabel(\"Residuals\")\n",
    "plt.title(\"Fitted vs Residual plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de9da3c",
   "metadata": {},
   "source": [
    "#### Observation:\n",
    "- There is an underrepresented age group from ~58 to ~63 years in the predictions, resulting in two groups which is interesting.\n",
    "- Within itself, the under 60 group shows no obvious pattern.\n",
    "- The group above 60 is heavy on the bottom, indicating larger underestimates for age here, and wider variance.\n",
    "- **Overall, there is not a definitive pattern, so we will consider the assumptions of independence and linearity met.**\n",
    "- We will be testing further for heteroscedastictiy, via the Goldfeld-Quandt test."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c84b78",
   "metadata": {},
   "source": [
    "### Test for Normality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea53a14b",
   "metadata": {},
   "source": [
    "#### Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24238cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram of residuals\n",
    "sns.histplot(data=df_pred, x=\"Residuals\", kde=True)\n",
    "plt.title(\"Normality of Residuals\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a85534",
   "metadata": {},
   "source": [
    "#### Q-Q plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31775c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the Q-Q plot\n",
    "stats.probplot(df_pred[\"Residuals\"], dist=\"norm\", plot=pylab)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e11b41",
   "metadata": {},
   "source": [
    "#### Observations:\n",
    "- The distribution of the residuals does have an overall bell shape, but is quite peaked at ~8, with a thicker tail on the negative end.\n",
    "- As we saw during EDA, there are possibly two Guassian's here.\n",
    "- The Q-Q plot and the histogram show that the distribution is left-skewed.\n",
    "- **We cannot strictly say that the assumption of normally distributed residuals is met.**\n",
    "- Our plan is to apply other modeling algorithms, so we will see how they compare."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38003b0",
   "metadata": {},
   "source": [
    "### Test for Homoscedasticity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910ec18f",
   "metadata": {},
   "source": [
    "#### Goldfeld-Quandt Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7a74a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Goldfeld-quandt test\n",
    "name = [\"F statistic\", \"p-value\"]\n",
    "test = sms.het_goldfeldquandt(df_pred[\"Residuals\"], X_train)\n",
    "lzip(name, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205d468c",
   "metadata": {},
   "source": [
    "#### Observations:\n",
    "- Since p-value is > 0.05, the residuals are homoscedastic.\n",
    "- **The assumption of homoscedasticity is met.**\n",
    "- **Not all of the assumptions of linear regression are strictly met.  However, we will accept them as sufficiently met to allow for guarded interpretation in addition to prediction.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f04a978",
   "metadata": {},
   "source": [
    "## Final Model Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef362753",
   "metadata": {},
   "source": [
    "### *olsmodel3* summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68eebd34",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(olsmodel3.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "671752ec",
   "metadata": {},
   "source": [
    "#### Final Model Performance on Train Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0751ef97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking final model performance on train set\n",
    "print(\"Training Performance\\n\")\n",
    "olsmodel_train_perf = model_performance_regression(olsmodel3, X_train, y_train)\n",
    "olsmodel_train_perf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1892988",
   "metadata": {},
   "source": [
    "#### Final Model Performance on Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36fce43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking final model performance on test set\n",
    "print(\"Testing Performance\\n\")\n",
    "olsmodel_test_perf = model_performance_regression(olsmodel3, X_test, y_test)\n",
    "olsmodel_test_perf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d0f540",
   "metadata": {},
   "source": [
    "#### Observations:\n",
    "- With $R^2$ of only 0.082 on the train set, our model is underfitting.  The predictors are only able to explain ~8% of the variation from the mean actual age.\n",
    "- Test $R^2$ of 0.079 indicates that the model is not overfitting, as it compares to that of the test set along with other measures.\n",
    "- MAE of 11.7 suggests that the model can predict within a mean error of 11.7 years on the test data.\n",
    "- MAPE of 19.3 on the test data means that we aree able to predict within ~19.3% of age."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5bc920",
   "metadata": {},
   "source": [
    "## Interpreting *olsmodel3* Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306ffcd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For loop to make list of parameters with p-values < 0.05\n",
    "# Final model predictors\n",
    "final_pred = X_train\n",
    "\n",
    "# initial list of all independent variable columns excluding constant\n",
    "cols = final_pred.columns[1:]\n",
    "\n",
    "# initial list of columns to interpret\n",
    "features_to_interp = []\n",
    "\n",
    "# for loop to create list of features with p < 0.05\n",
    "for feature in cols:\n",
    "    p_value = olsmodel3.pvalues[feature]\n",
    "    if p_value < 0.05:\n",
    "        features_to_interp.append(feature)\n",
    "\n",
    "print(\n",
    "    \"Features with interpretable coefficient confidence intervals: \\n\\n\", feat_to_interp\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c6df0e",
   "metadata": {},
   "source": [
    "#### Interpreting Final Features Coefficients (p-values < 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a9444e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a dataframe of features, coefficients, and interpretations\n",
    "interp_df = pd.DataFrame(olsmodel3.params).loc[features_to_interp, :].reset_index()\n",
    "interp_df.rename({\"index\": \"Feature\", 0: \"Coefficient\"}, axis=1, inplace=True)\n",
    "\n",
    "# title for interpretation column\n",
    "title = \"Impact on Age (all else constant; compared to reference levels for category)\"\n",
    "\n",
    "# for loop to indicate how used price % changes in relation to feature dependent on feature type/transformation\n",
    "for i, feature in enumerate(interp_df[\"Feature\"]):\n",
    "\n",
    "    # for mutliplicative inverse transformed features based on 10-fold factor change in feature\n",
    "    if feature.startswith(\"recip\"):\n",
    "        interp_df.loc[\n",
    "            i, title\n",
    "        ] = f\"geometric decrease (*{round(((interp_df.loc[i, 'Coefficient'])*.01), 2)}) with each 10-fold increase in {feature.removeprefix('recip_')}\"\n",
    "\n",
    "    # for categorical one hot encoded\n",
    "    elif feature.startswith('region'):\n",
    "        interp_df.loc[\n",
    "            i, title\n",
    "        ] = f\"{np.round((interp_df.loc[i, 'Coefficient']), 2)} year change with {feature}\"\n",
    "        \n",
    "    # for categorical one hot encoded\n",
    "    elif feature.startswith('prior_region'):\n",
    "        interp_df.loc[\n",
    "            i, title\n",
    "        ] = f\"{np.round((interp_df.loc[i, 'Coefficient']), 2)} year change with {feature}\"\n",
    "\n",
    "    # for categorical one hot encoded\n",
    "    elif feature.startswith('known_for'):\n",
    "        interp_df.loc[\n",
    "            i, title\n",
    "        ] = f\"{np.round((interp_df.loc[i, 'Coefficient']), 2)} year change with {feature}\"\n",
    "    # for numeric not transformed\n",
    "    else:\n",
    "        interp_df.loc[\n",
    "            i, title\n",
    "        ] = f\"{np.round(interp_df.loc[i, 'Coefficient']*10, 2)} year change with 10 unit change in {feature}\"\n",
    "\n",
    "pd.set_option(\"max_colwidth\", 100)\n",
    "interp_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1236e5c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1cd9b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c6bb09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecbe5c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"dunzo!\")\n",
    "\n",
    "# Sound notification when cell executes\n",
    "chime.success()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0271a07f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0f66697e",
   "metadata": {},
   "source": [
    "#### Observations:\n",
    "- We will now save our dataset and pick back up in a new notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1113a242",
   "metadata": {},
   "source": [
    "### Exporting Dataset to SQLite Database [wp_life_expect_clean.db]()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6008ac61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Exporting dataframe\n",
    "\n",
    "# # Saving dataset in a SQLite database\n",
    "# conn = sql.connect(\"wp_life_expect_clean.db\")\n",
    "# df.to_sql(\"wp_life_expect_clean\", conn, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36c0663",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Complete')\n",
    "\n",
    "# Chime notification when cell executes\n",
    "chime.success()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11aacfcc",
   "metadata": {},
   "source": [
    "# [Proceed to Data Cleaning Part ]()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
