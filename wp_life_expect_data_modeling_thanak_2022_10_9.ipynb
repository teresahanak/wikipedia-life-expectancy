{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "316a0779",
   "metadata": {},
   "source": [
    "# Wikipedia Notable Life Expectancies\n",
    "# [Notebook 11: Basic Linear Regression Model ](https://github.com/teresahanak/wikipedia-life-expectancy/blob/main/wp_life_expect_data_modeling_thanak_2022_10_9.ipynb)\n",
    "### Context\n",
    "\n",
    "The\n",
    "### Objective\n",
    "\n",
    "The\n",
    "### Data Dictionary\n",
    "- Feature: Description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99245d51",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "453bba83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1;\n",
       "                var nbb_unformatted_code = \"# To structure code automatically\\n%load_ext nb_black\\n\\n# To import/export sqlite databases\\n# import sqlite3 as sql\\n\\n# To save/open python objects in pickle file\\nimport pickle\\n\\n# To help with reading, cleaning, and manipulating data\\nimport pandas as pd\\nimport numpy as np\\n\\n# To help with data visualization\\nimport matplotlib.pyplot as plt\\nimport seaborn as sns\\n\\n# randomized data splitting\\nfrom sklearn.model_selection import train_test_split\\n\\n# building regression model\\nimport statsmodels.api as sm\\n\\n# check model performance\\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\\n\\n# check linear regression assumptions\\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\\nimport pylab\\nimport scipy.stats as stats\\nimport statsmodels.stats.api as sms\\nfrom statsmodels.compat import lzip\\n\\n# to compare fit between models\\nfrom scipy.stats.distributions import chi2\\n\\n# To define maximum number of columns to be displayed in a dataframe\\npd.set_option(\\\"display.max_columns\\\", None)\\n# To define the maximum number of rows to be displayed in a dataframe\\npd.set_option(\\\"display.max_rows\\\", 211)\\n\\n# To set some dataframe visualization attributes\\npd.set_option(\\\"max_colwidth\\\", 150)\\n\\n# To supress scientific notations for a dataframe\\n# pd.set_option(\\\"display.float_format\\\", lambda x: \\\"%.3f\\\" % x)\\n\\n# To supress warnings\\n# import warnings\\n\\n# warnings.filterwarnings(\\\"ignore\\\")\\n\\n# To set some plot visualization attributes\\nsns.set_theme()\\nsns.set(font_scale=1.4)\\nsns.set_palette(\\n    (\\n        \\\"midnightblue\\\",\\n        \\\"goldenrod\\\",\\n        \\\"maroon\\\",\\n        \\\"darkolivegreen\\\",\\n        \\\"cadetblue\\\",\\n        \\\"tab:purple\\\",\\n        \\\"yellowgreen\\\",\\n    )\\n)\\n# plt.rc(\\\"font\\\", size=12)\\n# plt.rc(\\\"axes\\\", titlesize=15)\\n# plt.rc(\\\"axes\\\", labelsize=14)\\n# plt.rc(\\\"xtick\\\", labelsize=13)\\n# plt.rc(\\\"ytick\\\", labelsize=13)\\n# plt.rc(\\\"legend\\\", fontsize=13)\\n# plt.rc(\\\"legend\\\", fontsize=14)\\n# plt.rc(\\\"figure\\\", titlesize=16)\\n\\n# To play auditory cue when cell has executed, has warning, or has error and set chime theme\\nimport chime\\n\\nchime.theme(\\\"zelda\\\")\";\n",
       "                var nbb_formatted_code = \"# To structure code automatically\\n%load_ext nb_black\\n\\n# To import/export sqlite databases\\n# import sqlite3 as sql\\n\\n# To save/open python objects in pickle file\\nimport pickle\\n\\n# To help with reading, cleaning, and manipulating data\\nimport pandas as pd\\nimport numpy as np\\n\\n# To help with data visualization\\nimport matplotlib.pyplot as plt\\nimport seaborn as sns\\n\\n# randomized data splitting\\nfrom sklearn.model_selection import train_test_split\\n\\n# building regression model\\nimport statsmodels.api as sm\\n\\n# check model performance\\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\\n\\n# check linear regression assumptions\\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\\nimport pylab\\nimport scipy.stats as stats\\nimport statsmodels.stats.api as sms\\nfrom statsmodels.compat import lzip\\n\\n# to compare fit between models\\nfrom scipy.stats.distributions import chi2\\n\\n# To define maximum number of columns to be displayed in a dataframe\\npd.set_option(\\\"display.max_columns\\\", None)\\n# To define the maximum number of rows to be displayed in a dataframe\\npd.set_option(\\\"display.max_rows\\\", 211)\\n\\n# To set some dataframe visualization attributes\\npd.set_option(\\\"max_colwidth\\\", 150)\\n\\n# To supress scientific notations for a dataframe\\n# pd.set_option(\\\"display.float_format\\\", lambda x: \\\"%.3f\\\" % x)\\n\\n# To supress warnings\\n# import warnings\\n\\n# warnings.filterwarnings(\\\"ignore\\\")\\n\\n# To set some plot visualization attributes\\nsns.set_theme()\\nsns.set(font_scale=1.4)\\nsns.set_palette(\\n    (\\n        \\\"midnightblue\\\",\\n        \\\"goldenrod\\\",\\n        \\\"maroon\\\",\\n        \\\"darkolivegreen\\\",\\n        \\\"cadetblue\\\",\\n        \\\"tab:purple\\\",\\n        \\\"yellowgreen\\\",\\n    )\\n)\\n# plt.rc(\\\"font\\\", size=12)\\n# plt.rc(\\\"axes\\\", titlesize=15)\\n# plt.rc(\\\"axes\\\", labelsize=14)\\n# plt.rc(\\\"xtick\\\", labelsize=13)\\n# plt.rc(\\\"ytick\\\", labelsize=13)\\n# plt.rc(\\\"legend\\\", fontsize=13)\\n# plt.rc(\\\"legend\\\", fontsize=14)\\n# plt.rc(\\\"figure\\\", titlesize=16)\\n\\n# To play auditory cue when cell has executed, has warning, or has error and set chime theme\\nimport chime\\n\\nchime.theme(\\\"zelda\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# To structure code automatically\n",
    "%load_ext nb_black\n",
    "\n",
    "# To import/export sqlite databases\n",
    "# import sqlite3 as sql\n",
    "\n",
    "# To save/open python objects in pickle file\n",
    "import pickle\n",
    "\n",
    "# To help with reading, cleaning, and manipulating data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# To help with data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# randomized data splitting\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# building regression model\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# check model performance\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# check linear regression assumptions\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "import pylab\n",
    "import scipy.stats as stats\n",
    "import statsmodels.stats.api as sms\n",
    "from statsmodels.compat import lzip\n",
    "\n",
    "# to compare fit between models\n",
    "from scipy.stats.distributions import chi2\n",
    "\n",
    "# To define maximum number of columns to be displayed in a dataframe\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "# To define the maximum number of rows to be displayed in a dataframe\n",
    "pd.set_option(\"display.max_rows\", 211)\n",
    "\n",
    "# To set some dataframe visualization attributes\n",
    "pd.set_option(\"max_colwidth\", 150)\n",
    "\n",
    "# To supress scientific notations for a dataframe\n",
    "# pd.set_option(\"display.float_format\", lambda x: \"%.3f\" % x)\n",
    "\n",
    "# To supress warnings\n",
    "# import warnings\n",
    "\n",
    "# warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# To set some plot visualization attributes\n",
    "sns.set_theme()\n",
    "sns.set(font_scale=1.4)\n",
    "sns.set_palette(\n",
    "    (\n",
    "        \"midnightblue\",\n",
    "        \"goldenrod\",\n",
    "        \"maroon\",\n",
    "        \"darkolivegreen\",\n",
    "        \"cadetblue\",\n",
    "        \"tab:purple\",\n",
    "        \"yellowgreen\",\n",
    "    )\n",
    ")\n",
    "# plt.rc(\"font\", size=12)\n",
    "# plt.rc(\"axes\", titlesize=15)\n",
    "# plt.rc(\"axes\", labelsize=14)\n",
    "# plt.rc(\"xtick\", labelsize=13)\n",
    "# plt.rc(\"ytick\", labelsize=13)\n",
    "# plt.rc(\"legend\", fontsize=13)\n",
    "# plt.rc(\"legend\", fontsize=14)\n",
    "# plt.rc(\"figure\", titlesize=16)\n",
    "\n",
    "# To play auditory cue when cell has executed, has warning, or has error and set chime theme\n",
    "import chime\n",
    "\n",
    "chime.theme(\"zelda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc818a82",
   "metadata": {},
   "source": [
    "## Data Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed005f6",
   "metadata": {},
   "source": [
    "### [Reading](https://github.com/teresahanak/wikipedia-life-expectancy/blob/main/wp_life_expect_preproc.csv), Sampling, and Checking Data Shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ca58a95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 77661 rows and 6 columns.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>recip_num_references</th>\n",
       "      <th>region</th>\n",
       "      <th>prior_region</th>\n",
       "      <th>known_for</th>\n",
       "      <th>years</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>73.0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>Europe</td>\n",
       "      <td>No Prior Region</td>\n",
       "      <td>spiritual</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>North America</td>\n",
       "      <td>No Prior Region</td>\n",
       "      <td>two</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  recip_num_references         region     prior_region  known_for  \\\n",
       "0  73.0              0.250000         Europe  No Prior Region  spiritual   \n",
       "1  90.0              0.333333  North America  No Prior Region        two   \n",
       "\n",
       "   years  \n",
       "0      8  \n",
       "1     13  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2;\n",
       "                var nbb_unformatted_code = \"# Reading the train set\\ndata = pd.read_csv(\\\"wp_life_expect_preproc.csv\\\")\\n\\n# Making a working copy\\ndf = data.copy()\\n\\n# Checking the shape\\nprint(f\\\"There are {df.shape[0]} rows and {df.shape[1]} columns.\\\")\\n\\n# Checking first 2 rows of the data\\ndf.head(2)\";\n",
       "                var nbb_formatted_code = \"# Reading the train set\\ndata = pd.read_csv(\\\"wp_life_expect_preproc.csv\\\")\\n\\n# Making a working copy\\ndf = data.copy()\\n\\n# Checking the shape\\nprint(f\\\"There are {df.shape[0]} rows and {df.shape[1]} columns.\\\")\\n\\n# Checking first 2 rows of the data\\ndf.head(2)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Reading the train set\n",
    "data = pd.read_csv(\"wp_life_expect_preproc.csv\")\n",
    "\n",
    "# Making a working copy\n",
    "df = data.copy()\n",
    "\n",
    "# Checking the shape\n",
    "print(f\"There are {df.shape[0]} rows and {df.shape[1]} columns.\")\n",
    "\n",
    "# Checking first 2 rows of the data\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6cca416f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>recip_num_references</th>\n",
       "      <th>region</th>\n",
       "      <th>prior_region</th>\n",
       "      <th>known_for</th>\n",
       "      <th>years</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>77659</th>\n",
       "      <td>74.0</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>North America</td>\n",
       "      <td>No Prior Region</td>\n",
       "      <td>arts</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77660</th>\n",
       "      <td>92.0</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>Europe</td>\n",
       "      <td>No Prior Region</td>\n",
       "      <td>sports</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age  recip_num_references         region     prior_region known_for  \\\n",
       "77659  74.0              0.142857  North America  No Prior Region      arts   \n",
       "77660  92.0              0.200000         Europe  No Prior Region    sports   \n",
       "\n",
       "       years  \n",
       "77659      0  \n",
       "77660      8  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 3;\n",
       "                var nbb_unformatted_code = \"# Checking last 2 rows of the data\\ndf.tail(2)\";\n",
       "                var nbb_formatted_code = \"# Checking last 2 rows of the data\\ndf.tail(2)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Checking last 2 rows of the data\n",
    "df.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de6e8ee5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>recip_num_references</th>\n",
       "      <th>region</th>\n",
       "      <th>prior_region</th>\n",
       "      <th>known_for</th>\n",
       "      <th>years</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>56572</th>\n",
       "      <td>89.0</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>North America</td>\n",
       "      <td>No Prior Region</td>\n",
       "      <td>arts</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66438</th>\n",
       "      <td>88.0</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>North America</td>\n",
       "      <td>No Prior Region</td>\n",
       "      <td>spiritual</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19698</th>\n",
       "      <td>85.0</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>North America</td>\n",
       "      <td>No Prior Region</td>\n",
       "      <td>arts</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44706</th>\n",
       "      <td>83.0</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>Middle East</td>\n",
       "      <td>No Prior Region</td>\n",
       "      <td>academia_humanities</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13590</th>\n",
       "      <td>89.0</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>Europe</td>\n",
       "      <td>No Prior Region</td>\n",
       "      <td>arts</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age  recip_num_references         region     prior_region  \\\n",
       "56572  89.0              0.200000  North America  No Prior Region   \n",
       "66438  88.0              0.066667  North America  No Prior Region   \n",
       "19698  85.0              0.142857  North America  No Prior Region   \n",
       "44706  83.0              0.029412    Middle East  No Prior Region   \n",
       "13590  89.0              0.142857         Europe  No Prior Region   \n",
       "\n",
       "                 known_for  years  \n",
       "56572                 arts     23  \n",
       "66438            spiritual     21  \n",
       "19698                 arts      5  \n",
       "44706  academia_humanities     21  \n",
       "13590                 arts      9  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 4;\n",
       "                var nbb_unformatted_code = \"# Checking a sample of the data\\ndf.sample(5)\";\n",
       "                var nbb_formatted_code = \"# Checking a sample of the data\\ndf.sample(5)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Checking a sample of the data\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d5f29da",
   "metadata": {},
   "source": [
    "### Checking Data Types and Null Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf505f87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 77661 entries, 0 to 77660\n",
      "Data columns (total 6 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   age                   77661 non-null  float64\n",
      " 1   recip_num_references  77661 non-null  float64\n",
      " 2   region                77661 non-null  object \n",
      " 3   prior_region          77661 non-null  object \n",
      " 4   known_for             77661 non-null  object \n",
      " 5   years                 77661 non-null  int64  \n",
      "dtypes: float64(2), int64(1), object(3)\n",
      "memory usage: 3.6+ MB\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 5;\n",
       "                var nbb_unformatted_code = \"# Checking data types and null values\\ndf.info()\";\n",
       "                var nbb_formatted_code = \"# Checking data types and null values\\ndf.info()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Checking data types and null values\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c459d7f8",
   "metadata": {},
   "source": [
    "#### Observations:\n",
    "- With our dataset loaded, we are ready for modeling.\n",
    "- We have two variables that need typcasting from object to category, then one hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c387ce6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No Prior Region               73352\n",
       "Europe                         2326\n",
       "North America                   432\n",
       "Asia                            341\n",
       "Russian Federation              279\n",
       "Africa                          242\n",
       "Mid-Cent America/Caribbean      202\n",
       "Middle East                     176\n",
       "Oceania                         136\n",
       "South America                   109\n",
       "South East Asia                  58\n",
       "Central Asia                      8\n",
       "Name: prior_region, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 6;\n",
       "                var nbb_unformatted_code = \"df[\\\"prior_region\\\"].value_counts()\";\n",
       "                var nbb_formatted_code = \"df[\\\"prior_region\\\"].value_counts()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df[\"prior_region\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c542ec1",
   "metadata": {},
   "source": [
    "#### Typecasting `prior_region` and `region` as Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "87fccaff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 77661 entries, 0 to 77660\n",
      "Data columns (total 6 columns):\n",
      " #   Column                Non-Null Count  Dtype   \n",
      "---  ------                --------------  -----   \n",
      " 0   age                   77661 non-null  float64 \n",
      " 1   recip_num_references  77661 non-null  float64 \n",
      " 2   region                77661 non-null  category\n",
      " 3   prior_region          77661 non-null  category\n",
      " 4   known_for             77661 non-null  object  \n",
      " 5   years                 77661 non-null  int64   \n",
      "dtypes: category(2), float64(2), int64(1), object(1)\n",
      "memory usage: 2.5+ MB\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 7;\n",
       "                var nbb_unformatted_code = \"# Typcasting prior_region and region as categorical\\ndf[[\\\"prior_region\\\", \\\"region\\\"]] = df[[\\\"prior_region\\\", \\\"region\\\"]].astype(\\\"category\\\")\\n\\n# Re-check info\\ndf.info()\";\n",
       "                var nbb_formatted_code = \"# Typcasting prior_region and region as categorical\\ndf[[\\\"prior_region\\\", \\\"region\\\"]] = df[[\\\"prior_region\\\", \\\"region\\\"]].astype(\\\"category\\\")\\n\\n# Re-check info\\ndf.info()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Typcasting prior_region and region as categorical\n",
    "df[[\"prior_region\", \"region\"]] = df[[\"prior_region\", \"region\"]].astype(\"category\")\n",
    "\n",
    "# Re-check info\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4804e77f",
   "metadata": {},
   "source": [
    "## Building a Linear Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176c405c",
   "metadata": {},
   "source": [
    "### Data Preparation for Modeling\n",
    "As there is no model tuning in this basic linear regression model, we can train directly with the `train` set and check performance direclty on the `test` set.  We will need to do the appropriate treatments on the `test` set first."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c14b3ab",
   "metadata": {},
   "source": [
    "### Test Set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9e1840",
   "metadata": {},
   "source": [
    "#### Loading [Test Set](https://github.com/teresahanak/wikipedia-life-expectancy/blob/main/wp_life_expect_test.csv) and [region_place_dict](https://github.com/teresahanak/wikipedia-life-expectancy/blob/main/region_place_dict.pkl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a0214f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 19608 rows and 25 columns.\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 8;\n",
       "                var nbb_unformatted_code = \"# Reading test.csv\\ntest = pd.read_csv(\\\"wp_life_expect_test.csv\\\")\\n\\n# Checking shape\\nprint(f\\\"There are {test.shape[0]} rows and {test.shape[1]} columns.\\\")\\n\\n# Loading region_place_dict\\nwith open(\\\"region_place_dict.pkl\\\", \\\"rb\\\") as f:\\n    region_place_dict = pickle.load(f)\";\n",
       "                var nbb_formatted_code = \"# Reading test.csv\\ntest = pd.read_csv(\\\"wp_life_expect_test.csv\\\")\\n\\n# Checking shape\\nprint(f\\\"There are {test.shape[0]} rows and {test.shape[1]} columns.\\\")\\n\\n# Loading region_place_dict\\nwith open(\\\"region_place_dict.pkl\\\", \\\"rb\\\") as f:\\n    region_place_dict = pickle.load(f)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Reading test.csv\n",
    "test = pd.read_csv(\"wp_life_expect_test.csv\")\n",
    "\n",
    "# Checking shape\n",
    "print(f\"There are {test.shape[0]} rows and {test.shape[1]} columns.\")\n",
    "\n",
    "# Loading region_place_dict\n",
    "with open(\"region_place_dict.pkl\", \"rb\") as f:\n",
    "    region_place_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eba2f22f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 19608 entries, 0 to 19607\n",
      "Data columns (total 25 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   day                        19608 non-null  int64  \n",
      " 1   name                       19608 non-null  object \n",
      " 2   info                       19608 non-null  object \n",
      " 3   link                       19608 non-null  object \n",
      " 4   num_references             19608 non-null  int64  \n",
      " 5   year                       19608 non-null  int64  \n",
      " 6   month                      19608 non-null  object \n",
      " 7   info_parenth               6832 non-null   object \n",
      " 8   age                        19608 non-null  float64\n",
      " 9   cause_of_death             6641 non-null   object \n",
      " 10  place_1                    19580 non-null  object \n",
      " 11  place_2                    1193 non-null   object \n",
      " 12  sciences                   19608 non-null  int64  \n",
      " 13  social                     19608 non-null  int64  \n",
      " 14  spiritual                  19608 non-null  int64  \n",
      " 15  academia_humanities        19608 non-null  int64  \n",
      " 16  business_farming           19608 non-null  int64  \n",
      " 17  arts                       19608 non-null  int64  \n",
      " 18  sports                     19608 non-null  int64  \n",
      " 19  law_enf_military_operator  19608 non-null  int64  \n",
      " 20  politics_govt_law          19608 non-null  int64  \n",
      " 21  crime                      19608 non-null  int64  \n",
      " 22  event_record_other         19608 non-null  int64  \n",
      " 23  other_species              19608 non-null  int64  \n",
      " 24  num_categories             19608 non-null  int64  \n",
      "dtypes: float64(1), int64(16), object(8)\n",
      "memory usage: 3.7+ MB\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 9;\n",
       "                var nbb_unformatted_code = \"# Checking info\\ntest.info()\";\n",
       "                var nbb_formatted_code = \"# Checking info\\ntest.info()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Checking info\n",
    "test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d04b53",
   "metadata": {},
   "source": [
    "#### Pre-processing Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dcd1344e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 19430 entries, 0 to 19429\n",
      "Data columns (total 6 columns):\n",
      " #   Column                Non-Null Count  Dtype   \n",
      "---  ------                --------------  -----   \n",
      " 0   age                   19430 non-null  float64 \n",
      " 1   recip_num_references  19430 non-null  float64 \n",
      " 2   region                19410 non-null  category\n",
      " 3   prior_region          19430 non-null  category\n",
      " 4   known_for             19430 non-null  object  \n",
      " 5   years                 19430 non-null  int64   \n",
      "dtypes: category(2), float64(2), int64(1), object(1)\n",
      "memory usage: 646.0+ KB\n",
      "CPU times: total: 10.6 s\n",
      "Wall time: 10.7 s\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 19;\n",
       "                var nbb_unformatted_code = \"%%time\\n\\n# 1. Dropping non-human entries\\nrows_to_drop = test[test[\\\"other_species\\\"] == 1].index\\ntest.drop(rows_to_drop, inplace=True)\\ntest.reset_index(inplace=True, drop=True)\\n\\n# 2. Dropping entries with event_record_other as sole category\\nrows_to_drop = test[(test['event_record_other']==1) & (test['num_categories']==1)].index\\ntest.drop(rows_to_drop, inplace=True)\\ntest.reset_index(inplace=True, drop=True)\\n\\n# 3. Creating recip_num_references column\\ntest[\\\"recip_num_references\\\"] = test[\\\"num_references\\\"].apply(lambda x: 1 / x)\\n\\n# 4. Creating region column\\n# Dropping place_2 values that are duplicates of place_1\\nindex = [\\n    index\\n    for index in test.index\\n    if test.loc[index, \\\"place_2\\\"] == test.loc[index, \\\"place_1\\\"]\\n]\\ntest.loc[index, \\\"place_2\\\"] = None\\n\\n# For loop to create region column\\ntest[\\\"region\\\"] = None\\nfor region, places in region_place_dict.items():\\n    for place in places:\\n        for index in test[(test[\\\"region\\\"].isna()) & (test[\\\"place_2\\\"].notna())].index:\\n            item = test.loc[index, \\\"place_2\\\"]\\n            if item:\\n                if item == place:\\n                    test.loc[index, \\\"region\\\"] = region\\n        for index in test[(test[\\\"region\\\"].isna()) & (test[\\\"place_2\\\"].isna())].index:\\n            item = test.loc[index, \\\"place_1\\\"]\\n            if item:\\n                if item == place:\\n                    test.loc[index, \\\"region\\\"] = region\\n\\n# 5. Creating prior_region column\\n# For loop to create prior_region column\\ntest[\\\"prior_region\\\"] = None\\nfor region, places in region_place_dict.items():\\n    for place in places:\\n        for index in test[\\n            (test[\\\"place_2\\\"].notna()) & (test[\\\"prior_region\\\"].isna())\\n        ].index:\\n            item = test.loc[index, \\\"place_1\\\"]\\n            if item:\\n                if item == place:\\n                    test.loc[index, \\\"prior_region\\\"] = region\\n# Adding No Prior Region category\\ntest[\\\"prior_region\\\"].fillna(\\\"No Prior Region\\\", inplace=True)\\n\\n# 6. Typecasting region and prior region as category\\ntest[['region', 'prior_region']] = test[['region', 'prior_region']].astype('category')\\n\\n# 7. Creating known_for column\\n# Initializing known_for\\ntest['known_for']=None\\n# List of known for columns\\ncols = ['sciences', 'social', 'spiritual', 'academia_humanities',\\n       'business_farming', 'arts', 'sports', 'law_enf_military_operator',\\n       'politics_govt_law', 'crime', 'event_record_other', 'other_species']\\n# For loop to assign known_for\\nfor index in test[test['known_for'].isna()].index:\\n    if test.loc[index, 'num_categories']==2:\\n        test.loc[index, 'known_for'] = 'two'\\n    elif test.loc[index, 'num_categories'] > 2:\\n        test.loc[index, 'known_for'] = 'three_to_five'\\n    else: \\n        for column in cols:\\n            if test.loc[index, column]==1:\\n                test.loc[index, 'known_for'] = column\\n\\n# 8. Creating years column\\ntest[\\\"years\\\"] = test[\\\"year\\\"].apply(lambda x: x - 1994)\\n\\n# 9. Dropping Unnecessary Columns\\ncols_to_drop = [\\n   'day', 'name', 'info', 'link', 'num_references', 'year', 'month',\\n       'info_parenth', 'cause_of_death', 'place_1', 'place_2',\\n       'sciences', 'social', 'spiritual', 'academia_humanities',\\n       'business_farming', 'arts', 'sports', 'law_enf_military_operator',\\n       'politics_govt_law', 'crime', 'event_record_other', 'other_species',\\n       'num_categories', \\n]\\ntest.drop(cols_to_drop, axis=1, inplace=True)\\n\\n# Rechecking columns\\ntest.info()\";\n",
       "                var nbb_formatted_code = \"%%time\\n\\n# 1. Dropping non-human entries\\nrows_to_drop = test[test[\\\"other_species\\\"] == 1].index\\ntest.drop(rows_to_drop, inplace=True)\\ntest.reset_index(inplace=True, drop=True)\\n\\n# 2. Dropping entries with event_record_other as sole category\\nrows_to_drop = test[(test['event_record_other']==1) & (test['num_categories']==1)].index\\ntest.drop(rows_to_drop, inplace=True)\\ntest.reset_index(inplace=True, drop=True)\\n\\n# 3. Creating recip_num_references column\\ntest[\\\"recip_num_references\\\"] = test[\\\"num_references\\\"].apply(lambda x: 1 / x)\\n\\n# 4. Creating region column\\n# Dropping place_2 values that are duplicates of place_1\\nindex = [\\n    index\\n    for index in test.index\\n    if test.loc[index, \\\"place_2\\\"] == test.loc[index, \\\"place_1\\\"]\\n]\\ntest.loc[index, \\\"place_2\\\"] = None\\n\\n# For loop to create region column\\ntest[\\\"region\\\"] = None\\nfor region, places in region_place_dict.items():\\n    for place in places:\\n        for index in test[(test[\\\"region\\\"].isna()) & (test[\\\"place_2\\\"].notna())].index:\\n            item = test.loc[index, \\\"place_2\\\"]\\n            if item:\\n                if item == place:\\n                    test.loc[index, \\\"region\\\"] = region\\n        for index in test[(test[\\\"region\\\"].isna()) & (test[\\\"place_2\\\"].isna())].index:\\n            item = test.loc[index, \\\"place_1\\\"]\\n            if item:\\n                if item == place:\\n                    test.loc[index, \\\"region\\\"] = region\\n\\n# 5. Creating prior_region column\\n# For loop to create prior_region column\\ntest[\\\"prior_region\\\"] = None\\nfor region, places in region_place_dict.items():\\n    for place in places:\\n        for index in test[\\n            (test[\\\"place_2\\\"].notna()) & (test[\\\"prior_region\\\"].isna())\\n        ].index:\\n            item = test.loc[index, \\\"place_1\\\"]\\n            if item:\\n                if item == place:\\n                    test.loc[index, \\\"prior_region\\\"] = region\\n# Adding No Prior Region category\\ntest[\\\"prior_region\\\"].fillna(\\\"No Prior Region\\\", inplace=True)\\n\\n# 6. Typecasting region and prior region as category\\ntest[['region', 'prior_region']] = test[['region', 'prior_region']].astype('category')\\n\\n# 7. Creating known_for column\\n# Initializing known_for\\ntest['known_for']=None\\n# List of known for columns\\ncols = ['sciences', 'social', 'spiritual', 'academia_humanities',\\n       'business_farming', 'arts', 'sports', 'law_enf_military_operator',\\n       'politics_govt_law', 'crime', 'event_record_other', 'other_species']\\n# For loop to assign known_for\\nfor index in test[test['known_for'].isna()].index:\\n    if test.loc[index, 'num_categories']==2:\\n        test.loc[index, 'known_for'] = 'two'\\n    elif test.loc[index, 'num_categories'] > 2:\\n        test.loc[index, 'known_for'] = 'three_to_five'\\n    else: \\n        for column in cols:\\n            if test.loc[index, column]==1:\\n                test.loc[index, 'known_for'] = column\\n\\n# 8. Creating years column\\ntest[\\\"years\\\"] = test[\\\"year\\\"].apply(lambda x: x - 1994)\\n\\n# 9. Dropping Unnecessary Columns\\ncols_to_drop = [\\n   'day', 'name', 'info', 'link', 'num_references', 'year', 'month',\\n       'info_parenth', 'cause_of_death', 'place_1', 'place_2',\\n       'sciences', 'social', 'spiritual', 'academia_humanities',\\n       'business_farming', 'arts', 'sports', 'law_enf_military_operator',\\n       'politics_govt_law', 'crime', 'event_record_other', 'other_species',\\n       'num_categories', \\n]\\ntest.drop(cols_to_drop, axis=1, inplace=True)\\n\\n# Rechecking columns\\ntest.info()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# 1. Dropping non-human entries\n",
    "rows_to_drop = test[test[\"other_species\"] == 1].index\n",
    "test.drop(rows_to_drop, inplace=True)\n",
    "test.reset_index(inplace=True, drop=True)\n",
    "\n",
    "# 2. Dropping entries with event_record_other as sole category\n",
    "rows_to_drop = test[(test['event_record_other']==1) & (test['num_categories']==1)].index\n",
    "test.drop(rows_to_drop, inplace=True)\n",
    "test.reset_index(inplace=True, drop=True)\n",
    "\n",
    "# 3. Creating recip_num_references column\n",
    "test[\"recip_num_references\"] = test[\"num_references\"].apply(lambda x: 1 / x)\n",
    "\n",
    "# 4. Creating region column\n",
    "# Dropping place_2 values that are duplicates of place_1\n",
    "index = [\n",
    "    index\n",
    "    for index in test.index\n",
    "    if test.loc[index, \"place_2\"] == test.loc[index, \"place_1\"]\n",
    "]\n",
    "test.loc[index, \"place_2\"] = None\n",
    "\n",
    "# For loop to create region column\n",
    "test[\"region\"] = None\n",
    "for region, places in region_place_dict.items():\n",
    "    for place in places:\n",
    "        for index in test[(test[\"region\"].isna()) & (test[\"place_2\"].notna())].index:\n",
    "            item = test.loc[index, \"place_2\"]\n",
    "            if item:\n",
    "                if item == place:\n",
    "                    test.loc[index, \"region\"] = region\n",
    "        for index in test[(test[\"region\"].isna()) & (test[\"place_2\"].isna())].index:\n",
    "            item = test.loc[index, \"place_1\"]\n",
    "            if item:\n",
    "                if item == place:\n",
    "                    test.loc[index, \"region\"] = region\n",
    "\n",
    "# 5. Creating prior_region column\n",
    "# For loop to create prior_region column\n",
    "test[\"prior_region\"] = None\n",
    "for region, places in region_place_dict.items():\n",
    "    for place in places:\n",
    "        for index in test[\n",
    "            (test[\"place_2\"].notna()) & (test[\"prior_region\"].isna())\n",
    "        ].index:\n",
    "            item = test.loc[index, \"place_1\"]\n",
    "            if item:\n",
    "                if item == place:\n",
    "                    test.loc[index, \"prior_region\"] = region\n",
    "# Adding No Prior Region category\n",
    "test[\"prior_region\"].fillna(\"No Prior Region\", inplace=True)\n",
    "\n",
    "# 6. Typecasting region and prior region as category\n",
    "test[['region', 'prior_region']] = test[['region', 'prior_region']].astype('category')\n",
    "\n",
    "# 7. Creating known_for column\n",
    "# Initializing known_for\n",
    "test['known_for']=None\n",
    "# List of known for columns\n",
    "cols = ['sciences', 'social', 'spiritual', 'academia_humanities',\n",
    "       'business_farming', 'arts', 'sports', 'law_enf_military_operator',\n",
    "       'politics_govt_law', 'crime', 'event_record_other', 'other_species']\n",
    "# For loop to assign known_for\n",
    "for index in test[test['known_for'].isna()].index:\n",
    "    if test.loc[index, 'num_categories']==2:\n",
    "        test.loc[index, 'known_for'] = 'two'\n",
    "    elif test.loc[index, 'num_categories'] > 2:\n",
    "        test.loc[index, 'known_for'] = 'three_to_five'\n",
    "    else: \n",
    "        for column in cols:\n",
    "            if test.loc[index, column]==1:\n",
    "                test.loc[index, 'known_for'] = column\n",
    "\n",
    "# 8. Creating years column\n",
    "test[\"years\"] = test[\"year\"].apply(lambda x: x - 1994)\n",
    "\n",
    "# 9. Dropping Unnecessary Columns\n",
    "cols_to_drop = [\n",
    "   'day', 'name', 'info', 'link', 'num_references', 'year', 'month',\n",
    "       'info_parenth', 'cause_of_death', 'place_1', 'place_2',\n",
    "       'sciences', 'social', 'spiritual', 'academia_humanities',\n",
    "       'business_farming', 'arts', 'sports', 'law_enf_military_operator',\n",
    "       'politics_govt_law', 'crime', 'event_record_other', 'other_species',\n",
    "       'num_categories', \n",
    "]\n",
    "test.drop(cols_to_drop, axis=1, inplace=True)\n",
    "\n",
    "# Rechecking columns\n",
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "52e3a1c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>recip_num_references</th>\n",
       "      <th>region</th>\n",
       "      <th>prior_region</th>\n",
       "      <th>known_for</th>\n",
       "      <th>years</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17169</th>\n",
       "      <td>73.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>Europe</td>\n",
       "      <td>No Prior Region</td>\n",
       "      <td>sciences</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5219</th>\n",
       "      <td>66.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>North America</td>\n",
       "      <td>No Prior Region</td>\n",
       "      <td>arts</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10469</th>\n",
       "      <td>78.0</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>Asia</td>\n",
       "      <td>No Prior Region</td>\n",
       "      <td>two</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5893</th>\n",
       "      <td>91.0</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>Europe</td>\n",
       "      <td>No Prior Region</td>\n",
       "      <td>two</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981</th>\n",
       "      <td>92.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>Europe</td>\n",
       "      <td>No Prior Region</td>\n",
       "      <td>arts</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3535</th>\n",
       "      <td>88.0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>Europe</td>\n",
       "      <td>No Prior Region</td>\n",
       "      <td>sports</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4905</th>\n",
       "      <td>77.0</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>North America</td>\n",
       "      <td>No Prior Region</td>\n",
       "      <td>arts</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5665</th>\n",
       "      <td>85.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>Europe</td>\n",
       "      <td>No Prior Region</td>\n",
       "      <td>sports</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6997</th>\n",
       "      <td>86.0</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>North America</td>\n",
       "      <td>No Prior Region</td>\n",
       "      <td>arts</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3153</th>\n",
       "      <td>67.0</td>\n",
       "      <td>0.017544</td>\n",
       "      <td>North America</td>\n",
       "      <td>No Prior Region</td>\n",
       "      <td>arts</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age  recip_num_references         region     prior_region known_for  \\\n",
       "17169  73.0              0.166667         Europe  No Prior Region  sciences   \n",
       "5219   66.0              0.166667  North America  No Prior Region      arts   \n",
       "10469  78.0              0.052632           Asia  No Prior Region       two   \n",
       "5893   91.0              0.200000         Europe  No Prior Region       two   \n",
       "1981   92.0              0.333333         Europe  No Prior Region      arts   \n",
       "3535   88.0              0.250000         Europe  No Prior Region    sports   \n",
       "4905   77.0              0.055556  North America  No Prior Region      arts   \n",
       "5665   85.0              0.166667         Europe  No Prior Region    sports   \n",
       "6997   86.0              0.016667  North America  No Prior Region      arts   \n",
       "3153   67.0              0.017544  North America  No Prior Region      arts   \n",
       "\n",
       "       years  \n",
       "17169     16  \n",
       "5219       8  \n",
       "10469     27  \n",
       "5893      11  \n",
       "1981      26  \n",
       "3535      25  \n",
       "4905      25  \n",
       "5665       2  \n",
       "6997      17  \n",
       "3153      16  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 21;\n",
       "                var nbb_unformatted_code = \"# Checking a sample\\ntest.sample(10)\";\n",
       "                var nbb_formatted_code = \"# Checking a sample\\ntest.sample(10)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Checking a sample of rows\n",
    "test.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8168b5",
   "metadata": {},
   "source": [
    "#### Observations:\n",
    "- Treatment of `test` missing values is the only remaining step.\n",
    "- We will use the modes for the `known_for` groups from `train` to fill missing values for `test` to avoid data leakage.  `region` is the only column with missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221f578f",
   "metadata": {},
   "source": [
    "#### Treating Missing Values for `region` in Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cf531d45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 20 missing values.\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 22;\n",
       "                var nbb_unformatted_code = \"# Checking the starting missing values\\nprint(f'There are {test[\\\"region\\\"].isna().sum()} missing values.')\";\n",
       "                var nbb_formatted_code = \"# Checking the starting missing values\\nprint(f'There are {test[\\\"region\\\"].isna().sum()} missing values.')\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Checking the starting missing values\n",
    "print(f'There are {test[\"region\"].isna().sum()} missing values.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5092b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For loop to impute test missing values with mode of train rows with matching sole known for category\n",
    "null_col = \"region\"\n",
    "group_rows = df[df[column] == 1].index.tolist()\n",
    "    group_mode = df.loc[group_rows, null_col].mode()[0]\n",
    "\n",
    "    for index in test[test.isna()].index:\n",
    "        if test.loc[index, column] == 1:\n",
    "            test.loc[index, \"region\"] = group_mode\n",
    "\n",
    "# Imputing missing values with train column mode for remaining entries with multiple known for categories\n",
    "column_mode = df[null_col].mode()[0]\n",
    "test[null_col].fillna(column_mode, inplace=True)\n",
    "\n",
    "# Checking the starting missing values\n",
    "print(f'There are {test[\"region\"].isna().sum()} missing values.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf4e183",
   "metadata": {},
   "source": [
    "#### Observations:\n",
    "- `train` and `test` are both ready for modeling.\n",
    "- We will perform one hot encoding when defining our independent variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23403783",
   "metadata": {},
   "source": [
    "#### Defining Independent and Dependent Variables for Train and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2216c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining independent and dependent variables\n",
    "X_train, X_test = df.drop(\"age\", axis=1), test.drop(\"age\", axis=1)\n",
    "y_train, y_test = df[\"age\"], test[\"age\"]\n",
    "\n",
    "\n",
    "# One hot encoding independent categorical features\n",
    "X_train = pd.get_dummies(X_train, drop_first=True)\n",
    "X_test = pd.get_dummies(X_test, drop_first=True)\n",
    "\n",
    "# Adding the intercept\n",
    "X_train = sm.add_constant(X_train)\n",
    "X_test = sm.add_constant(X_test)\n",
    "\n",
    "# Typecasting independent variables as float\n",
    "X_train = X_train.astype(\"float64\")\n",
    "X_test = X_test.astype(\"float64\")\n",
    "\n",
    "# Checking shape of train and test sets\n",
    "print(f\"There are {X_train.shape[0]} rows and {X_train.shape[1]} columns in X_train.\")\n",
    "print(f\"There are {X_test.shape[0]} rows and {X_test.shape[1]} columns in X_test.\\n\")\n",
    "\n",
    "# Checking a sample of train set\n",
    "X_train.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "598a53f2",
   "metadata": {},
   "source": [
    "#### Observations:\n",
    "- We are ready to build our model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e86a0713",
   "metadata": {},
   "source": [
    "### Fitting a Linear Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa7c7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting a linear model and displaying model summary\n",
    "olsmodel = sm.OLS(y_train, X_train).fit()\n",
    "print(olsmodel.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ef7379",
   "metadata": {},
   "source": [
    "### Model Performance Check"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be442673",
   "metadata": {},
   "source": [
    "#### Functions to check model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815c33f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to compute adjusted R-squared\n",
    "def adj_r2_score(predictors, targets, predictions):\n",
    "    r2 = r2_score(targets, predictions)\n",
    "    n = predictors.shape[0]\n",
    "    k = predictors.shape[1]\n",
    "    return 1 - ((1 - r2) * (n - 1) / (n - k - 1))\n",
    "\n",
    "\n",
    "# function to compute MAPE\n",
    "def mape_score(targets, predictions):\n",
    "    return np.mean(np.abs((targets - predictions) / targets)) * 100\n",
    "\n",
    "\n",
    "# function to compute and display different metrics to check performance of a regression model\n",
    "# with conversion back to original scale for RMSE, MAE, and MAPE for ease of explainability\n",
    "def model_performance_regression(model, predictors, target):\n",
    "    \"\"\"\n",
    "    Function to compute and return a dataframe of different metrics to check\n",
    "    regression model performance\n",
    "    \n",
    "    model: regressor\n",
    "    predictors: independent variables\n",
    "    target: dependent variable\n",
    "    \"\"\"\n",
    "    # predictions\n",
    "    pred = model.predict(predictors)\n",
    "\n",
    "    r2 = r2_score(target, pred)  # to compute R-squared\n",
    "    adjr2 = adj_r2_score(predictors, target, pred)  # to compute adjusted R-squared\n",
    "    rmse = np.sqrt(mean_squared_error(target, pred))  # to compute RMSE\n",
    "    mae = mean_absolute_error(target, pred)  # to compute MAE\n",
    "    mape = mape_score(target, pred)  # to compute MAPE\n",
    "\n",
    "    # creating a dataframe of metrics\n",
    "    df_perf = pd.DataFrame(\n",
    "        {\n",
    "            \"RMSE\": rmse,\n",
    "            \"MAE\": mae,\n",
    "            \"R-squared\": r2,\n",
    "            \"Adj. R-squared\": adjr2,\n",
    "            \"MAPE\": mape,\n",
    "        },\n",
    "        index=[0],\n",
    "    )\n",
    "\n",
    "    return df_perf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "738385af",
   "metadata": {},
   "source": [
    "#### Model Performance on Train Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c19a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking model performance on train set\n",
    "print(\"Training Performance\\n\")\n",
    "olsmodel_train_perf = model_performance_regression(olsmodel, X_train, y_train)\n",
    "olsmodel_train_perf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46dbdf32",
   "metadata": {},
   "source": [
    "### Model Performance on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d45f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking model performance on validation set\n",
    "print(\"Test Peformance\\n\")\n",
    "olsmodel_test_perf = model_performance_regression(olsmodel, X_test, y_test)\n",
    "olsmodel_test_perf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a15e44",
   "metadata": {},
   "source": [
    "#### Observations:\n",
    "- The train and test $R^2$ are 0.098 and 0.066, respectively, indicating that the model explains 9.8% of total variation in the train set and 6.6% of variation in the test set, so very little.\n",
    "- RMSE values for the two sets are comparable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e498339",
   "metadata": {},
   "source": [
    "### Checking Linear Regression Assumptions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0dd4c8f",
   "metadata": {},
   "source": [
    "### Test for Multicollinearity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5caeb86",
   "metadata": {},
   "source": [
    "#### Function to check VIF of Each Independent Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45eb9177",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to check and display VIF of each independent variable\n",
    "def checking_vif(predictors):\n",
    "    \"\"\"\n",
    "    Takes input dependent variables predictors and returns\n",
    "    a dataframe of variable name and VIF\n",
    "    \"\"\"\n",
    "    vif = pd.DataFrame()\n",
    "    vif[\"feature\"] = predictors.columns\n",
    "\n",
    "    # calculating VIF for each feature\n",
    "    vif[\"VIF\"] = [\n",
    "        variance_inflation_factor(predictors.values, i)\n",
    "        for i in range(len(predictors.columns))\n",
    "    ]\n",
    "    return vif"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f6e35b",
   "metadata": {},
   "source": [
    "#### VIF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5591c46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking vif\n",
    "vif = checking_vif(X_train).sort_values(by=\"VIF\", ascending=False)\n",
    "vif"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a3ca177",
   "metadata": {},
   "source": [
    "#### Function to Treat Multicollinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b38a46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def treating_multicollinearity(predictors, target, high_vif_columns):\n",
    "    \"\"\"\n",
    "    Checking the effect of dropping the columns showing high multicollinearity\n",
    "    on model performance (adj. R-squared and RMSE)\n",
    "\n",
    "    predictors: independent variables\n",
    "    target: dependent variable\n",
    "    high_vif_columns: columns having high VIF\n",
    "    \"\"\"\n",
    "    # empty lists to store adj. R-squared and RMSE values\n",
    "    adj_r2 = []\n",
    "    rmse = []\n",
    "\n",
    "    # build ols models by dropping one of the high VIF columns at a time\n",
    "    # store the adjusted R-squared and RMSE in the lists defined previously\n",
    "    for cols in high_vif_columns:\n",
    "        # defining the new train set\n",
    "        train = predictors.loc[:, ~predictors.columns.str.startswith(cols)]\n",
    "\n",
    "        # create the model\n",
    "        olsmodel = sm.OLS(target, train).fit()\n",
    "\n",
    "        # adding adj. R-squared and RMSE to the lists\n",
    "        adj_r2.append(olsmodel.rsquared_adj)\n",
    "        rmse.append(np.sqrt(olsmodel.mse_resid))\n",
    "\n",
    "    # creating a dataframe for the results\n",
    "    temp = pd.DataFrame(\n",
    "        {\n",
    "            \"col\": high_vif_columns,\n",
    "            \"Adj. R-squared after_dropping col\": adj_r2,\n",
    "            \"RMSE after dropping col\": rmse,\n",
    "        }\n",
    "    ).sort_values(by=\"Adj. R-squared after_dropping col\", ascending=False)\n",
    "    temp.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe878568",
   "metadata": {},
   "source": [
    "#### Checking Impact of Dropping Columns on Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9147ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking impact of dropping columns\n",
    "col_list = vif[vif[\"VIF\"] >= 5][\"feature\"].tolist()\n",
    "\n",
    "results = treating_multicollinearity(X_train, y_train, col_list)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a9595fb",
   "metadata": {},
   "source": [
    "#### Dropping `event_record_other`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eecac674",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping event_record_other column\n",
    "col_to_drop = \"event_record_other\"\n",
    "X_train = X_train.drop(col_to_drop, axis=1)\n",
    "X_test = X_test.drop(col_to_drop, axis=1)\n",
    "\n",
    "# Recheck VIF\n",
    "vif = checking_vif(X_train).sort_values(by=\"VIF\", ascending=False)\n",
    "vif"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fffa51dd",
   "metadata": {},
   "source": [
    "#### Checking Impact of Dropping Columns on Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a64dda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking impact of dropping columns\n",
    "col_list = vif[vif[\"VIF\"] >= 5][\"feature\"].tolist()\n",
    "col_list.remove(\"const\")\n",
    "\n",
    "results = treating_multicollinearity(X_train, y_train, col_list)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50e79ee",
   "metadata": {},
   "source": [
    "#### Dropping `arts`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764cafcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping arts column\n",
    "col_to_drop = \"arts\"\n",
    "X_train = X_train.drop(col_to_drop, axis=1)\n",
    "X_test = X_test.drop(col_to_drop, axis=1)\n",
    "\n",
    "# Recheck VIF\n",
    "vif = checking_vif(X_train).sort_values(by=\"VIF\", ascending=False)\n",
    "vif"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42ca4f4",
   "metadata": {},
   "source": [
    "#### Checking Impact of Dropping Columns on Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b7c34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking impact of dropping columns\n",
    "col_list = vif[vif[\"VIF\"] >= 5][\"feature\"].tolist()\n",
    "col_list.remove(\"const\")\n",
    "\n",
    "results = treating_multicollinearity(X_train, y_train, col_list)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4a5851",
   "metadata": {},
   "source": [
    "#### Dropping `prior_region_No Prior Region`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c65329b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping prior_region_No Prior Region column\n",
    "col_to_drop = \"prior_region_No Prior Region\"\n",
    "X_train = X_train.drop(col_to_drop, axis=1)\n",
    "X_test = X_test.drop(col_to_drop, axis=1)\n",
    "\n",
    "# Recheck VIF\n",
    "vif = checking_vif(X_train).sort_values(by=\"VIF\", ascending=False)\n",
    "vif"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53701483",
   "metadata": {},
   "source": [
    "#### Checking Impact of Dropping Columns on Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3c7c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking impact of dropping columns\n",
    "col_list = vif[vif[\"VIF\"] >= 5][\"feature\"].tolist()\n",
    "col_list.remove(\"const\")\n",
    "\n",
    "results = treating_multicollinearity(X_train, y_train, col_list)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824eaeb6",
   "metadata": {},
   "source": [
    "#### Dropping `region_Europe`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe25943a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping region_Europe column\n",
    "col_to_drop = \"region_Europe\"\n",
    "X_train = X_train.drop(col_to_drop, axis=1)\n",
    "X_test = X_test.drop(col_to_drop, axis=1)\n",
    "\n",
    "# Recheck VIF\n",
    "vif = checking_vif(X_train).sort_values(by=\"VIF\", ascending=False)\n",
    "vif"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a014e23",
   "metadata": {},
   "source": [
    "#### Fitting Second Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b9787e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting a linear model and displaying model summary\n",
    "olsmodel2 = sm.OLS(y_train, X_train).fit()\n",
    "print(olsmodel2.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1ce68e",
   "metadata": {},
   "source": [
    "#### Checking Features with High Coefficient p-values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db60a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loop for Dropping variables with high coefficient p-values one at a time excluding constant and dummy variables\n",
    "# Current model predictors\n",
    "train_predictors = X_train\n",
    "\n",
    "# initial list of all independent variable columns including constant\n",
    "cols = train_predictors.columns.to_list()\n",
    "\n",
    "# initial empty list of independent variables to exclude\n",
    "excluded_features = []\n",
    "\n",
    "# setting an initial max p_value\n",
    "max_p_value = 1\n",
    "\n",
    "for i in range(len(cols)):\n",
    "    # defining the train set\n",
    "    x_train_aux = train_predictors[cols]\n",
    "\n",
    "    # fitting the model\n",
    "    model = sm.OLS(y_train, x_train_aux).fit()\n",
    "\n",
    "    # getting the p-values and the maximum p-value\n",
    "    p_values = model.pvalues[cols]\n",
    "    max_p_value = max(p_values)\n",
    "\n",
    "    # name of the variable with maximum p-value\n",
    "    feature_with_p_max = p_values.idxmax()\n",
    "\n",
    "    if max_p_value > 0.05:\n",
    "        cols.remove(feature_with_p_max)\n",
    "        excluded_features.append(feature_with_p_max)\n",
    "    else:\n",
    "        break\n",
    "\n",
    "print(f\"Features with high p-values to exclude: {excluded_features}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd86680d",
   "metadata": {},
   "source": [
    "#### Dropping `excluded_features` with High p-values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf36614",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping excluded_features\n",
    "X_train.drop(excluded_features, axis=1, inplace=True)\n",
    "X_test.drop(excluded_features, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a384648",
   "metadata": {},
   "source": [
    "#### Fitting Third Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a669c67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fitting third model and printing summary\n",
    "olsmodel3 = sm.OLS(y_train, X_train).fit()\n",
    "print(olsmodel3.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cca321e",
   "metadata": {},
   "source": [
    "### Test for Linearity and Independence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ddda70b",
   "metadata": {},
   "source": [
    "#### Dataframe of Actual, Fitted, and Residual Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297c2f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe of actual, fitted, and residual values\n",
    "df_pred = pd.DataFrame()\n",
    "\n",
    "df_pred[\"Actual Values\"] = y_train  # actual values\n",
    "df_pred[\"Fitted Values\"] = olsmodel3.fittedvalues  # predicted values\n",
    "df_pred[\"Residuals\"] = olsmodel3.resid  # residuals\n",
    "\n",
    "df_pred.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e1f0fe9",
   "metadata": {},
   "source": [
    "#### Plot of Fitted Values vs Residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83e48ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot of fitted values vs residuals\n",
    "sns.residplot(\n",
    "    data=df_pred, x=\"Fitted Values\", y=\"Residuals\", color=\"purple\", lowess=True\n",
    ")\n",
    "plt.xlabel(\"Fitted Values\")\n",
    "plt.ylabel(\"Residuals\")\n",
    "plt.title(\"Fitted vs Residual plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c84b78",
   "metadata": {},
   "source": [
    "### Test for Normality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea53a14b",
   "metadata": {},
   "source": [
    "#### Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24238cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram of residuals\n",
    "sns.histplot(data=df_pred, x=\"Residuals\", kde=True)\n",
    "plt.title(\"Normality of Residuals\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a85534",
   "metadata": {},
   "source": [
    "#### Q-Q plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31775c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the Q-Q plot\n",
    "stats.probplot(df_pred[\"Residuals\"], dist=\"norm\", plot=pylab)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d98f78e",
   "metadata": {},
   "source": [
    "#### Shapiro-Wilk Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac1e715",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shapiro-Wilk Test for normality\n",
    "test_stat, p_value = stats.shapiro(df_pred[\"Residuals\"])\n",
    "print(f\"p-value = {p_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38003b0",
   "metadata": {},
   "source": [
    "### Test for Homoscedasticity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910ec18f",
   "metadata": {},
   "source": [
    "#### Goldfeld-Quandt Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7a74a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Goldfeld-quandt test\n",
    "name = [\"F statistic\", \"p-value\"]\n",
    "test = sms.het_goldfeldquandt(df_pred[\"Residuals\"], X_train)\n",
    "lzip(name, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f04a978",
   "metadata": {},
   "source": [
    "## Final Model Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef362753",
   "metadata": {},
   "source": [
    "### *olsmodel3* summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68eebd34",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(olsmodel3.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "671752ec",
   "metadata": {},
   "source": [
    "#### Final Model Performance on Train Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0751ef97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking final model performance on train set\n",
    "print(\"Training Performance\\n\")\n",
    "olsmodel_train_perf = model_performance_regression(olsmodel3, X_train, y_train)\n",
    "olsmodel_train_perf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1892988",
   "metadata": {},
   "source": [
    "#### Final Model Performance on Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36fce43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking final model performance on test set\n",
    "print(\"Testing Performance\\n\")\n",
    "olsmodel_test_perf = model_performance_regression(olsmodel3, X_test, y_test)\n",
    "olsmodel_test_perf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5bc920",
   "metadata": {},
   "source": [
    "## Interpreting Model Parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306ffcd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For loop to make list of parameters with p-values < 0.05\n",
    "# Final model predictors\n",
    "final_pred = X_train\n",
    "\n",
    "# initial list of all independent variable columns excluding constant\n",
    "cols = final_pred.columns[1:]\n",
    "\n",
    "# initial list of columns to interpret\n",
    "feat_to_interp = []\n",
    "\n",
    "# for loop to create list of features with p < 0.05\n",
    "for feature in cols:\n",
    "    p_value = olsmodel3.pvalues[feature]\n",
    "    if p_value < 0.05:\n",
    "        feat_to_interp.append(feature)\n",
    "\n",
    "print(\n",
    "    \"Features with interpretable coefficient confidence intervals: \\n\\n\", feat_to_interp\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c6df0e",
   "metadata": {},
   "source": [
    "#### Interpreting Features with Coefficient p-values < 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf1cc0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecbe5c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"dunzo!\")\n",
    "\n",
    "# Sound notification when cell executes\n",
    "chime.success()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0271a07f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40e3f27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6c3c0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0f66697e",
   "metadata": {},
   "source": [
    "#### Observations:\n",
    "- We will now save our dataset and pick back up in a new notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1113a242",
   "metadata": {},
   "source": [
    "### Exporting Dataset to SQLite Database [wp_life_expect_clean.db]()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6008ac61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Exporting dataframe\n",
    "\n",
    "# # Saving dataset in a SQLite database\n",
    "# conn = sql.connect(\"wp_life_expect_clean.db\")\n",
    "# df.to_sql(\"wp_life_expect_clean\", conn, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36c0663",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Complete')\n",
    "\n",
    "# Chime notification when cell executes\n",
    "chime.success()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11aacfcc",
   "metadata": {},
   "source": [
    "# [Proceed to Data Cleaning Part ]()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
